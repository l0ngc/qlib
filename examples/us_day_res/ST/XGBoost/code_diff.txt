diff --git a/examples/benchmarks/ADARNN/README.md b/examples/benchmarks/ADARNN/README.md
deleted file mode 100644
index 2296af92..00000000
--- a/examples/benchmarks/ADARNN/README.md
+++ /dev/null
@@ -1,4 +0,0 @@
-# AdaRNN
-* Code: [https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn](https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn)
-* Paper: [AdaRNN: Adaptive Learning and Forecasting for Time Series](https://arxiv.org/pdf/2108.04443.pdf).
-
diff --git a/examples/benchmarks/ADARNN/requirements.txt b/examples/benchmarks/ADARNN/requirements.txt
deleted file mode 100644
index bfdf9415..00000000
--- a/examples/benchmarks/ADARNN/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/ADARNN/workflow_config_adarnn_Alpha360.yaml b/examples/benchmarks/ADARNN/workflow_config_adarnn_Alpha360.yaml
deleted file mode 100644
index ae2bad5c..00000000
--- a/examples/benchmarks/ADARNN/workflow_config_adarnn_Alpha360.yaml
+++ /dev/null
@@ -1,87 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: ADARNN
-        module_path: qlib.contrib.model.pytorch_adarnn
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.0
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 20
-            batch_size: 800
-            metric: loss
-            loss: mse
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/ADD/README.md b/examples/benchmarks/ADD/README.md
deleted file mode 100644
index 986b29e5..00000000
--- a/examples/benchmarks/ADD/README.md
+++ /dev/null
@@ -1,3 +0,0 @@
-# ADD
-* Paper: [ADD: Augmented Disentanglement Distillation Framework for Improving Stock Trend Forecasting](https://arxiv.org/abs/2012.06289).
-
diff --git a/examples/benchmarks/ADD/requirements.txt b/examples/benchmarks/ADD/requirements.txt
deleted file mode 100644
index baf29249..00000000
--- a/examples/benchmarks/ADD/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-numpy==1.21.0
-pandas==1.1.2
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/ADD/workflow_config_add_Alpha360.yaml b/examples/benchmarks/ADD/workflow_config_add_Alpha360.yaml
deleted file mode 100644
index b2168a1b..00000000
--- a/examples/benchmarks/ADD/workflow_config_add_Alpha360.yaml
+++ /dev/null
@@ -1,92 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: ADD
-        module_path: qlib.contrib.model.pytorch_add
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.1
-            dec_dropout: 0.0
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 20
-            batch_size: 5000
-            metric: ic
-            base_model: GRU
-            gamma: 0.1
-            gamma_clip: 0.2
-            optimizer: adam
-            mu: 0.2
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record:
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs:
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs:
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs:
-            config: *port_analysis_config
diff --git a/examples/benchmarks/ALSTM/README.md b/examples/benchmarks/ALSTM/README.md
deleted file mode 100644
index b1a3b222..00000000
--- a/examples/benchmarks/ALSTM/README.md
+++ /dev/null
@@ -1,9 +0,0 @@
-# ALSTM
-
-- ALSTM contains a temporal attentive aggregation layer based on normal LSTM.
-
-- Paper: A dual-stage attention-based recurrent neural network for time series prediction.
-
-  [https://www.ijcai.org/Proceedings/2017/0366.pdf](https://www.ijcai.org/Proceedings/2017/0366.pdf)
-
-- NOTE: Current version of implementation is just a simplified version of ALSTM. It is an LSTM with attention.
diff --git a/examples/benchmarks/ALSTM/requirements.txt b/examples/benchmarks/ALSTM/requirements.txt
deleted file mode 100644
index baf29249..00000000
--- a/examples/benchmarks/ALSTM/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-numpy==1.21.0
-pandas==1.1.2
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha158.yaml b/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha158.yaml
deleted file mode 100755
index 568505ee..00000000
--- a/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha158.yaml
+++ /dev/null
@@ -1,98 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: FilterCol
-          kwargs:
-              fields_group: feature
-              col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
-                            "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
-                            "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
-                        ]
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"] 
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: ALSTM
-        module_path: qlib.contrib.model.pytorch_alstm_ts
-        kwargs:
-            d_feat: 20
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.0
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 10
-            batch_size: 800
-            metric: loss
-            loss: mse
-            n_jobs: 20
-            GPU: 0
-            rnn_type: GRU
-    dataset:
-        class: TSDatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-            step_len: 20
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha360.yaml b/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha360.yaml
deleted file mode 100644
index b345cacd..00000000
--- a/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha360.yaml
+++ /dev/null
@@ -1,88 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: ALSTM
-        module_path: qlib.contrib.model.pytorch_alstm
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.0
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 20
-            batch_size: 800
-            metric: loss
-            loss: mse
-            GPU: 0
-            rnn_type: GRU
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/CatBoost/README.md b/examples/benchmarks/CatBoost/README.md
deleted file mode 100644
index 5e4f3966..00000000
--- a/examples/benchmarks/CatBoost/README.md
+++ /dev/null
@@ -1,3 +0,0 @@
-# CatBoost
-* Code: [https://github.com/catboost/catboost](https://github.com/catboost/catboost)
-* Paper: CatBoost: unbiased boosting with categorical features. [https://proceedings.neurips.cc/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf](https://proceedings.neurips.cc/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf).
\ No newline at end of file
diff --git a/examples/benchmarks/CatBoost/requirements.txt b/examples/benchmarks/CatBoost/requirements.txt
deleted file mode 100644
index 1eb520ab..00000000
--- a/examples/benchmarks/CatBoost/requirements.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-catboost==0.24.3
diff --git a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158.yaml b/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158.yaml
deleted file mode 100644
index 635611ff..00000000
--- a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158.yaml
+++ /dev/null
@@ -1,70 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: CatBoostModel
-        module_path: qlib.contrib.model.catboost_model
-        kwargs:
-            loss: RMSE
-            learning_rate: 0.0421
-            subsample: 0.8789
-            max_depth: 6
-            num_leaves: 100
-            thread_count: 20
-            grow_policy: Lossguide
-            bootstrap_type: Poisson
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158_csi500.yaml b/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158_csi500.yaml
deleted file mode 100644
index c40f0f81..00000000
--- a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha158_csi500.yaml
+++ /dev/null
@@ -1,70 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi500
-benchmark: &benchmark SH000905
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: CatBoostModel
-        module_path: qlib.contrib.model.catboost_model
-        kwargs:
-            loss: RMSE
-            learning_rate: 0.0421
-            subsample: 0.8789
-            max_depth: 6
-            num_leaves: 100
-            thread_count: 20
-            grow_policy: Lossguide
-            bootstrap_type: Poisson
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360.yaml b/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360.yaml
deleted file mode 100644
index 136ab7e6..00000000
--- a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360.yaml
+++ /dev/null
@@ -1,77 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors: []
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: CatBoostModel
-        module_path: qlib.contrib.model.catboost_model
-        kwargs:
-            loss: RMSE
-            learning_rate: 0.0421
-            subsample: 0.8789
-            max_depth: 6
-            num_leaves: 100
-            thread_count: 20
-            grow_policy: Lossguide
-            bootstrap_type: Poisson
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360_csi500.yaml b/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360_csi500.yaml
deleted file mode 100644
index 44814070..00000000
--- a/examples/benchmarks/CatBoost/workflow_config_catboost_Alpha360_csi500.yaml
+++ /dev/null
@@ -1,77 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi500
-benchmark: &benchmark SH000905
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors: []
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: CatBoostModel
-        module_path: qlib.contrib.model.catboost_model
-        kwargs:
-            loss: RMSE
-            learning_rate: 0.0421
-            subsample: 0.8789
-            max_depth: 6
-            num_leaves: 100
-            thread_count: 20
-            grow_policy: Lossguide
-            bootstrap_type: Poisson
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/DoubleEnsemble/README.md b/examples/benchmarks/DoubleEnsemble/README.md
deleted file mode 100644
index 67e74105..00000000
--- a/examples/benchmarks/DoubleEnsemble/README.md
+++ /dev/null
@@ -1,4 +0,0 @@
-# DoubleEnsemble
-* DoubleEnsemble is an ensemble framework leveraging learning trajectory based sample reweighting and shuffling based feature selection, to solve both the low signal-to-noise ratio and increasing number of features problems. They identify the key samples based on the training dynamics on each sample and elicit key features based on the ablation impact of each feature via shuffling. The model is applicable to a wide range of base models, capable of extracting complex patterns, while mitigating the overfitting and instability issues for financial market prediction.
-* This code used in Qlib is implemented by ourselves.
-* Paper: DoubleEnsemble: A New Ensemble Method Based on Sample Reweighting and Feature Selection for Financial Data Analysis [https://arxiv.org/pdf/2010.01265.pdf](https://arxiv.org/pdf/2010.01265.pdf).
\ No newline at end of file
diff --git a/examples/benchmarks/DoubleEnsemble/requirements.txt b/examples/benchmarks/DoubleEnsemble/requirements.txt
deleted file mode 100644
index d25789bd..00000000
--- a/examples/benchmarks/DoubleEnsemble/requirements.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-lightgbm==3.1.0
\ No newline at end of file
diff --git a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158.yaml b/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158.yaml
deleted file mode 100644
index 58a01d63..00000000
--- a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158.yaml
+++ /dev/null
@@ -1,92 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: DEnsembleModel
-        module_path: qlib.contrib.model.double_ensemble
-        kwargs:
-            base_model: "gbm"
-            loss: mse
-            num_models: 3
-            enable_sr: True
-            enable_fs: True
-            alpha1: 1
-            alpha2: 1
-            bins_sr: 10
-            bins_fs: 5
-            decay: 0.5
-            sample_ratios:
-                - 0.8
-                - 0.7
-                - 0.6
-                - 0.5
-                - 0.4
-            sub_weights:
-                - 1
-                - 1
-                - 1
-            epochs: 28
-            colsample_bytree: 0.8879
-            learning_rate: 0.2
-            subsample: 0.8789
-            lambda_l1: 205.6999
-            lambda_l2: 580.9768
-            max_depth: 8
-            num_leaves: 210
-            num_threads: 20
-            verbosity: -1
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158_csi500.yaml b/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158_csi500.yaml
deleted file mode 100644
index ea92fbc7..00000000
--- a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha158_csi500.yaml
+++ /dev/null
@@ -1,95 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi500
-benchmark: &benchmark SH000905
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: DEnsembleModel
-        module_path: qlib.contrib.model.double_ensemble
-        kwargs:
-            base_model: "gbm"
-            loss: mse
-            num_models: 6
-            enable_sr: True
-            enable_fs: True
-            alpha1: 1
-            alpha2: 1
-            bins_sr: 10
-            bins_fs: 5
-            decay: 0.5
-            sample_ratios:
-                - 0.8
-                - 0.7
-                - 0.6
-                - 0.5
-                - 0.4
-            sub_weights:
-                - 1
-                - 0.2
-                - 0.2
-                - 0.2
-                - 0.2
-                - 0.2
-            epochs: 28
-            colsample_bytree: 0.8879
-            learning_rate: 0.2
-            subsample: 0.8789
-            lambda_l1: 205.6999
-            lambda_l2: 580.9768
-            max_depth: 8
-            num_leaves: 210
-            num_threads: 20
-            verbosity: -1
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360.yaml b/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360.yaml
deleted file mode 100644
index edb5e960..00000000
--- a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360.yaml
+++ /dev/null
@@ -1,99 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors: []
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: DEnsembleModel
-        module_path: qlib.contrib.model.double_ensemble
-        kwargs:
-            base_model: "gbm"
-            loss: mse
-            num_models: 3
-            enable_sr: True
-            enable_fs: True
-            alpha1: 1
-            alpha2: 1
-            bins_sr: 10
-            bins_fs: 5
-            decay: 0.5
-            sample_ratios:
-                - 0.8
-                - 0.7
-                - 0.6
-                - 0.5
-                - 0.4
-            sub_weights:
-                - 1
-                - 1
-                - 1
-            epochs: 136
-            colsample_bytree: 0.8879
-            learning_rate: 0.0421
-            subsample: 0.8789
-            lambda_l1: 205.6999
-            lambda_l2: 580.9768
-            max_depth: 8
-            num_leaves: 210
-            num_threads: 20
-            verbosity: -1
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs:
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360_csi500.yaml b/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360_csi500.yaml
deleted file mode 100644
index ec8afefb..00000000
--- a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_Alpha360_csi500.yaml
+++ /dev/null
@@ -1,102 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi500
-benchmark: &benchmark SH000905
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors: []
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: DEnsembleModel
-        module_path: qlib.contrib.model.double_ensemble
-        kwargs:
-            base_model: "gbm"
-            loss: mse
-            num_models: 6
-            enable_sr: True
-            enable_fs: True
-            alpha1: 1
-            alpha2: 1
-            bins_sr: 10
-            bins_fs: 5
-            decay: 0.5
-            sample_ratios:
-                - 0.8
-                - 0.7
-                - 0.6
-                - 0.5
-                - 0.4
-            sub_weights:
-                - 1
-                - 0.2
-                - 0.2
-                - 0.2
-                - 0.2
-                - 0.2
-            epochs: 136
-            colsample_bytree: 0.8879
-            learning_rate: 0.0421
-            subsample: 0.8789
-            lambda_l1: 205.6999
-            lambda_l2: 580.9768
-            max_depth: 8
-            num_leaves: 210
-            num_threads: 20
-            verbosity: -1
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs:
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_early_stop_Alpha158.yaml b/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_early_stop_Alpha158.yaml
deleted file mode 100644
index 3960aca1..00000000
--- a/examples/benchmarks/DoubleEnsemble/workflow_config_doubleensemble_early_stop_Alpha158.yaml
+++ /dev/null
@@ -1,93 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: DEnsembleModel
-        module_path: qlib.contrib.model.double_ensemble
-        kwargs:
-            base_model: "gbm"
-            loss: mse
-            num_models: 3
-            enable_sr: True
-            enable_fs: True
-            alpha1: 1
-            alpha2: 1
-            bins_sr: 10
-            bins_fs: 5
-            decay: 0.5
-            sample_ratios:
-                - 0.8
-                - 0.7
-                - 0.6
-                - 0.5
-                - 0.4
-            sub_weights:
-                - 1
-                - 1
-                - 1
-            epochs: 1000
-            early_stopping_rounds: 50
-            colsample_bytree: 0.8879
-            learning_rate: 0.2
-            subsample: 0.8789
-            lambda_l1: 205.6999
-            lambda_l2: 580.9768
-            max_depth: 8
-            num_leaves: 210
-            num_threads: 20
-            verbosity: -1
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/GATs/README.md b/examples/benchmarks/GATs/README.md
deleted file mode 100644
index f432b6c5..00000000
--- a/examples/benchmarks/GATs/README.md
+++ /dev/null
@@ -1,5 +0,0 @@
-# GATs
-* Graph Attention Networks(GATs) leverage masked self-attentional layers on graph-structured data. The nodes in stacked layers have different weights and they are able to attend over their
-neighborhoodsâ€™ features, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront.
-* This code used in Qlib is implemented with PyTorch by ourselves.
-* Paper: Graph Attention Networks https://arxiv.org/pdf/1710.10903.pdf
\ No newline at end of file
diff --git a/examples/benchmarks/GATs/requirements.txt b/examples/benchmarks/GATs/requirements.txt
deleted file mode 100644
index bfdf9415..00000000
--- a/examples/benchmarks/GATs/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/GATs/workflow_config_gats_Alpha158.yaml b/examples/benchmarks/GATs/workflow_config_gats_Alpha158.yaml
deleted file mode 100644
index 0710f318..00000000
--- a/examples/benchmarks/GATs/workflow_config_gats_Alpha158.yaml
+++ /dev/null
@@ -1,96 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: FilterCol
-          kwargs:
-              fields_group: feature
-              col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
-                            "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
-                            "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
-                        ]
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"] 
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: GATs
-        module_path: qlib.contrib.model.pytorch_gats_ts
-        kwargs:
-            d_feat: 20
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.7
-            n_epochs: 200
-            lr: 1e-4
-            early_stop: 10
-            metric: loss
-            loss: mse
-            base_model: LSTM
-            model_path: "benchmarks/LSTM/csi300_lstm_ts.pkl"
-            GPU: 0
-    dataset:
-        class: TSDatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-            step_len: 20
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/GATs/workflow_config_gats_Alpha360.yaml b/examples/benchmarks/GATs/workflow_config_gats_Alpha360.yaml
deleted file mode 100644
index 095e0bad..00000000
--- a/examples/benchmarks/GATs/workflow_config_gats_Alpha360.yaml
+++ /dev/null
@@ -1,88 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: GATs
-        module_path: qlib.contrib.model.pytorch_gats
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.7
-            n_epochs: 200
-            lr: 1e-4
-            early_stop: 20
-            metric: loss
-            loss: mse
-            base_model: LSTM
-            model_path: "benchmarks/LSTM/model_lstm_csi300.pkl"
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/GRU/README.md b/examples/benchmarks/GRU/README.md
deleted file mode 100644
index cc2ba320..00000000
--- a/examples/benchmarks/GRU/README.md
+++ /dev/null
@@ -1,2 +0,0 @@
-# Gated Recurrent Unit (GRU)
-* Paper: [Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation](https://aclanthology.org/D14-1179.pdf).
diff --git a/examples/benchmarks/GRU/csi300_gru_ts.pkl b/examples/benchmarks/GRU/csi300_gru_ts.pkl
deleted file mode 100644
index ac1a25fe..00000000
Binary files a/examples/benchmarks/GRU/csi300_gru_ts.pkl and /dev/null differ
diff --git a/examples/benchmarks/GRU/model_gru_csi300.pkl b/examples/benchmarks/GRU/model_gru_csi300.pkl
deleted file mode 100644
index 46347ce8..00000000
Binary files a/examples/benchmarks/GRU/model_gru_csi300.pkl and /dev/null differ
diff --git a/examples/benchmarks/GRU/requirements.txt b/examples/benchmarks/GRU/requirements.txt
deleted file mode 100644
index baf29249..00000000
--- a/examples/benchmarks/GRU/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-numpy==1.21.0
-pandas==1.1.2
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/GRU/workflow_config_gru_Alpha158.yaml b/examples/benchmarks/GRU/workflow_config_gru_Alpha158.yaml
deleted file mode 100755
index a2f03a23..00000000
--- a/examples/benchmarks/GRU/workflow_config_gru_Alpha158.yaml
+++ /dev/null
@@ -1,97 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: FilterCol
-          kwargs:
-              fields_group: feature
-              col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
-                            "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
-                            "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
-                        ]
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"] 
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: GRU
-        module_path: qlib.contrib.model.pytorch_gru_ts
-        kwargs:
-            d_feat: 20
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.0
-            n_epochs: 200
-            lr: 2e-4
-            early_stop: 10
-            batch_size: 800
-            metric: loss
-            loss: mse
-            n_jobs: 20
-            GPU: 0
-    dataset:
-        class: TSDatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-            step_len: 20
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/GRU/workflow_config_gru_Alpha360.yaml b/examples/benchmarks/GRU/workflow_config_gru_Alpha360.yaml
deleted file mode 100644
index f5d837a0..00000000
--- a/examples/benchmarks/GRU/workflow_config_gru_Alpha360.yaml
+++ /dev/null
@@ -1,87 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: GRU
-        module_path: qlib.contrib.model.pytorch_gru
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.0
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 20
-            batch_size: 800
-            metric: loss
-            loss: mse
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/HIST/README.md b/examples/benchmarks/HIST/README.md
deleted file mode 100644
index 87f9a35c..00000000
--- a/examples/benchmarks/HIST/README.md
+++ /dev/null
@@ -1,3 +0,0 @@
-# HIST
-* Code: [https://github.com/Wentao-Xu/HIST](https://github.com/Wentao-Xu/HIST)
-* Paper: [HIST: A Graph-based Framework for Stock Trend Forecasting via Mining Concept-Oriented Shared InformationAdaRNN: Adaptive Learning and Forecasting for Time Series](https://arxiv.org/abs/2110.13716).
\ No newline at end of file
diff --git a/examples/benchmarks/HIST/qlib_csi300_stock_index.npy b/examples/benchmarks/HIST/qlib_csi300_stock_index.npy
deleted file mode 100644
index 36db027d..00000000
Binary files a/examples/benchmarks/HIST/qlib_csi300_stock_index.npy and /dev/null differ
diff --git a/examples/benchmarks/HIST/requirements.txt b/examples/benchmarks/HIST/requirements.txt
deleted file mode 100644
index d2f37de6..00000000
--- a/examples/benchmarks/HIST/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
\ No newline at end of file
diff --git a/examples/benchmarks/HIST/workflow_config_hist_Alpha360.yaml b/examples/benchmarks/HIST/workflow_config_hist_Alpha360.yaml
deleted file mode 100644
index cd50b338..00000000
--- a/examples/benchmarks/HIST/workflow_config_hist_Alpha360.yaml
+++ /dev/null
@@ -1,90 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: HIST
-        module_path: qlib.contrib.model.pytorch_hist
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0
-            n_epochs: 200
-            lr: 1e-4
-            early_stop: 20
-            metric: ic
-            loss: mse
-            base_model: LSTM
-            model_path: "benchmarks/LSTM/model_lstm_csi300.pkl"
-            stock2concept: "benchmarks/HIST/qlib_csi300_stock2concept.npy"
-            stock_index: "benchmarks/HIST/qlib_csi300_stock_index.npy"
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/IGMTF/README.md b/examples/benchmarks/IGMTF/README.md
deleted file mode 100644
index dbda8e6b..00000000
--- a/examples/benchmarks/IGMTF/README.md
+++ /dev/null
@@ -1,4 +0,0 @@
-# IGMTF
-* Code: [https://github.com/Wentao-Xu/IGMTF](https://github.com/Wentao-Xu/IGMTF)
-* Paper: [IGMTF: An Instance-wise Graph-based Framework for
-Multivariate Time Series Forecasting](https://arxiv.org/abs/2109.06489).
\ No newline at end of file
diff --git a/examples/benchmarks/IGMTF/requirements.txt b/examples/benchmarks/IGMTF/requirements.txt
deleted file mode 100644
index bfdf9415..00000000
--- a/examples/benchmarks/IGMTF/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/IGMTF/workflow_config_igmtf_Alpha360.yaml b/examples/benchmarks/IGMTF/workflow_config_igmtf_Alpha360.yaml
deleted file mode 100644
index 838e6606..00000000
--- a/examples/benchmarks/IGMTF/workflow_config_igmtf_Alpha360.yaml
+++ /dev/null
@@ -1,88 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: IGMTF
-        module_path: qlib.contrib.model.pytorch_igmtf
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0
-            n_epochs: 200
-            lr: 1e-4
-            early_stop: 20
-            metric: ic
-            loss: mse
-            base_model: LSTM
-            model_path: "benchmarks/LSTM/model_lstm_csi300.pkl"
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/KRNN/README.md b/examples/benchmarks/KRNN/README.md
deleted file mode 100644
index 31af523e..00000000
--- a/examples/benchmarks/KRNN/README.md
+++ /dev/null
@@ -1,8 +0,0 @@
-# KRNN
-* Code: [https://github.com/microsoft/FOST/blob/main/fostool/model/krnn.py](https://github.com/microsoft/FOST/blob/main/fostool/model/krnn.py)
-
-
-# Introductions about the settings/configs.
-* Torch_geometric is used in the original model in FOST, but we didn't use it.
-* make use your CUDA version matches the torch version to allow the usage of GPU, we use CUDA==10.2 and torch.__version__==1.12.1
-
diff --git a/examples/benchmarks/KRNN/requirements.txt b/examples/benchmarks/KRNN/requirements.txt
deleted file mode 100644
index 87d3b2dd..00000000
--- a/examples/benchmarks/KRNN/requirements.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-numpy==1.23.4
-pandas==1.5.2
diff --git a/examples/benchmarks/KRNN/workflow_config_krnn_Alpha360.yaml b/examples/benchmarks/KRNN/workflow_config_krnn_Alpha360.yaml
deleted file mode 100644
index b5a3e3bc..00000000
--- a/examples/benchmarks/KRNN/workflow_config_krnn_Alpha360.yaml
+++ /dev/null
@@ -1,89 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: KRNN
-        module_path: qlib.contrib.model.pytorch_krnn
-        kwargs:
-            fea_dim: 6
-            cnn_dim: 8
-            cnn_kernel_size: 3
-            rnn_dim: 8
-            rnn_dups: 2
-            rnn_layers: 2
-            n_epochs: 200
-            lr: 0.001
-            early_stop: 20
-            batch_size: 2000
-            metric: loss
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
-
diff --git a/examples/benchmarks/Localformer/README.md b/examples/benchmarks/Localformer/README.md
deleted file mode 100644
index 9340c209..00000000
--- a/examples/benchmarks/Localformer/README.md
+++ /dev/null
@@ -1 +0,0 @@
-# Localformer
diff --git a/examples/benchmarks/Localformer/requirements.txt b/examples/benchmarks/Localformer/requirements.txt
deleted file mode 100644
index 4c864907..00000000
--- a/examples/benchmarks/Localformer/requirements.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-numpy==1.21.0
-pandas==1.1.2
-torch==1.2.0
\ No newline at end of file
diff --git a/examples/benchmarks/Localformer/workflow_config_localformer_Alpha158.yaml b/examples/benchmarks/Localformer/workflow_config_localformer_Alpha158.yaml
deleted file mode 100644
index e3200f12..00000000
--- a/examples/benchmarks/Localformer/workflow_config_localformer_Alpha158.yaml
+++ /dev/null
@@ -1,87 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: FilterCol
-          kwargs:
-              fields_group: feature
-              col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
-                            "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
-                            "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
-                        ]
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"] 
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: LocalformerModel
-        module_path: qlib.contrib.model.pytorch_localformer_ts
-        kwargs:
-            seed: 0
-            n_jobs: 20
-    dataset:
-        class: TSDatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-            step_len: 20
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-              model: <MODEL>
-              dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-              ana_long_short: False
-              ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-              config: *port_analysis_config
diff --git a/examples/benchmarks/Localformer/workflow_config_localformer_Alpha360.yaml b/examples/benchmarks/Localformer/workflow_config_localformer_Alpha360.yaml
deleted file mode 100644
index 39c0093a..00000000
--- a/examples/benchmarks/Localformer/workflow_config_localformer_Alpha360.yaml
+++ /dev/null
@@ -1,78 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: LocalformerModel
-        module_path: qlib.contrib.model.pytorch_localformer
-        kwargs:
-            d_feat: 6
-            seed: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-    - class: SignalRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        model: <MODEL>
-        dataset: <DATASET>
-    - class: SigAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        ana_long_short: False
-        ann_scaler: 252
-    - class: PortAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        config: *port_analysis_config
diff --git a/examples/benchmarks/SFM/README.md b/examples/benchmarks/SFM/README.md
deleted file mode 100644
index ff54145a..00000000
--- a/examples/benchmarks/SFM/README.md
+++ /dev/null
@@ -1,3 +0,0 @@
-# State-Frequency-Memory
-- State Frequency Memory (SFM) is a novel recurrent network that uses Discrete Fourier Transform to decompose the hidden states of memory cells and capture the multi-frequency trading patterns from past market data to make stock price predictions. 
-- Paper: Stock Price Prediction via Discovering Multi-Frequency Trading Patterns. [http://www.eecs.ucf.edu/~gqi/publications/kdd2017_stock.pdf.](http://www.eecs.ucf.edu/~gqi/publications/kdd2017_stock.pdf)
\ No newline at end of file
diff --git a/examples/benchmarks/SFM/requirements.txt b/examples/benchmarks/SFM/requirements.txt
deleted file mode 100644
index bfdf9415..00000000
--- a/examples/benchmarks/SFM/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/SFM/workflow_config_sfm_Alpha360.yaml b/examples/benchmarks/SFM/workflow_config_sfm_Alpha360.yaml
deleted file mode 100644
index d992af34..00000000
--- a/examples/benchmarks/SFM/workflow_config_sfm_Alpha360.yaml
+++ /dev/null
@@ -1,90 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: SFM
-        module_path: qlib.contrib.model.pytorch_sfm
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            output_dim: 32
-            freq_dim: 25
-            dropout_W: 0.5
-            dropout_U: 0.5
-            n_epochs: 20
-            lr: 1e-3
-            batch_size: 1600
-            early_stop: 20
-            eval_steps: 5
-            loss: mse
-            optimizer: adam
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/Sandwich/README.md b/examples/benchmarks/Sandwich/README.md
deleted file mode 100644
index 26f189a3..00000000
--- a/examples/benchmarks/Sandwich/README.md
+++ /dev/null
@@ -1,8 +0,0 @@
-# Sandwich
-* Code: [https://github.com/microsoft/FOST/blob/main/fostool/model/sandwich.py](https://github.com/microsoft/FOST/blob/main/fostool/model/sandwich.py)
-
-
-# Introductions about the settings/configs.
-* Torch_geometric is used in the original model in FOST, but we didn't use it.
-make use your CUDA version matches the torch version to allow the usage of GPU, we use CUDA==10.2 and torch.version==1.12.1
-
diff --git a/examples/benchmarks/Sandwich/requirements.txt b/examples/benchmarks/Sandwich/requirements.txt
deleted file mode 100644
index 87d3b2dd..00000000
--- a/examples/benchmarks/Sandwich/requirements.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-numpy==1.23.4
-pandas==1.5.2
diff --git a/examples/benchmarks/Sandwich/workflow_config_sandwich_Alpha360.yaml b/examples/benchmarks/Sandwich/workflow_config_sandwich_Alpha360.yaml
deleted file mode 100644
index 29e67d67..00000000
--- a/examples/benchmarks/Sandwich/workflow_config_sandwich_Alpha360.yaml
+++ /dev/null
@@ -1,91 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: Sandwich
-        module_path: qlib.contrib.model.pytorch_sandwich
-        kwargs:
-            fea_dim: 6
-            cnn_dim_1: 16
-            cnn_dim_2: 16
-            cnn_kernel_size: 3
-            rnn_dim_1: 8
-            rnn_dim_2: 8
-            rnn_dups: 2
-            rnn_layers: 2
-            n_epochs: 200
-            lr: 0.001
-            early_stop: 20
-            batch_size: 2000
-            metric: loss
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
-
diff --git a/examples/benchmarks/TCN/README.md b/examples/benchmarks/TCN/README.md
deleted file mode 100644
index 127ed741..00000000
--- a/examples/benchmarks/TCN/README.md
+++ /dev/null
@@ -1,4 +0,0 @@
-# TCN
-* Code: [https://github.com/locuslab/TCN](https://github.com/locuslab/TCN)
-* Paper: [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/abs/1803.01271).
-
diff --git a/examples/benchmarks/TCN/requirements.txt b/examples/benchmarks/TCN/requirements.txt
deleted file mode 100644
index baf29249..00000000
--- a/examples/benchmarks/TCN/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-numpy==1.21.0
-pandas==1.1.2
-scikit_learn==0.23.2
-torch==1.7.0
diff --git a/examples/benchmarks/TCN/workflow_config_tcn_Alpha158.yaml b/examples/benchmarks/TCN/workflow_config_tcn_Alpha158.yaml
deleted file mode 100755
index dcb7508a..00000000
--- a/examples/benchmarks/TCN/workflow_config_tcn_Alpha158.yaml
+++ /dev/null
@@ -1,99 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: FilterCol
-          kwargs:
-              fields_group: feature
-              col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
-                            "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
-                            "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
-                        ]
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TCN
-        module_path: qlib.contrib.model.pytorch_tcn_ts
-        kwargs:
-            d_feat: 20
-            num_layers: 5
-            n_chans: 32
-            kernel_size: 7
-            dropout: 0.5
-            n_epochs: 200
-            lr: 1e-4
-            early_stop: 20
-            batch_size: 2000
-            metric: loss
-            loss: mse
-            optimizer: adam
-            n_jobs: 20
-            GPU: 0
-    dataset:
-        class: TSDatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-            step_len: 20
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/TCN/workflow_config_tcn_Alpha360.yaml b/examples/benchmarks/TCN/workflow_config_tcn_Alpha360.yaml
deleted file mode 100644
index 4756a93b..00000000
--- a/examples/benchmarks/TCN/workflow_config_tcn_Alpha360.yaml
+++ /dev/null
@@ -1,89 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TCN
-        module_path: qlib.contrib.model.pytorch_tcn
-        kwargs:
-            d_feat: 6
-            num_layers: 5
-            n_chans: 128
-            kernel_size: 3
-            dropout: 0.5
-            n_epochs: 200
-            lr: 1e-3
-            early_stop: 20
-            batch_size: 2000
-            metric: loss
-            loss: mse
-            optimizer: adam
-            GPU: 0
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/TCTS/README.md b/examples/benchmarks/TCTS/README.md
deleted file mode 100644
index 0b405c6b..00000000
--- a/examples/benchmarks/TCTS/README.md
+++ /dev/null
@@ -1,38 +0,0 @@
-# Temporally Correlated Task Scheduling for Sequence Learning
-### Background
-Sequence learning has attracted much research attention from the machine learning community in recent years. In many applications, a sequence learning task is usually associated with multiple temporally correlated auxiliary tasks, which are different in terms of how much input information to use or which future step to predict. In stock trend forecasting, as demonstrated in Figure1, one can predict the price of a stock in different future days (e.g., tomorrow, the day after tomorrow). In this paper, we propose a framework to make use of those temporally correlated tasks to help each other. 
-
-### Method
-Given that there are usually multiple temporally correlated tasks, the key challenge lies in which tasks to use and when to use them in the training process. This work introduces a learnable task scheduler for sequence learning, which adaptively selects temporally correlated tasks during the training process. The scheduler accesses the model status and the current training data (e.g., in the current minibatch) and selects the best auxiliary task to help the training of the main task. The scheduler and the model for the main task are jointly trained through bi-level optimization: the scheduler is trained to maximize the validation performance of the model, and the model is trained to minimize the training loss guided by the scheduler. The process is demonstrated in Figure2.
-
-<p align="center"> 
-<img src="workflow.png"/>
-</p>
-
-At step <img src="https://latex.codecogs.com/png.latex?s" title="s" />, with training data <img src="https://latex.codecogs.com/png.latex?x_s,y_s" title="x_s,y_s" />, the scheduler <img src="https://latex.codecogs.com/png.latex?\varphi" title="\varphi" /> chooses a suitable task <img src="https://latex.codecogs.com/png.latex?T_{i_s}" title="T_{i_s}" /> (green solid lines) to update the model <img src="https://latex.codecogs.com/png.latex?f" title="f" /> (blue solid lines). After <img src="https://latex.codecogs.com/png.latex?S" title="S" /> steps, we evaluate the model <img src="https://latex.codecogs.com/png.latex?f" title="f" /> on the validation set and update the scheduler <img src="https://latex.codecogs.com/png.latex?\varphi" title="\varphi" /> (green dashed lines).
-
-### Experiments
-Due to different data versions and different Qlib versions, the original data and data preprocessing methods of the experimental settings in the paper are different from those experimental settings in the existing Qlib version. Therefore, we provide two versions of the code according to the two kinds of settings, 1) the [code](https://github.com/lwwang1995/tcts) that can be used to reproduce the experimental results and 2) the [code](https://github.com/microsoft/qlib/blob/main/qlib/contrib/model/pytorch_tcts.py) in the current Qlib baseline.
-
-#### Setting1
-* Dataset: We use the historical transaction data for 300 stocks on [CSI300](http://www.csindex.com.cn/en/indices/index-detail/000300) from 01/01/2008 to 08/01/2020. We split the data into training (01/01/2008-12/31/2013), validation (01/01/2014-12/31/2015), and test sets (01/01/2016-08/01/2020) based on the transaction time. 
-
-* The main tasks <img src="https://latex.codecogs.com/png.latex?T_k" title="T_k" /> refers to forecasting return of stock <img src="https://latex.codecogs.com/png.latex?i" title="i" /> as following,
-<div align=center>
-<img src="https://latex.codecogs.com/png.image?\dpi{110}&space;r_{i}^{t,k}&space;=&space;\frac{price_i^{t&plus;k}}{price_i^{t&plus;k-1}}-1" title="r_{i}^{t,k} = \frac{price_i^{t+k}}{price_i^{t+k-1}}-1" />
-</div>
-
-* Temporally correlated task sets <img src="https://latex.codecogs.com/png.latex?\mathcal{T}_k&space;=&space;\{T_1,&space;T_2,&space;...&space;,&space;T_k\}" title="\mathcal{T}_k = \{T_1, T_2, ... , T_k\}" />, in this paper, <img src="https://latex.codecogs.com/png.latex?\mathcal{T}_3" title="\mathcal{T}_3" />, <img src="https://latex.codecogs.com/png.latex?\mathcal{T}_5" title="\mathcal{T}_5" /> and <img src="https://latex.codecogs.com/png.latex?\mathcal{T}_{10}" title="\mathcal{T}_{10}" /> are used in <img src="https://latex.codecogs.com/png.latex?T_1" title="T_1" />, <img src="https://latex.codecogs.com/png.latex?T_2" title="T_2" />, and <img src="https://latex.codecogs.com/png.latex?T_3" title="T_3" />.
-
-#### Setting2
-* Dataset: We use the historical transaction data for 300 stocks on [CSI300](http://www.csindex.com.cn/en/indices/index-detail/000300) from 01/01/2008 to 08/01/2020. We split the data into training (01/01/2008-12/31/2014), validation (01/01/2015-12/31/2016), and test sets (01/01/2017-08/01/2020) based on the transaction time. 
-
-* The main tasks <img src="https://latex.codecogs.com/png.latex?T_k" title="T_k" /> refers to forecasting return of stock <img src="https://latex.codecogs.com/png.latex?i" title="i" /> as following,
-<div align=center>
-<img src="https://latex.codecogs.com/png.image?\dpi{110}&space;r_{i}^{t,k}&space;=&space;\frac{price_i^{t&plus;1&plus;k}}{price_i^{t&plus;1}}-1" title="r_{i}^{t,k} = \frac{price_i^{t+1+k}}{price_i^{t+1}}-1" />
-</div>
-
-* In Qlib baseline, <img src="https://latex.codecogs.com/png.latex?\mathcal{T}_3" title="\mathcal{T}_3" />, is used in  <img src="https://latex.codecogs.com/png.latex?T_1" title="T_1" />.
-
-### Experimental Result
-You can find the experimental result of setting1 in the [paper](http://proceedings.mlr.press/v139/wu21e/wu21e.pdf) and the experimental result of setting2 in this [page](https://github.com/microsoft/qlib/tree/main/examples/benchmarks).
\ No newline at end of file
diff --git a/examples/benchmarks/TCTS/requirements.txt b/examples/benchmarks/TCTS/requirements.txt
deleted file mode 100644
index d2f37de6..00000000
--- a/examples/benchmarks/TCTS/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
\ No newline at end of file
diff --git a/examples/benchmarks/TCTS/workflow.png b/examples/benchmarks/TCTS/workflow.png
deleted file mode 100644
index 403a17de..00000000
Binary files a/examples/benchmarks/TCTS/workflow.png and /dev/null differ
diff --git a/examples/benchmarks/TCTS/workflow_config_tcts_Alpha360.yaml b/examples/benchmarks/TCTS/workflow_config_tcts_Alpha360.yaml
deleted file mode 100644
index 7adf9758..00000000
--- a/examples/benchmarks/TCTS/workflow_config_tcts_Alpha360.yaml
+++ /dev/null
@@ -1,96 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1", 
-            "Ref($close, -3) / Ref($close, -1) - 1", 
-            "Ref($close, -4) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TCTS
-        module_path: qlib.contrib.model.pytorch_tcts
-        kwargs:
-            d_feat: 6
-            hidden_size: 64
-            num_layers: 2
-            dropout: 0.3
-            n_epochs: 200
-            early_stop: 20
-            batch_size: 800
-            metric: loss
-            loss: mse
-            GPU: 0
-            fore_optimizer: adam
-            weight_optimizer: adam
-            output_dim: 3
-            fore_lr: 2e-3
-            weight_lr: 2e-3
-            steps: 3
-            target_label: 0
-            lowest_valid_performance: 0.993
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/TFT/README.md b/examples/benchmarks/TFT/README.md
deleted file mode 100644
index 991066b7..00000000
--- a/examples/benchmarks/TFT/README.md
+++ /dev/null
@@ -1,14 +0,0 @@
-# Temporal Fusion Transformers Benchmark
-## Source
-**Reference**: Lim, Bryan, et al. "Temporal fusion transformers for interpretable multi-horizon time series forecasting." arXiv preprint arXiv:1912.09363 (2019).
-
-**GitHub**: https://github.com/google-research/google-research/tree/master/tft
-
-## Run the Workflow
-Users can follow the ``workflow_by_code_tft.py`` to run the benchmark. 
-
-### Notes
-1. Please be **aware** that this script can only support `Python 3.6 - 3.7`.
-2. If the CUDA version on your machine is not 10.0, please remember to run the following commands `conda install anaconda cudatoolkit=10.0` and `conda install cudnn` on your machine.
-3. The model must run in GPU, or an error will be raised.
-4. New datasets should be registered in ``data_formatters``, for detail please visit the source.
diff --git a/examples/benchmarks/TFT/data_formatters/__init__.py b/examples/benchmarks/TFT/data_formatters/__init__.py
deleted file mode 100644
index 87ec3284..00000000
--- a/examples/benchmarks/TFT/data_formatters/__init__.py
+++ /dev/null
@@ -1,14 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/benchmarks/TFT/data_formatters/base.py b/examples/benchmarks/TFT/data_formatters/base.py
deleted file mode 100644
index 9cdce638..00000000
--- a/examples/benchmarks/TFT/data_formatters/base.py
+++ /dev/null
@@ -1,222 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Default data formatting functions for experiments.
-
-For new datasets, inherit form GenericDataFormatter and implement
-all abstract functions.
-
-These dataset-specific methods:
-1) Define the column and input types for tabular dataframes used by model
-2) Perform the necessary input feature engineering & normalisation steps
-3) Reverts the normalisation for predictions
-4) Are responsible for train, validation and test splits
-
-
-"""
-
-import abc
-import enum
-
-
-# Type definitions
-class DataTypes(enum.IntEnum):
-    """Defines numerical types of each column."""
-
-    REAL_VALUED = 0
-    CATEGORICAL = 1
-    DATE = 2
-
-
-class InputTypes(enum.IntEnum):
-    """Defines input types of each column."""
-
-    TARGET = 0
-    OBSERVED_INPUT = 1
-    KNOWN_INPUT = 2
-    STATIC_INPUT = 3
-    ID = 4  # Single column used as an entity identifier
-    TIME = 5  # Single column exclusively used as a time index
-
-
-class GenericDataFormatter(abc.ABC):
-    """Abstract base class for all data formatters.
-
-    User can implement the abstract methods below to perform dataset-specific
-    manipulations.
-
-    """
-
-    @abc.abstractmethod
-    def set_scalers(self, df):
-        """Calibrates scalers using the data supplied."""
-        raise NotImplementedError()
-
-    @abc.abstractmethod
-    def transform_inputs(self, df):
-        """Performs feature transformation."""
-        raise NotImplementedError()
-
-    @abc.abstractmethod
-    def format_predictions(self, df):
-        """Reverts any normalisation to give predictions in original scale."""
-        raise NotImplementedError()
-
-    @abc.abstractmethod
-    def split_data(self, df):
-        """Performs the default train, validation and test splits."""
-        raise NotImplementedError()
-
-    @property
-    @abc.abstractmethod
-    def _column_definition(self):
-        """Defines order, input type and data type of each column."""
-        raise NotImplementedError()
-
-    @abc.abstractmethod
-    def get_fixed_params(self):
-        """Defines the fixed parameters used by the model for training.
-
-        Requires the following keys:
-          'total_time_steps': Defines the total number of time steps used by TFT
-          'num_encoder_steps': Determines length of LSTM encoder (i.e. history)
-          'num_epochs': Maximum number of epochs for training
-          'early_stopping_patience': Early stopping param for keras
-          'multiprocessing_workers': # of cpus for data processing
-
-
-        Returns:
-          A dictionary of fixed parameters, e.g.:
-
-          fixed_params = {
-              'total_time_steps': 252 + 5,
-              'num_encoder_steps': 252,
-              'num_epochs': 100,
-              'early_stopping_patience': 5,
-              'multiprocessing_workers': 5,
-          }
-        """
-        raise NotImplementedError
-
-    # Shared functions across data-formatters
-    @property
-    def num_classes_per_cat_input(self):
-        """Returns number of categories per relevant input.
-
-        This is seqeuently required for keras embedding layers.
-        """
-        return self._num_classes_per_cat_input
-
-    def get_num_samples_for_calibration(self):
-        """Gets the default number of training and validation samples.
-
-        Use to sub-sample the data for network calibration and a value of -1 uses
-        all available samples.
-
-        Returns:
-          Tuple of (training samples, validation samples)
-        """
-        return -1, -1
-
-    def get_column_definition(self):
-        """Returns formatted column definition in order expected by the TFT."""
-
-        column_definition = self._column_definition
-
-        # Sanity checks first.
-        # Ensure only one ID and time column exist
-        def _check_single_column(input_type):
-            length = len([tup for tup in column_definition if tup[2] == input_type])
-
-            if length != 1:
-                raise ValueError("Illegal number of inputs ({}) of type {}".format(length, input_type))
-
-        _check_single_column(InputTypes.ID)
-        _check_single_column(InputTypes.TIME)
-
-        identifier = [tup for tup in column_definition if tup[2] == InputTypes.ID]
-        time = [tup for tup in column_definition if tup[2] == InputTypes.TIME]
-        real_inputs = [
-            tup
-            for tup in column_definition
-            if tup[1] == DataTypes.REAL_VALUED and tup[2] not in {InputTypes.ID, InputTypes.TIME}
-        ]
-        categorical_inputs = [
-            tup
-            for tup in column_definition
-            if tup[1] == DataTypes.CATEGORICAL and tup[2] not in {InputTypes.ID, InputTypes.TIME}
-        ]
-
-        return identifier + time + real_inputs + categorical_inputs
-
-    def _get_input_columns(self):
-        """Returns names of all input columns."""
-        return [tup[0] for tup in self.get_column_definition() if tup[2] not in {InputTypes.ID, InputTypes.TIME}]
-
-    def _get_tft_input_indices(self):
-        """Returns the relevant indexes and input sizes required by TFT."""
-
-        # Functions
-        def _extract_tuples_from_data_type(data_type, defn):
-            return [tup for tup in defn if tup[1] == data_type and tup[2] not in {InputTypes.ID, InputTypes.TIME}]
-
-        def _get_locations(input_types, defn):
-            return [i for i, tup in enumerate(defn) if tup[2] in input_types]
-
-        # Start extraction
-        column_definition = [
-            tup for tup in self.get_column_definition() if tup[2] not in {InputTypes.ID, InputTypes.TIME}
-        ]
-
-        categorical_inputs = _extract_tuples_from_data_type(DataTypes.CATEGORICAL, column_definition)
-        real_inputs = _extract_tuples_from_data_type(DataTypes.REAL_VALUED, column_definition)
-
-        locations = {
-            "input_size": len(self._get_input_columns()),
-            "output_size": len(_get_locations({InputTypes.TARGET}, column_definition)),
-            "category_counts": self.num_classes_per_cat_input,
-            "input_obs_loc": _get_locations({InputTypes.TARGET}, column_definition),
-            "static_input_loc": _get_locations({InputTypes.STATIC_INPUT}, column_definition),
-            "known_regular_inputs": _get_locations({InputTypes.STATIC_INPUT, InputTypes.KNOWN_INPUT}, real_inputs),
-            "known_categorical_inputs": _get_locations(
-                {InputTypes.STATIC_INPUT, InputTypes.KNOWN_INPUT}, categorical_inputs
-            ),
-        }
-
-        return locations
-
-    def get_experiment_params(self):
-        """Returns fixed model parameters for experiments."""
-
-        required_keys = [
-            "total_time_steps",
-            "num_encoder_steps",
-            "num_epochs",
-            "early_stopping_patience",
-            "multiprocessing_workers",
-        ]
-
-        fixed_params = self.get_fixed_params()
-
-        for k in required_keys:
-            if k not in fixed_params:
-                raise ValueError("Field {}".format(k) + " missing from fixed parameter definitions!")
-
-        fixed_params["column_definition"] = self.get_column_definition()
-
-        fixed_params.update(self._get_tft_input_indices())
-
-        return fixed_params
diff --git a/examples/benchmarks/TFT/data_formatters/qlib_Alpha158.py b/examples/benchmarks/TFT/data_formatters/qlib_Alpha158.py
deleted file mode 100644
index a2afcc81..00000000
--- a/examples/benchmarks/TFT/data_formatters/qlib_Alpha158.py
+++ /dev/null
@@ -1,230 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Custom formatting functions for Alpha158 dataset.
-
-Defines dataset specific column definitions and data transformations.
-"""
-
-import data_formatters.base
-import libs.utils as utils
-import sklearn.preprocessing
-
-GenericDataFormatter = data_formatters.base.GenericDataFormatter
-DataTypes = data_formatters.base.DataTypes
-InputTypes = data_formatters.base.InputTypes
-
-
-class Alpha158Formatter(GenericDataFormatter):
-    """Defines and formats data for the Alpha158 dataset.
-
-    Attributes:
-      column_definition: Defines input and data type of column used in the
-        experiment.
-      identifiers: Entity identifiers used in experiments.
-    """
-
-    _column_definition = [
-        ("instrument", DataTypes.CATEGORICAL, InputTypes.ID),
-        ("LABEL0", DataTypes.REAL_VALUED, InputTypes.TARGET),
-        ("date", DataTypes.DATE, InputTypes.TIME),
-        ("month", DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),
-        ("day_of_week", DataTypes.CATEGORICAL, InputTypes.KNOWN_INPUT),
-        # Selected features
-        ("RESI5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("WVMA5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("RSQR5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("KLEN", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("RSQR10", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORR5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORD5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORR10", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("ROC60", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("RESI10", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("VSTD5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("RSQR60", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORR60", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("WVMA60", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("STD5", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("RSQR20", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORD60", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORD10", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("CORR20", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("KLOW", DataTypes.REAL_VALUED, InputTypes.OBSERVED_INPUT),
-        ("const", DataTypes.CATEGORICAL, InputTypes.STATIC_INPUT),
-    ]
-
-    def __init__(self):
-        """Initialises formatter."""
-
-        self.identifiers = None
-        self._real_scalers = None
-        self._cat_scalers = None
-        self._target_scaler = None
-        self._num_classes_per_cat_input = None
-
-    def split_data(self, df, valid_boundary=2016, test_boundary=2018):
-        """Splits data frame into training-validation-test data frames.
-
-        This also calibrates scaling object, and transforms data for each split.
-
-        Args:
-          df: Source data frame to split.
-          valid_boundary: Starting year for validation data
-          test_boundary: Starting year for test data
-
-        Returns:
-          Tuple of transformed (train, valid, test) data.
-        """
-
-        print("Formatting train-valid-test splits.")
-
-        index = df["year"]
-        train = df.loc[index < valid_boundary]
-        valid = df.loc[(index >= valid_boundary) & (index < test_boundary)]
-        test = df.loc[index >= test_boundary]
-
-        self.set_scalers(train)
-
-        return (self.transform_inputs(data) for data in [train, valid, test])
-
-    def set_scalers(self, df):
-        """Calibrates scalers using the data supplied.
-
-        Args:
-          df: Data to use to calibrate scalers.
-        """
-        print("Setting scalers with training data...")
-
-        column_definitions = self.get_column_definition()
-        id_column = utils.get_single_col_by_input_type(InputTypes.ID, column_definitions)
-        target_column = utils.get_single_col_by_input_type(InputTypes.TARGET, column_definitions)
-
-        # Extract identifiers in case required
-        self.identifiers = list(df[id_column].unique())
-
-        # Format real scalers
-        real_inputs = utils.extract_cols_from_data_type(
-            DataTypes.REAL_VALUED, column_definitions, {InputTypes.ID, InputTypes.TIME}
-        )
-
-        data = df[real_inputs].values
-        self._real_scalers = sklearn.preprocessing.StandardScaler().fit(data)
-        self._target_scaler = sklearn.preprocessing.StandardScaler().fit(
-            df[[target_column]].values
-        )  # used for predictions
-
-        # Format categorical scalers
-        categorical_inputs = utils.extract_cols_from_data_type(
-            DataTypes.CATEGORICAL, column_definitions, {InputTypes.ID, InputTypes.TIME}
-        )
-
-        categorical_scalers = {}
-        num_classes = []
-        for col in categorical_inputs:
-            # Set all to str so that we don't have mixed integer/string columns
-            srs = df[col].apply(str)
-            categorical_scalers[col] = sklearn.preprocessing.LabelEncoder().fit(srs.values)
-            num_classes.append(srs.nunique())
-
-        # Set categorical scaler outputs
-        self._cat_scalers = categorical_scalers
-        self._num_classes_per_cat_input = num_classes
-
-    def transform_inputs(self, df):
-        """Performs feature transformations.
-
-        This includes both feature engineering, preprocessing and normalisation.
-
-        Args:
-          df: Data frame to transform.
-
-        Returns:
-          Transformed data frame.
-
-        """
-        output = df.copy()
-
-        if self._real_scalers is None and self._cat_scalers is None:
-            raise ValueError("Scalers have not been set!")
-
-        column_definitions = self.get_column_definition()
-
-        real_inputs = utils.extract_cols_from_data_type(
-            DataTypes.REAL_VALUED, column_definitions, {InputTypes.ID, InputTypes.TIME}
-        )
-        categorical_inputs = utils.extract_cols_from_data_type(
-            DataTypes.CATEGORICAL, column_definitions, {InputTypes.ID, InputTypes.TIME}
-        )
-
-        # Format real inputs
-        output[real_inputs] = self._real_scalers.transform(df[real_inputs].values)
-
-        # Format categorical inputs
-        for col in categorical_inputs:
-            string_df = df[col].apply(str)
-            output[col] = self._cat_scalers[col].transform(string_df)
-
-        return output
-
-    def format_predictions(self, predictions):
-        """Reverts any normalisation to give predictions in original scale.
-
-        Args:
-          predictions: Dataframe of model predictions.
-
-        Returns:
-          Data frame of unnormalised predictions.
-        """
-        output = predictions.copy()
-
-        column_names = predictions.columns
-
-        for col in column_names:
-            if col not in {"forecast_time", "identifier"}:
-                # Using [col] is for aligning with the format when fitting
-                output[col] = self._target_scaler.inverse_transform(predictions[[col]])
-
-        return output
-
-    # Default params
-    def get_fixed_params(self):
-        """Returns fixed model parameters for experiments."""
-
-        fixed_params = {
-            "total_time_steps": 6 + 6,
-            "num_encoder_steps": 6,
-            "num_epochs": 100,
-            "early_stopping_patience": 10,
-            "multiprocessing_workers": 5,
-        }
-
-        return fixed_params
-
-    def get_default_model_params(self):
-        """Returns default optimised model parameters."""
-
-        model_params = {
-            "dropout_rate": 0.4,
-            "hidden_layer_size": 160,
-            "learning_rate": 0.0001,
-            "minibatch_size": 128,
-            "max_gradient_norm": 0.0135,
-            "num_heads": 1,
-            "stack_size": 1,
-        }
-
-        return model_params
diff --git a/examples/benchmarks/TFT/expt_settings/__init__.py b/examples/benchmarks/TFT/expt_settings/__init__.py
deleted file mode 100644
index 87ec3284..00000000
--- a/examples/benchmarks/TFT/expt_settings/__init__.py
+++ /dev/null
@@ -1,14 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/benchmarks/TFT/expt_settings/configs.py b/examples/benchmarks/TFT/expt_settings/configs.py
deleted file mode 100644
index 55eb32a0..00000000
--- a/examples/benchmarks/TFT/expt_settings/configs.py
+++ /dev/null
@@ -1,94 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Default configs for TFT experiments.
-
-Contains the default output paths for data, serialised models and predictions
-for the main experiments used in the publication.
-"""
-
-import os
-
-import data_formatters.qlib_Alpha158
-
-
-class ExperimentConfig:
-    """Defines experiment configs and paths to outputs.
-
-    Attributes:
-      root_folder: Root folder to contain all experimental outputs.
-      experiment: Name of experiment to run.
-      data_folder: Folder to store data for experiment.
-      model_folder: Folder to store serialised models.
-      results_folder: Folder to store results.
-      data_csv_path: Path to primary data csv file used in experiment.
-      hyperparam_iterations: Default number of random search iterations for
-        experiment.
-    """
-
-    default_experiments = ["Alpha158"]
-
-    def __init__(self, experiment="volatility", root_folder=None):
-        """Creates configs based on default experiment chosen.
-
-        Args:
-          experiment: Name of experiment.
-          root_folder: Root folder to save all outputs of training.
-        """
-
-        if experiment not in self.default_experiments:
-            raise ValueError("Unrecognised experiment={}".format(experiment))
-
-        # Defines all relevant paths
-        if root_folder is None:
-            root_folder = os.path.join(os.path.dirname(os.path.realpath(__file__)), "..", "outputs")
-            print("Using root folder {}".format(root_folder))
-
-        self.root_folder = root_folder
-        self.experiment = experiment
-        self.data_folder = os.path.join(root_folder, "data", experiment)
-        self.model_folder = os.path.join(root_folder, "saved_models", experiment)
-        self.results_folder = os.path.join(root_folder, "results", experiment)
-
-        # Creates folders if they don't exist
-        for relevant_directory in [self.root_folder, self.data_folder, self.model_folder, self.results_folder]:
-            if not os.path.exists(relevant_directory):
-                os.makedirs(relevant_directory)
-
-    @property
-    def data_csv_path(self):
-        csv_map = {
-            "Alpha158": "Alpha158.csv",
-        }
-
-        return os.path.join(self.data_folder, csv_map[self.experiment])
-
-    @property
-    def hyperparam_iterations(self):
-        return 240 if self.experiment == "volatility" else 60
-
-    def make_data_formatter(self):
-        """Gets a data formatter object for experiment.
-
-        Returns:
-          Default DataFormatter per experiment.
-        """
-
-        data_formatter_class = {
-            "Alpha158": data_formatters.qlib_Alpha158.Alpha158Formatter,
-        }
-
-        return data_formatter_class[self.experiment]()
diff --git a/examples/benchmarks/TFT/libs/__init__.py b/examples/benchmarks/TFT/libs/__init__.py
deleted file mode 100644
index 87ec3284..00000000
--- a/examples/benchmarks/TFT/libs/__init__.py
+++ /dev/null
@@ -1,14 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
diff --git a/examples/benchmarks/TFT/libs/hyperparam_opt.py b/examples/benchmarks/TFT/libs/hyperparam_opt.py
deleted file mode 100644
index 86f587d7..00000000
--- a/examples/benchmarks/TFT/libs/hyperparam_opt.py
+++ /dev/null
@@ -1,428 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Classes used for hyperparameter optimisation.
-
-Two main classes exist:
-1) HyperparamOptManager used for optimisation on a single machine/GPU.
-2) DistributedHyperparamOptManager for multiple GPUs on different machines.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import collections
-import os
-import shutil
-import libs.utils as utils
-import numpy as np
-import pandas as pd
-
-Deque = collections.deque
-
-
-class HyperparamOptManager:
-    """Manages hyperparameter optimisation using random search for a single GPU.
-
-    Attributes:
-      param_ranges: Discrete hyperparameter range for random search.
-      results: Dataframe of validation results.
-      fixed_params: Fixed model parameters per experiment.
-      saved_params: Dataframe of parameters trained.
-      best_score: Minimum validation loss observed thus far.
-      optimal_name: Key to best configuration.
-      hyperparam_folder: Where to save optimisation outputs.
-    """
-
-    def __init__(self, param_ranges, fixed_params, model_folder, override_w_fixed_params=True):
-        """Instantiates model.
-
-        Args:
-          param_ranges: Discrete hyperparameter range for random search.
-          fixed_params: Fixed model parameters per experiment.
-          model_folder: Folder to store optimisation artifacts.
-          override_w_fixed_params: Whether to override serialsed fixed model
-            parameters with new supplied values.
-        """
-
-        self.param_ranges = param_ranges
-
-        self._max_tries = 1000
-        self.results = pd.DataFrame()
-        self.fixed_params = fixed_params
-        self.saved_params = pd.DataFrame()
-
-        self.best_score = np.Inf
-        self.optimal_name = ""
-
-        # Setup
-        # Create folder for saving if its not there
-        self.hyperparam_folder = model_folder
-        utils.create_folder_if_not_exist(self.hyperparam_folder)
-
-        self._override_w_fixed_params = override_w_fixed_params
-
-    def load_results(self):
-        """Loads results from previous hyperparameter optimisation.
-
-        Returns:
-          A boolean indicating if previous results can be loaded.
-        """
-        print("Loading results from", self.hyperparam_folder)
-
-        results_file = os.path.join(self.hyperparam_folder, "results.csv")
-        params_file = os.path.join(self.hyperparam_folder, "params.csv")
-
-        if os.path.exists(results_file) and os.path.exists(params_file):
-            self.results = pd.read_csv(results_file, index_col=0)
-            self.saved_params = pd.read_csv(params_file, index_col=0)
-
-            if not self.results.empty:
-                self.results.at["loss"] = self.results.loc["loss"].apply(float)
-                self.best_score = self.results.loc["loss"].min()
-
-                is_optimal = self.results.loc["loss"] == self.best_score
-                self.optimal_name = self.results.T[is_optimal].index[0]
-
-                return True
-
-        return False
-
-    def _get_params_from_name(self, name):
-        """Returns previously saved parameters given a key."""
-        params = self.saved_params
-
-        selected_params = dict(params[name])
-
-        if self._override_w_fixed_params:
-            for k in self.fixed_params:
-                selected_params[k] = self.fixed_params[k]
-
-        return selected_params
-
-    def get_best_params(self):
-        """Returns the optimal hyperparameters thus far."""
-
-        optimal_name = self.optimal_name
-
-        return self._get_params_from_name(optimal_name)
-
-    def clear(self):
-        """Clears all previous results and saved parameters."""
-        shutil.rmtree(self.hyperparam_folder)
-        os.makedirs(self.hyperparam_folder)
-        self.results = pd.DataFrame()
-        self.saved_params = pd.DataFrame()
-
-    def _check_params(self, params):
-        """Checks that parameter map is properly defined."""
-
-        valid_fields = list(self.param_ranges.keys()) + list(self.fixed_params.keys())
-        invalid_fields = [k for k in params if k not in valid_fields]
-        missing_fields = [k for k in valid_fields if k not in params]
-
-        if invalid_fields:
-            raise ValueError("Invalid Fields Found {} - Valid ones are {}".format(invalid_fields, valid_fields))
-        if missing_fields:
-            raise ValueError("Missing Fields Found {} - Valid ones are {}".format(missing_fields, valid_fields))
-
-    def _get_name(self, params):
-        """Returns a unique key for the supplied set of params."""
-
-        self._check_params(params)
-
-        fields = list(params.keys())
-        fields.sort()
-
-        return "_".join([str(params[k]) for k in fields])
-
-    def get_next_parameters(self, ranges_to_skip=None):
-        """Returns the next set of parameters to optimise.
-
-        Args:
-          ranges_to_skip: Explicitly defines a set of keys to skip.
-        """
-        if ranges_to_skip is None:
-            ranges_to_skip = set(self.results.index)
-
-        if not isinstance(self.param_ranges, dict):
-            raise ValueError("Only works for random search!")
-
-        param_range_keys = list(self.param_ranges.keys())
-        param_range_keys.sort()
-
-        def _get_next():
-            """Returns next hyperparameter set per try."""
-
-            parameters = {k: np.random.choice(self.param_ranges[k]) for k in param_range_keys}
-
-            # Adds fixed params
-            for k in self.fixed_params:
-                parameters[k] = self.fixed_params[k]
-
-            return parameters
-
-        for _ in range(self._max_tries):
-            parameters = _get_next()
-            name = self._get_name(parameters)
-
-            if name not in ranges_to_skip:
-                return parameters
-
-        raise ValueError("Exceeded max number of hyperparameter searches!!")
-
-    def update_score(self, parameters, loss, model, info=""):
-        """Updates the results from last optimisation run.
-
-        Args:
-          parameters: Hyperparameters used in optimisation.
-          loss: Validation loss obtained.
-          model: Model to serialised if required.
-          info: Any ancillary information to tag on to results.
-
-        Returns:
-          Boolean flag indicating if the model is the best seen so far.
-        """
-
-        if np.isnan(loss):
-            loss = np.Inf
-
-        if not os.path.isdir(self.hyperparam_folder):
-            os.makedirs(self.hyperparam_folder)
-
-        name = self._get_name(parameters)
-
-        is_optimal = self.results.empty or loss < self.best_score
-
-        # save the first model
-        if is_optimal:
-            # Try saving first, before updating info
-            if model is not None:
-                print("Optimal model found, updating")
-                model.save(self.hyperparam_folder)
-            self.best_score = loss
-            self.optimal_name = name
-
-        self.results[name] = pd.Series({"loss": loss, "info": info})
-        self.saved_params[name] = pd.Series(parameters)
-
-        self.results.to_csv(os.path.join(self.hyperparam_folder, "results.csv"))
-        self.saved_params.to_csv(os.path.join(self.hyperparam_folder, "params.csv"))
-
-        return is_optimal
-
-
-class DistributedHyperparamOptManager(HyperparamOptManager):
-    """Manages distributed hyperparameter optimisation across many gpus."""
-
-    def __init__(
-        self,
-        param_ranges,
-        fixed_params,
-        root_model_folder,
-        worker_number,
-        search_iterations=1000,
-        num_iterations_per_worker=5,
-        clear_serialised_params=False,
-    ):
-        """Instantiates optimisation manager.
-
-        This hyperparameter optimisation pre-generates #search_iterations
-        hyperparameter combinations and serialises them
-        at the start. At runtime, each worker goes through their own set of
-        parameter ranges. The pregeneration
-        allows for multiple workers to run in parallel on different machines without
-        resulting in parameter overlaps.
-
-        Args:
-          param_ranges: Discrete hyperparameter range for random search.
-          fixed_params: Fixed model parameters per experiment.
-          root_model_folder: Folder to store optimisation artifacts.
-          worker_number: Worker index defining which set of hyperparameters to
-            test.
-          search_iterations: Maximum number of random search iterations.
-          num_iterations_per_worker: How many iterations are handled per worker.
-          clear_serialised_params: Whether to regenerate hyperparameter
-            combinations.
-        """
-
-        max_workers = int(np.ceil(search_iterations / num_iterations_per_worker))
-
-        # Sanity checks
-        if worker_number > max_workers:
-            raise ValueError(
-                "Worker number ({}) cannot be larger than the total number of workers!".format(max_workers)
-            )
-        if worker_number > search_iterations:
-            raise ValueError(
-                "Worker number ({}) cannot be larger than the max search iterations ({})!".format(
-                    worker_number, search_iterations
-                )
-            )
-
-        print("*** Creating hyperparameter manager for worker {} ***".format(worker_number))
-
-        hyperparam_folder = os.path.join(root_model_folder, str(worker_number))
-        super().__init__(param_ranges, fixed_params, hyperparam_folder, override_w_fixed_params=True)
-
-        serialised_ranges_folder = os.path.join(root_model_folder, "hyperparams")
-        if clear_serialised_params:
-            print("Regenerating hyperparameter list")
-            if os.path.exists(serialised_ranges_folder):
-                shutil.rmtree(serialised_ranges_folder)
-
-        utils.create_folder_if_not_exist(serialised_ranges_folder)
-
-        self.serialised_ranges_path = os.path.join(serialised_ranges_folder, "ranges_{}.csv".format(search_iterations))
-        self.hyperparam_folder = hyperparam_folder  # override
-        self.worker_num = worker_number
-        self.total_search_iterations = search_iterations
-        self.num_iterations_per_worker = num_iterations_per_worker
-        self.global_hyperparam_df = self.load_serialised_hyperparam_df()
-        self.worker_search_queue = self._get_worker_search_queue()
-
-    @property
-    def optimisation_completed(self):
-        return False if self.worker_search_queue else True
-
-    def get_next_parameters(self):
-        """Returns next dictionary of hyperparameters to optimise."""
-        param_name = self.worker_search_queue.pop()
-
-        params = self.global_hyperparam_df.loc[param_name, :].to_dict()
-
-        # Always override!
-        for k in self.fixed_params:
-            print("Overriding saved {}: {}".format(k, self.fixed_params[k]))
-
-            params[k] = self.fixed_params[k]
-
-        return params
-
-    def load_serialised_hyperparam_df(self):
-        """Loads serialsed hyperparameter ranges from file.
-
-        Returns:
-          DataFrame containing hyperparameter combinations.
-        """
-        print(
-            "Loading params for {} search iterations form {}".format(
-                self.total_search_iterations, self.serialised_ranges_path
-            )
-        )
-
-        if os.path.exists(self.serialised_ranges_folder):
-            df = pd.read_csv(self.serialised_ranges_path, index_col=0)
-        else:
-            print("Unable to load - regenerating search ranges instead")
-            df = self.update_serialised_hyperparam_df()
-
-        return df
-
-    def update_serialised_hyperparam_df(self):
-        """Regenerates hyperparameter combinations and saves to file.
-
-        Returns:
-          DataFrame containing hyperparameter combinations.
-        """
-        search_df = self._generate_full_hyperparam_df()
-
-        print(
-            "Serialising params for {} search iterations to {}".format(
-                self.total_search_iterations, self.serialised_ranges_path
-            )
-        )
-
-        search_df.to_csv(self.serialised_ranges_path)
-
-        return search_df
-
-    def _generate_full_hyperparam_df(self):
-        """Generates actual hyperparameter combinations.
-
-        Returns:
-          DataFrame containing hyperparameter combinations.
-        """
-
-        np.random.seed(131)  # for reproducibility of hyperparam list
-
-        name_list = []
-        param_list = []
-        for _ in range(self.total_search_iterations):
-            params = super().get_next_parameters(name_list)
-
-            name = self._get_name(params)
-
-            name_list.append(name)
-            param_list.append(params)
-
-        full_search_df = pd.DataFrame(param_list, index=name_list)
-
-        return full_search_df
-
-    def clear(self):  # reset when cleared
-        """Clears results for hyperparameter manager and resets."""
-        super().clear()
-        self.worker_search_queue = self._get_worker_search_queue()
-
-    def load_results(self):
-        """Load results from file and queue parameter combinations to try.
-
-        Returns:
-          Boolean indicating if results were successfully loaded.
-        """
-        success = super().load_results()
-
-        if success:
-            self.worker_search_queue = self._get_worker_search_queue()
-
-        return success
-
-    def _get_worker_search_queue(self):
-        """Generates the queue of param combinations for current worker.
-
-        Returns:
-          Queue of hyperparameter combinations outstanding.
-        """
-        global_df = self.assign_worker_numbers(self.global_hyperparam_df)
-        worker_df = global_df[global_df["worker"] == self.worker_num]
-
-        left_overs = [s for s in worker_df.index if s not in self.results.columns]
-
-        return Deque(left_overs)
-
-    def assign_worker_numbers(self, df):
-        """Updates parameter combinations with the index of the worker used.
-
-        Args:
-          df: DataFrame of parameter combinations.
-
-        Returns:
-          Updated DataFrame with worker number.
-        """
-        output = df.copy()
-
-        n = self.total_search_iterations
-        batch_size = self.num_iterations_per_worker
-
-        max_worker_num = int(np.ceil(n / batch_size))
-
-        worker_idx = np.concatenate([np.tile(i + 1, self.num_iterations_per_worker) for i in range(max_worker_num)])
-
-        output["worker"] = worker_idx[: len(output)]
-
-        return output
diff --git a/examples/benchmarks/TFT/libs/tft_model.py b/examples/benchmarks/TFT/libs/tft_model.py
deleted file mode 100644
index 2a1a2fa1..00000000
--- a/examples/benchmarks/TFT/libs/tft_model.py
+++ /dev/null
@@ -1,1277 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Temporal Fusion Transformer Model.
-
-Contains the full TFT architecture and associated components. Defines functions
-for training, evaluation and prediction using simple Pandas Dataframe inputs.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import gc
-import json
-import os
-import shutil
-
-import data_formatters.base
-import libs.utils as utils
-import numpy as np
-import pandas as pd
-import tensorflow as tf
-
-# Layer definitions.
-concat = tf.keras.backend.concatenate
-stack = tf.keras.backend.stack
-K = tf.keras.backend
-Add = tf.keras.layers.Add
-LayerNorm = tf.keras.layers.LayerNormalization
-Dense = tf.keras.layers.Dense
-Multiply = tf.keras.layers.Multiply
-Dropout = tf.keras.layers.Dropout
-Activation = tf.keras.layers.Activation
-Lambda = tf.keras.layers.Lambda
-
-# Default input types.
-InputTypes = data_formatters.base.InputTypes
-
-
-# Layer utility functions.
-def linear_layer(size, activation=None, use_time_distributed=False, use_bias=True):
-    """Returns simple Keras linear layer.
-
-    Args:
-      size: Output size
-      activation: Activation function to apply if required
-      use_time_distributed: Whether to apply layer across time
-      use_bias: Whether bias should be included in layer
-    """
-    linear = tf.keras.layers.Dense(size, activation=activation, use_bias=use_bias)
-    if use_time_distributed:
-        linear = tf.keras.layers.TimeDistributed(linear)
-    return linear
-
-
-def apply_mlp(
-    inputs, hidden_size, output_size, output_activation=None, hidden_activation="tanh", use_time_distributed=False
-):
-    """Applies simple feed-forward network to an input.
-
-    Args:
-      inputs: MLP inputs
-      hidden_size: Hidden state size
-      output_size: Output size of MLP
-      output_activation: Activation function to apply on output
-      hidden_activation: Activation function to apply on input
-      use_time_distributed: Whether to apply across time
-
-    Returns:
-      Tensor for MLP outputs.
-    """
-    if use_time_distributed:
-        hidden = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(hidden_size, activation=hidden_activation))(
-            inputs
-        )
-        return tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(output_size, activation=output_activation))(hidden)
-    else:
-        hidden = tf.keras.layers.Dense(hidden_size, activation=hidden_activation)(inputs)
-        return tf.keras.layers.Dense(output_size, activation=output_activation)(hidden)
-
-
-def apply_gating_layer(x, hidden_layer_size, dropout_rate=None, use_time_distributed=True, activation=None):
-    """Applies a Gated Linear Unit (GLU) to an input.
-
-    Args:
-      x: Input to gating layer
-      hidden_layer_size: Dimension of GLU
-      dropout_rate: Dropout rate to apply if any
-      use_time_distributed: Whether to apply across time
-      activation: Activation function to apply to the linear feature transform if
-        necessary
-
-    Returns:
-      Tuple of tensors for: (GLU output, gate)
-    """
-
-    if dropout_rate is not None:
-        x = tf.keras.layers.Dropout(dropout_rate)(x)
-
-    if use_time_distributed:
-        activation_layer = tf.keras.layers.TimeDistributed(
-            tf.keras.layers.Dense(hidden_layer_size, activation=activation)
-        )(x)
-        gated_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(hidden_layer_size, activation="sigmoid"))(x)
-    else:
-        activation_layer = tf.keras.layers.Dense(hidden_layer_size, activation=activation)(x)
-        gated_layer = tf.keras.layers.Dense(hidden_layer_size, activation="sigmoid")(x)
-
-    return tf.keras.layers.Multiply()([activation_layer, gated_layer]), gated_layer
-
-
-def add_and_norm(x_list):
-    """Applies skip connection followed by layer normalisation.
-
-    Args:
-      x_list: List of inputs to sum for skip connection
-
-    Returns:
-      Tensor output from layer.
-    """
-    tmp = Add()(x_list)
-    tmp = LayerNorm()(tmp)
-    return tmp
-
-
-def gated_residual_network(
-    x,
-    hidden_layer_size,
-    output_size=None,
-    dropout_rate=None,
-    use_time_distributed=True,
-    additional_context=None,
-    return_gate=False,
-):
-    """Applies the gated residual network (GRN) as defined in paper.
-
-    Args:
-      x: Network inputs
-      hidden_layer_size: Internal state size
-      output_size: Size of output layer
-      dropout_rate: Dropout rate if dropout is applied
-      use_time_distributed: Whether to apply network across time dimension
-      additional_context: Additional context vector to use if relevant
-      return_gate: Whether to return GLU gate for diagnostic purposes
-
-    Returns:
-      Tuple of tensors for: (GRN output, GLU gate)
-    """
-
-    # Setup skip connection
-    if output_size is None:
-        output_size = hidden_layer_size
-        skip = x
-    else:
-        linear = Dense(output_size)
-        if use_time_distributed:
-            linear = tf.keras.layers.TimeDistributed(linear)
-        skip = linear(x)
-
-    # Apply feedforward network
-    hidden = linear_layer(hidden_layer_size, activation=None, use_time_distributed=use_time_distributed)(x)
-    if additional_context is not None:
-        hidden = hidden + linear_layer(
-            hidden_layer_size, activation=None, use_time_distributed=use_time_distributed, use_bias=False
-        )(additional_context)
-    hidden = tf.keras.layers.Activation("elu")(hidden)
-    hidden = linear_layer(hidden_layer_size, activation=None, use_time_distributed=use_time_distributed)(hidden)
-
-    gating_layer, gate = apply_gating_layer(
-        hidden, output_size, dropout_rate=dropout_rate, use_time_distributed=use_time_distributed, activation=None
-    )
-
-    if return_gate:
-        return add_and_norm([skip, gating_layer]), gate
-    else:
-        return add_and_norm([skip, gating_layer])
-
-
-# Attention Components.
-def get_decoder_mask(self_attn_inputs):
-    """Returns causal mask to apply for self-attention layer.
-
-    Args:
-      self_attn_inputs: Inputs to self attention layer to determine mask shape
-    """
-    len_s = tf.shape(self_attn_inputs)[1]
-    bs = tf.shape(self_attn_inputs)[:1]
-    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)
-    return mask
-
-
-class ScaledDotProductAttention:
-    """Defines scaled dot product attention layer.
-
-    Attributes:
-      dropout: Dropout rate to use
-      activation: Normalisation function for scaled dot product attention (e.g.
-        softmax by default)
-    """
-
-    def __init__(self, attn_dropout=0.0):
-        self.dropout = Dropout(attn_dropout)
-        self.activation = Activation("softmax")
-
-    def __call__(self, q, k, v, mask):
-        """Applies scaled dot product attention.
-
-        Args:
-          q: Queries
-          k: Keys
-          v: Values
-          mask: Masking if required -- sets softmax to very large value
-
-        Returns:
-          Tuple of (layer outputs, attention weights)
-        """
-        temper = tf.sqrt(tf.cast(tf.shape(k)[-1], dtype="float32"))
-        attn = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=[2, 2]) / temper)([q, k])  # shape=(batch, q, k)
-        if mask is not None:
-            mmask = Lambda(lambda x: (-1e9) * (1.0 - K.cast(x, "float32")))(mask)  # setting to infinity
-            attn = Add()([attn, mmask])
-        attn = self.activation(attn)
-        attn = self.dropout(attn)
-        output = Lambda(lambda x: K.batch_dot(x[0], x[1]))([attn, v])
-        return output, attn
-
-
-class InterpretableMultiHeadAttention:
-    """Defines interpretable multi-head attention layer.
-
-    Attributes:
-      n_head: Number of heads
-      d_k: Key/query dimensionality per head
-      d_v: Value dimensionality
-      dropout: Dropout rate to apply
-      qs_layers: List of queries across heads
-      ks_layers: List of keys across heads
-      vs_layers: List of values across heads
-      attention: Scaled dot product attention layer
-      w_o: Output weight matrix to project internal state to the original TFT
-        state size
-    """
-
-    def __init__(self, n_head, d_model, dropout):
-        """Initialises layer.
-
-        Args:
-          n_head: Number of heads
-          d_model: TFT state dimensionality
-          dropout: Dropout discard rate
-        """
-
-        self.n_head = n_head
-        self.d_k = self.d_v = d_k = d_v = d_model // n_head
-        self.dropout = dropout
-
-        self.qs_layers = []
-        self.ks_layers = []
-        self.vs_layers = []
-
-        # Use same value layer to facilitate interp
-        vs_layer = Dense(d_v, use_bias=False)
-
-        for _ in range(n_head):
-            self.qs_layers.append(Dense(d_k, use_bias=False))
-            self.ks_layers.append(Dense(d_k, use_bias=False))
-            self.vs_layers.append(vs_layer)  # use same vs_layer
-
-        self.attention = ScaledDotProductAttention()
-        self.w_o = Dense(d_model, use_bias=False)
-
-    def __call__(self, q, k, v, mask=None):
-        """Applies interpretable multihead attention.
-
-        Using T to denote the number of time steps fed into the transformer.
-
-        Args:
-          q: Query tensor of shape=(?, T, d_model)
-          k: Key of shape=(?, T, d_model)
-          v: Values of shape=(?, T, d_model)
-          mask: Masking if required with shape=(?, T, T)
-
-        Returns:
-          Tuple of (layer outputs, attention weights)
-        """
-        n_head = self.n_head
-
-        heads = []
-        attns = []
-        for i in range(n_head):
-            qs = self.qs_layers[i](q)
-            ks = self.ks_layers[i](k)
-            vs = self.vs_layers[i](v)
-            head, attn = self.attention(qs, ks, vs, mask)
-
-            head_dropout = Dropout(self.dropout)(head)
-            heads.append(head_dropout)
-            attns.append(attn)
-        head = K.stack(heads) if n_head > 1 else heads[0]
-        attn = K.stack(attns)
-
-        outputs = K.mean(head, axis=0) if n_head > 1 else head
-        outputs = self.w_o(outputs)
-        outputs = Dropout(self.dropout)(outputs)  # output dropout
-
-        return outputs, attn
-
-
-class TFTDataCache:
-    """Caches data for the TFT."""
-
-    _data_cache = {}
-
-    @classmethod
-    def update(cls, data, key):
-        """Updates cached data.
-
-        Args:
-          data: Source to update
-          key: Key to dictionary location
-        """
-        cls._data_cache[key] = data
-
-    @classmethod
-    def get(cls, key):
-        """Returns data stored at key location."""
-        return cls._data_cache[key].copy()
-
-    @classmethod
-    def contains(cls, key):
-        """Returns boolean indicating whether key is present in cache."""
-
-        return key in cls._data_cache
-
-
-# TFT model definitions.
-class TemporalFusionTransformer:
-    """Defines Temporal Fusion Transformer.
-
-    Attributes:
-      name: Name of model
-      time_steps: Total number of input time steps per forecast date (i.e. Width
-        of Temporal fusion decoder N)
-      input_size: Total number of inputs
-      output_size: Total number of outputs
-      category_counts: Number of categories per categorical variable
-      n_multiprocessing_workers: Number of workers to use for parallel
-        computations
-      column_definition: List of tuples of (string, DataType, InputType) that
-        define each column
-      quantiles: Quantiles to forecast for TFT
-      use_cudnn: Whether to use Keras CuDNNLSTM or standard LSTM layers
-      hidden_layer_size: Internal state size of TFT
-      dropout_rate: Dropout discard rate
-      max_gradient_norm: Maximum norm for gradient clipping
-      learning_rate: Initial learning rate of ADAM optimizer
-      minibatch_size: Size of minibatches for training
-      num_epochs: Maximum number of epochs for training
-      early_stopping_patience: Maximum number of iterations of non-improvement
-        before early stopping kicks in
-      num_encoder_steps: Size of LSTM encoder -- i.e. number of past time steps
-        before forecast date to use
-      num_stacks: Number of self-attention layers to apply (default is 1 for basic
-        TFT)
-      num_heads: Number of heads for interpretable mulit-head attention
-      model: Keras model for TFT
-    """
-
-    def __init__(self, raw_params, use_cudnn=False):
-        """Builds TFT from parameters.
-
-        Args:
-          raw_params: Parameters to define TFT
-          use_cudnn: Whether to use CUDNN GPU optimised LSTM
-        """
-
-        self.name = self.__class__.__name__
-
-        params = dict(raw_params)  # copy locally
-
-        # Data parameters
-        self.time_steps = int(params["total_time_steps"])
-        self.input_size = int(params["input_size"])
-        self.output_size = int(params["output_size"])
-        self.category_counts = json.loads(str(params["category_counts"]))
-        self.n_multiprocessing_workers = int(params["multiprocessing_workers"])
-
-        # Relevant indices for TFT
-        self._input_obs_loc = json.loads(str(params["input_obs_loc"]))
-        self._static_input_loc = json.loads(str(params["static_input_loc"]))
-        self._known_regular_input_idx = json.loads(str(params["known_regular_inputs"]))
-        self._known_categorical_input_idx = json.loads(str(params["known_categorical_inputs"]))
-
-        self.column_definition = params["column_definition"]
-
-        # Network params
-        self.quantiles = [0.1, 0.5, 0.9]
-        self.use_cudnn = use_cudnn  # Whether to use GPU optimised LSTM
-        self.hidden_layer_size = int(params["hidden_layer_size"])
-        self.dropout_rate = float(params["dropout_rate"])
-        self.max_gradient_norm = float(params["max_gradient_norm"])
-        self.learning_rate = float(params["learning_rate"])
-        self.minibatch_size = int(params["minibatch_size"])
-        self.num_epochs = int(params["num_epochs"])
-        self.early_stopping_patience = int(params["early_stopping_patience"])
-
-        self.num_encoder_steps = int(params["num_encoder_steps"])
-        self.num_stacks = int(params["stack_size"])
-        self.num_heads = int(params["num_heads"])
-
-        # Serialisation options
-        self._temp_folder = os.path.join(params["model_folder"], "tmp")
-        self.reset_temp_folder()
-
-        # Extra components to store Tensorflow nodes for attention computations
-        self._input_placeholder = None
-        self._attention_components = None
-        self._prediction_parts = None
-
-        print("*** {} params ***".format(self.name))
-        for k in params:
-            print("# {} = {}".format(k, params[k]))
-
-        # Build model
-        self.model = self.build_model()
-
-    def get_tft_embeddings(self, all_inputs):
-        """Transforms raw inputs to embeddings.
-
-        Applies linear transformation onto continuous variables and uses embeddings
-        for categorical variables.
-
-        Args:
-          all_inputs: Inputs to transform
-
-        Returns:
-          Tensors for transformed inputs.
-        """
-
-        time_steps = self.time_steps
-
-        # Sanity checks
-        for i in self._known_regular_input_idx:
-            if i in self._input_obs_loc:
-                raise ValueError("Observation cannot be known a priori!")
-        for i in self._input_obs_loc:
-            if i in self._static_input_loc:
-                raise ValueError("Observation cannot be static!")
-
-        if all_inputs.get_shape().as_list()[-1] != self.input_size:
-            raise ValueError(
-                "Illegal number of inputs! Inputs observed={}, expected={}".format(
-                    all_inputs.get_shape().as_list()[-1], self.input_size
-                )
-            )
-
-        num_categorical_variables = len(self.category_counts)
-        num_regular_variables = self.input_size - num_categorical_variables
-
-        embedding_sizes = [self.hidden_layer_size for i, size in enumerate(self.category_counts)]
-
-        embeddings = []
-        for i in range(num_categorical_variables):
-            embedding = tf.keras.Sequential(
-                [
-                    tf.keras.layers.InputLayer([time_steps]),
-                    tf.keras.layers.Embedding(
-                        self.category_counts[i], embedding_sizes[i], input_length=time_steps, dtype=tf.float32
-                    ),
-                ]
-            )
-            embeddings.append(embedding)
-
-        regular_inputs, categorical_inputs = (
-            all_inputs[:, :, :num_regular_variables],
-            all_inputs[:, :, num_regular_variables:],
-        )
-
-        embedded_inputs = [embeddings[i](categorical_inputs[Ellipsis, i]) for i in range(num_categorical_variables)]
-
-        # Static inputs
-        if self._static_input_loc:
-            static_inputs = [
-                tf.keras.layers.Dense(self.hidden_layer_size)(regular_inputs[:, 0, i : i + 1])
-                for i in range(num_regular_variables)
-                if i in self._static_input_loc
-            ] + [
-                embedded_inputs[i][:, 0, :]
-                for i in range(num_categorical_variables)
-                if i + num_regular_variables in self._static_input_loc
-            ]
-            static_inputs = tf.keras.backend.stack(static_inputs, axis=1)
-
-        else:
-            static_inputs = None
-
-        def convert_real_to_embedding(x):
-            """Applies linear transformation for time-varying inputs."""
-            return tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.hidden_layer_size))(x)
-
-        # Targets
-        obs_inputs = tf.keras.backend.stack(
-            [convert_real_to_embedding(regular_inputs[Ellipsis, i : i + 1]) for i in self._input_obs_loc], axis=-1
-        )
-
-        # Observed (a prioir unknown) inputs
-        wired_embeddings = []
-        for i in range(num_categorical_variables):
-            if i not in self._known_categorical_input_idx and i + num_regular_variables not in self._input_obs_loc:
-                e = embeddings[i](categorical_inputs[:, :, i])
-                wired_embeddings.append(e)
-
-        unknown_inputs = []
-        for i in range(regular_inputs.shape[-1]):
-            if i not in self._known_regular_input_idx and i not in self._input_obs_loc:
-                e = convert_real_to_embedding(regular_inputs[Ellipsis, i : i + 1])
-                unknown_inputs.append(e)
-
-        if unknown_inputs + wired_embeddings:
-            unknown_inputs = tf.keras.backend.stack(unknown_inputs + wired_embeddings, axis=-1)
-        else:
-            unknown_inputs = None
-
-        # A priori known inputs
-        known_regular_inputs = [
-            convert_real_to_embedding(regular_inputs[Ellipsis, i : i + 1])
-            for i in self._known_regular_input_idx
-            if i not in self._static_input_loc
-        ]
-        known_categorical_inputs = [
-            embedded_inputs[i]
-            for i in self._known_categorical_input_idx
-            if i + num_regular_variables not in self._static_input_loc
-        ]
-
-        known_combined_layer = tf.keras.backend.stack(known_regular_inputs + known_categorical_inputs, axis=-1)
-
-        return unknown_inputs, known_combined_layer, obs_inputs, static_inputs
-
-    def _get_single_col_by_type(self, input_type):
-        """Returns name of single column for input type."""
-
-        return utils.get_single_col_by_input_type(input_type, self.column_definition)
-
-    def training_data_cached(self):
-        """Returns boolean indicating if training data has been cached."""
-
-        return TFTDataCache.contains("train") and TFTDataCache.contains("valid")
-
-    def cache_batched_data(self, data, cache_key, num_samples=-1):
-        """Batches and caches data once for using during training.
-
-        Args:
-          data: Data to batch and cache
-          cache_key: Key used for cache
-          num_samples: Maximum number of samples to extract (-1 to use all data)
-        """
-
-        if num_samples > 0:
-            TFTDataCache.update(self._batch_sampled_data(data, max_samples=num_samples), cache_key)
-        else:
-            TFTDataCache.update(self._batch_data(data), cache_key)
-
-        print('Cached data "{}" updated'.format(cache_key))
-
-    def _batch_sampled_data(self, data, max_samples):
-        """Samples segments into a compatible format.
-
-        Args:
-          data: Sources data to sample and batch
-          max_samples: Maximum number of samples in batch
-
-        Returns:
-          Dictionary of batched data with the maximum samples specified.
-        """
-
-        if max_samples < 1:
-            raise ValueError("Illegal number of samples specified! samples={}".format(max_samples))
-
-        id_col = self._get_single_col_by_type(InputTypes.ID)
-        time_col = self._get_single_col_by_type(InputTypes.TIME)
-
-        data.sort_values(by=[id_col, time_col], inplace=True)
-
-        print("Getting valid sampling locations.")
-        valid_sampling_locations = []
-        split_data_map = {}
-        for identifier, df in data.groupby(id_col):
-            print("Getting locations for {}".format(identifier))
-            num_entries = len(df)
-            if num_entries >= self.time_steps:
-                valid_sampling_locations += [
-                    (identifier, self.time_steps + i) for i in range(num_entries - self.time_steps + 1)
-                ]
-            split_data_map[identifier] = df
-
-        inputs = np.zeros((max_samples, self.time_steps, self.input_size))
-        outputs = np.zeros((max_samples, self.time_steps, self.output_size))
-        time = np.empty((max_samples, self.time_steps, 1), dtype=object)
-        identifiers = np.empty((max_samples, self.time_steps, 1), dtype=object)
-
-        if max_samples > 0 and len(valid_sampling_locations) > max_samples:
-            print("Extracting {} samples...".format(max_samples))
-            ranges = [
-                valid_sampling_locations[i]
-                for i in np.random.choice(len(valid_sampling_locations), max_samples, replace=False)
-            ]
-        else:
-            print("Max samples={} exceeds # available segments={}".format(max_samples, len(valid_sampling_locations)))
-            ranges = valid_sampling_locations
-
-        id_col = self._get_single_col_by_type(InputTypes.ID)
-        time_col = self._get_single_col_by_type(InputTypes.TIME)
-        target_col = self._get_single_col_by_type(InputTypes.TARGET)
-        input_cols = [tup[0] for tup in self.column_definition if tup[2] not in {InputTypes.ID, InputTypes.TIME}]
-
-        for i, tup in enumerate(ranges):
-            if (i + 1 % 1000) == 0:
-                print(i + 1, "of", max_samples, "samples done...")
-            identifier, start_idx = tup
-            sliced = split_data_map[identifier].iloc[start_idx - self.time_steps : start_idx]
-            inputs[i, :, :] = sliced[input_cols]
-            outputs[i, :, :] = sliced[[target_col]]
-            time[i, :, 0] = sliced[time_col]
-            identifiers[i, :, 0] = sliced[id_col]
-
-        sampled_data = {
-            "inputs": inputs,
-            "outputs": outputs[:, self.num_encoder_steps :, :],
-            "active_entries": np.ones_like(outputs[:, self.num_encoder_steps :, :]),
-            "time": time,
-            "identifier": identifiers,
-        }
-
-        return sampled_data
-
-    def _batch_data(self, data):
-        """Batches data for training.
-
-        Converts raw dataframe from a 2-D tabular format to a batched 3-D array
-        to feed into Keras model.
-
-        Args:
-          data: DataFrame to batch
-
-        Returns:
-          Batched Numpy array with shape=(?, self.time_steps, self.input_size)
-        """
-
-        # Functions.
-        def _batch_single_entity(input_data):
-            time_steps = len(input_data)
-            lags = self.time_steps
-            x = input_data.values
-            if time_steps >= lags:
-                return np.stack([x[i : time_steps - (lags - 1) + i, :] for i in range(lags)], axis=1)
-
-            else:
-                return None
-
-        id_col = self._get_single_col_by_type(InputTypes.ID)
-        time_col = self._get_single_col_by_type(InputTypes.TIME)
-        target_col = self._get_single_col_by_type(InputTypes.TARGET)
-        input_cols = [tup[0] for tup in self.column_definition if tup[2] not in {InputTypes.ID, InputTypes.TIME}]
-
-        data_map = {}
-        for _, sliced in data.groupby(id_col):
-            col_mappings = {"identifier": [id_col], "time": [time_col], "outputs": [target_col], "inputs": input_cols}
-
-            for k in col_mappings:
-                cols = col_mappings[k]
-                arr = _batch_single_entity(sliced[cols].copy())
-
-                if k not in data_map:
-                    data_map[k] = [arr]
-                else:
-                    data_map[k].append(arr)
-
-        # Combine all data
-        for k in data_map:
-            # Wendi: Avoid returning None when the length is not enough
-            data_map[k] = np.concatenate([i for i in data_map[k] if i is not None], axis=0)
-
-        # Shorten target so we only get decoder steps
-        data_map["outputs"] = data_map["outputs"][:, self.num_encoder_steps :, :]
-
-        active_entries = np.ones_like(data_map["outputs"])
-        if "active_entries" not in data_map:
-            data_map["active_entries"] = active_entries
-        else:
-            data_map["active_entries"].append(active_entries)
-
-        return data_map
-
-    def _get_active_locations(self, x):
-        """Formats sample weights for Keras training."""
-        return (np.sum(x, axis=-1) > 0.0) * 1.0
-
-    def _build_base_graph(self):
-        """Returns graph defining layers of the TFT."""
-
-        # Size definitions.
-        time_steps = self.time_steps
-        combined_input_size = self.input_size
-        encoder_steps = self.num_encoder_steps
-
-        # Inputs.
-        all_inputs = tf.keras.layers.Input(
-            shape=(
-                time_steps,
-                combined_input_size,
-            )
-        )
-
-        unknown_inputs, known_combined_layer, obs_inputs, static_inputs = self.get_tft_embeddings(all_inputs)
-
-        # Isolate known and observed historical inputs.
-        if unknown_inputs is not None:
-            historical_inputs = concat(
-                [
-                    unknown_inputs[:, :encoder_steps, :],
-                    known_combined_layer[:, :encoder_steps, :],
-                    obs_inputs[:, :encoder_steps, :],
-                ],
-                axis=-1,
-            )
-        else:
-            historical_inputs = concat(
-                [known_combined_layer[:, :encoder_steps, :], obs_inputs[:, :encoder_steps, :]], axis=-1
-            )
-
-        # Isolate only known future inputs.
-        future_inputs = known_combined_layer[:, encoder_steps:, :]
-
-        def static_combine_and_mask(embedding):
-            """Applies variable selection network to static inputs.
-
-            Args:
-              embedding: Transformed static inputs
-
-            Returns:
-              Tensor output for variable selection network
-            """
-
-            # Add temporal features
-            _, num_static, _ = embedding.get_shape().as_list()
-
-            flatten = tf.keras.layers.Flatten()(embedding)
-
-            # Nonlinear transformation with gated residual network.
-            mlp_outputs = gated_residual_network(
-                flatten,
-                self.hidden_layer_size,
-                output_size=num_static,
-                dropout_rate=self.dropout_rate,
-                use_time_distributed=False,
-                additional_context=None,
-            )
-
-            sparse_weights = tf.keras.layers.Activation("softmax")(mlp_outputs)
-            sparse_weights = K.expand_dims(sparse_weights, axis=-1)
-
-            trans_emb_list = []
-            for i in range(num_static):
-                e = gated_residual_network(
-                    embedding[:, i : i + 1, :],
-                    self.hidden_layer_size,
-                    dropout_rate=self.dropout_rate,
-                    use_time_distributed=False,
-                )
-                trans_emb_list.append(e)
-
-            transformed_embedding = concat(trans_emb_list, axis=1)
-
-            combined = tf.keras.layers.Multiply()([sparse_weights, transformed_embedding])
-
-            static_vec = K.sum(combined, axis=1)
-
-            return static_vec, sparse_weights
-
-        static_encoder, static_weights = static_combine_and_mask(static_inputs)
-
-        static_context_variable_selection = gated_residual_network(
-            static_encoder, self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False
-        )
-        static_context_enrichment = gated_residual_network(
-            static_encoder, self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False
-        )
-        static_context_state_h = gated_residual_network(
-            static_encoder, self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False
-        )
-        static_context_state_c = gated_residual_network(
-            static_encoder, self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False
-        )
-
-        def lstm_combine_and_mask(embedding):
-            """Apply temporal variable selection networks.
-
-            Args:
-              embedding: Transformed inputs.
-
-            Returns:
-              Processed tensor outputs.
-            """
-
-            # Add temporal features
-            _, time_steps, embedding_dim, num_inputs = embedding.get_shape().as_list()
-
-            flatten = K.reshape(embedding, [-1, time_steps, embedding_dim * num_inputs])
-
-            expanded_static_context = K.expand_dims(static_context_variable_selection, axis=1)
-
-            # Variable selection weights
-            mlp_outputs, static_gate = gated_residual_network(
-                flatten,
-                self.hidden_layer_size,
-                output_size=num_inputs,
-                dropout_rate=self.dropout_rate,
-                use_time_distributed=True,
-                additional_context=expanded_static_context,
-                return_gate=True,
-            )
-
-            sparse_weights = tf.keras.layers.Activation("softmax")(mlp_outputs)
-            sparse_weights = tf.expand_dims(sparse_weights, axis=2)
-
-            # Non-linear Processing & weight application
-            trans_emb_list = []
-            for i in range(num_inputs):
-                grn_output = gated_residual_network(
-                    embedding[Ellipsis, i],
-                    self.hidden_layer_size,
-                    dropout_rate=self.dropout_rate,
-                    use_time_distributed=True,
-                )
-                trans_emb_list.append(grn_output)
-
-            transformed_embedding = stack(trans_emb_list, axis=-1)
-
-            combined = tf.keras.layers.Multiply()([sparse_weights, transformed_embedding])
-            temporal_ctx = K.sum(combined, axis=-1)
-
-            return temporal_ctx, sparse_weights, static_gate
-
-        historical_features, historical_flags, _ = lstm_combine_and_mask(historical_inputs)
-        future_features, future_flags, _ = lstm_combine_and_mask(future_inputs)
-
-        # LSTM layer
-        def get_lstm(return_state):
-            """Returns LSTM cell initialized with default parameters."""
-            if self.use_cudnn:
-                lstm = tf.keras.layers.CuDNNLSTM(
-                    self.hidden_layer_size,
-                    return_sequences=True,
-                    return_state=return_state,
-                    stateful=False,
-                )
-            else:
-                lstm = tf.keras.layers.LSTM(
-                    self.hidden_layer_size,
-                    return_sequences=True,
-                    return_state=return_state,
-                    stateful=False,
-                    # Additional params to ensure LSTM matches CuDNN, See TF 2.0 :
-                    # (https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)
-                    activation="tanh",
-                    recurrent_activation="sigmoid",
-                    recurrent_dropout=0,
-                    unroll=False,
-                    use_bias=True,
-                )
-            return lstm
-
-        history_lstm, state_h, state_c = get_lstm(return_state=True)(
-            historical_features, initial_state=[static_context_state_h, static_context_state_c]
-        )
-
-        future_lstm = get_lstm(return_state=False)(future_features, initial_state=[state_h, state_c])
-
-        lstm_layer = concat([history_lstm, future_lstm], axis=1)
-
-        # Apply gated skip connection
-        input_embeddings = concat([historical_features, future_features], axis=1)
-
-        lstm_layer, _ = apply_gating_layer(lstm_layer, self.hidden_layer_size, self.dropout_rate, activation=None)
-        temporal_feature_layer = add_and_norm([lstm_layer, input_embeddings])
-
-        # Static enrichment layers
-        expanded_static_context = K.expand_dims(static_context_enrichment, axis=1)
-        enriched, _ = gated_residual_network(
-            temporal_feature_layer,
-            self.hidden_layer_size,
-            dropout_rate=self.dropout_rate,
-            use_time_distributed=True,
-            additional_context=expanded_static_context,
-            return_gate=True,
-        )
-
-        # Decoder self attention
-        self_attn_layer = InterpretableMultiHeadAttention(
-            self.num_heads, self.hidden_layer_size, dropout=self.dropout_rate
-        )
-
-        mask = get_decoder_mask(enriched)
-        x, self_att = self_attn_layer(enriched, enriched, enriched, mask=mask)
-
-        x, _ = apply_gating_layer(x, self.hidden_layer_size, dropout_rate=self.dropout_rate, activation=None)
-        x = add_and_norm([x, enriched])
-
-        # Nonlinear processing on outputs
-        decoder = gated_residual_network(
-            x, self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=True
-        )
-
-        # Final skip connection
-        decoder, _ = apply_gating_layer(decoder, self.hidden_layer_size, activation=None)
-        transformer_layer = add_and_norm([decoder, temporal_feature_layer])
-
-        # Attention components for explainability
-        attention_components = {
-            # Temporal attention weights
-            "decoder_self_attn": self_att,
-            # Static variable selection weights
-            "static_flags": static_weights[Ellipsis, 0],
-            # Variable selection weights of past inputs
-            "historical_flags": historical_flags[Ellipsis, 0, :],
-            # Variable selection weights of future inputs
-            "future_flags": future_flags[Ellipsis, 0, :],
-        }
-
-        return transformer_layer, all_inputs, attention_components
-
-    def build_model(self):
-        """Build model and defines training losses.
-
-        Returns:
-          Fully defined Keras model.
-        """
-
-        with tf.variable_scope(self.name):
-            transformer_layer, all_inputs, attention_components = self._build_base_graph()
-
-            outputs = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.output_size * len(self.quantiles)))(
-                transformer_layer[Ellipsis, self.num_encoder_steps :, :]
-            )
-
-            self._attention_components = attention_components
-
-            adam = tf.keras.optimizers.Adam(lr=self.learning_rate, clipnorm=self.max_gradient_norm)
-
-            model = tf.keras.Model(inputs=all_inputs, outputs=outputs)
-
-            print(model.summary())
-
-            valid_quantiles = self.quantiles
-            output_size = self.output_size
-
-            class QuantileLossCalculator:
-                """Computes the combined quantile loss for prespecified quantiles.
-
-                Attributes:
-                  quantiles: Quantiles to compute losses
-                """
-
-                def __init__(self, quantiles):
-                    """Initializes computer with quantiles for loss calculations.
-
-                    Args:
-                      quantiles: Quantiles to use for computations.
-                    """
-                    self.quantiles = quantiles
-
-                def quantile_loss(self, a, b):
-                    """Returns quantile loss for specified quantiles.
-
-                    Args:
-                      a: Targets
-                      b: Predictions
-                    """
-                    quantiles_used = set(self.quantiles)
-
-                    loss = 0.0
-                    for i, quantile in enumerate(valid_quantiles):
-                        if quantile in quantiles_used:
-                            loss += utils.tensorflow_quantile_loss(
-                                a[Ellipsis, output_size * i : output_size * (i + 1)],
-                                b[Ellipsis, output_size * i : output_size * (i + 1)],
-                                quantile,
-                            )
-                    return loss
-
-            quantile_loss = QuantileLossCalculator(valid_quantiles).quantile_loss
-
-            model.compile(loss=quantile_loss, optimizer=adam, sample_weight_mode="temporal")
-
-            self._input_placeholder = all_inputs
-
-        return model
-
-    def fit(self, train_df=None, valid_df=None):
-        """Fits deep neural network for given training and validation data.
-
-        Args:
-          train_df: DataFrame for training data
-          valid_df: DataFrame for validation data
-        """
-
-        print("*** Fitting {} ***".format(self.name))
-
-        # Add relevant callbacks
-        callbacks = [
-            tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=self.early_stopping_patience, min_delta=1e-4),
-            tf.keras.callbacks.ModelCheckpoint(
-                filepath=self.get_keras_saved_path(self._temp_folder),
-                monitor="val_loss",
-                save_best_only=True,
-                save_weights_only=True,
-            ),
-            tf.keras.callbacks.TerminateOnNaN(),
-        ]
-
-        print("Getting batched_data")
-        if train_df is None:
-            print("Using cached training data")
-            train_data = TFTDataCache.get("train")
-        else:
-            train_data = self._batch_data(train_df)
-
-        if valid_df is None:
-            print("Using cached validation data")
-            valid_data = TFTDataCache.get("valid")
-        else:
-            valid_data = self._batch_data(valid_df)
-
-        print("Using keras standard fit")
-
-        def _unpack(data):
-            return data["inputs"], data["outputs"], self._get_active_locations(data["active_entries"])
-
-        # Unpack without sample weights
-        data, labels, active_flags = _unpack(train_data)
-        val_data, val_labels, val_flags = _unpack(valid_data)
-
-        all_callbacks = callbacks
-
-        self.model.fit(
-            x=data,
-            y=np.concatenate([labels, labels, labels], axis=-1),
-            sample_weight=active_flags,
-            epochs=self.num_epochs,
-            batch_size=self.minibatch_size,
-            validation_data=(val_data, np.concatenate([val_labels, val_labels, val_labels], axis=-1), val_flags),
-            callbacks=all_callbacks,
-            shuffle=True,
-            use_multiprocessing=True,
-            workers=self.n_multiprocessing_workers,
-        )
-
-        # Load best checkpoint again
-        tmp_checkpont = self.get_keras_saved_path(self._temp_folder)
-        if os.path.exists(tmp_checkpont):
-            self.load(self._temp_folder, use_keras_loadings=True)
-
-        else:
-            print("Cannot load from {}, skipping ...".format(self._temp_folder))
-
-    def evaluate(self, data=None, eval_metric="loss"):
-        """Applies evaluation metric to the training data.
-
-        Args:
-          data: Dataframe for evaluation
-          eval_metric: Evaluation metic to return, based on model definition.
-
-        Returns:
-          Computed evaluation loss.
-        """
-
-        if data is None:
-            print("Using cached validation data")
-            raw_data = TFTDataCache.get("valid")
-        else:
-            raw_data = self._batch_data(data)
-
-        inputs = raw_data["inputs"]
-        outputs = raw_data["outputs"]
-        active_entries = self._get_active_locations(raw_data["active_entries"])
-
-        metric_values = self.model.evaluate(
-            x=inputs,
-            y=np.concatenate([outputs, outputs, outputs], axis=-1),
-            sample_weight=active_entries,
-            workers=16,
-            use_multiprocessing=True,
-        )
-
-        metrics = pd.Series(metric_values, self.model.metrics_names)
-
-        return metrics[eval_metric]
-
-    def predict(self, df, return_targets=False):
-        """Computes predictions for a given input dataset.
-
-        Args:
-          df: Input dataframe
-          return_targets: Whether to also return outputs aligned with predictions to
-            facilitate evaluation
-
-        Returns:
-          Input dataframe or tuple of (input dataframe, aligned output dataframe).
-        """
-
-        data = self._batch_data(df)
-
-        inputs = data["inputs"]
-        time = data["time"]
-        identifier = data["identifier"]
-        outputs = data["outputs"]
-
-        combined = self.model.predict(inputs, workers=16, use_multiprocessing=True, batch_size=self.minibatch_size)
-
-        # Format output_csv
-        if self.output_size != 1:
-            raise NotImplementedError("Current version only supports 1D targets!")
-
-        def format_outputs(prediction):
-            """Returns formatted dataframes for prediction."""
-
-            flat_prediction = pd.DataFrame(
-                prediction[:, :, 0], columns=["t+{}".format(i) for i in range(self.time_steps - self.num_encoder_steps)]
-            )
-            cols = list(flat_prediction.columns)
-            flat_prediction["forecast_time"] = time[:, self.num_encoder_steps - 1, 0]
-            flat_prediction["identifier"] = identifier[:, 0, 0]
-
-            # Arrange in order
-            return flat_prediction[["forecast_time", "identifier"] + cols]
-
-        # Extract predictions for each quantile into different entries
-        process_map = {
-            "p{}".format(int(q * 100)): combined[Ellipsis, i * self.output_size : (i + 1) * self.output_size]
-            for i, q in enumerate(self.quantiles)
-        }
-
-        if return_targets:
-            # Add targets if relevant
-            process_map["targets"] = outputs
-
-        return {k: format_outputs(process_map[k]) for k in process_map}
-
-    def get_attention(self, df):
-        """Computes TFT attention weights for a given dataset.
-
-        Args:
-          df: Input dataframe
-
-        Returns:
-            Dictionary of numpy arrays for temporal attention weights and variable
-              selection weights, along with their identifiers and time indices
-        """
-
-        data = self._batch_data(df)
-        inputs = data["inputs"]
-        identifiers = data["identifier"]
-        time = data["time"]
-
-        def get_batch_attention_weights(input_batch):
-            """Returns weights for a given minibatch of data."""
-            input_placeholder = self._input_placeholder
-            attention_weights = {}
-            for k in self._attention_components:
-                attention_weight = tf.keras.backend.get_session().run(
-                    self._attention_components[k], {input_placeholder: input_batch.astype(np.float32)}
-                )
-                attention_weights[k] = attention_weight
-            return attention_weights
-
-        # Compute number of batches
-        batch_size = self.minibatch_size
-        n = inputs.shape[0]
-        num_batches = n // batch_size
-        if n - (num_batches * batch_size) > 0:
-            num_batches += 1
-
-        # Split up inputs into batches
-        batched_inputs = [inputs[i * batch_size : (i + 1) * batch_size, Ellipsis] for i in range(num_batches)]
-
-        # Get attention weights, while avoiding large memory increases
-        attention_by_batch = [get_batch_attention_weights(batch) for batch in batched_inputs]
-        attention_weights = {}
-        for k in self._attention_components:
-            attention_weights[k] = []
-            for batch_weights in attention_by_batch:
-                attention_weights[k].append(batch_weights[k])
-
-            if len(attention_weights[k][0].shape) == 4:
-                tmp = np.concatenate(attention_weights[k], axis=1)
-            else:
-                tmp = np.concatenate(attention_weights[k], axis=0)
-
-            del attention_weights[k]
-            gc.collect()
-            attention_weights[k] = tmp
-
-        attention_weights["identifiers"] = identifiers[:, 0, 0]
-        attention_weights["time"] = time[:, :, 0]
-
-        return attention_weights
-
-    # Serialisation.
-    def reset_temp_folder(self):
-        """Deletes and recreates folder with temporary Keras training outputs."""
-        print("Resetting temp folder...")
-        utils.create_folder_if_not_exist(self._temp_folder)
-        shutil.rmtree(self._temp_folder)
-        os.makedirs(self._temp_folder)
-
-    def get_keras_saved_path(self, model_folder):
-        """Returns path to keras checkpoint."""
-        return os.path.join(model_folder, "{}.check".format(self.name))
-
-    def save(self, model_folder):
-        """Saves optimal TFT weights.
-
-        Args:
-          model_folder: Location to serialze model.
-        """
-        # Allows for direct serialisation of tensorflow variables to avoid spurious
-        # issue with Keras that leads to different performance evaluation results
-        # when model is reloaded (https://github.com/keras-team/keras/issues/4875).
-
-        utils.save(tf.keras.backend.get_session(), model_folder, cp_name=self.name, scope=self.name)
-
-    def load(self, model_folder, use_keras_loadings=False):
-        """Loads TFT weights.
-
-        Args:
-          model_folder: Folder containing serialized models.
-          use_keras_loadings: Whether to load from Keras checkpoint.
-
-        Returns:
-
-        """
-        if use_keras_loadings:
-            # Loads temporary Keras model saved during training.
-            serialisation_path = self.get_keras_saved_path(model_folder)
-            print("Loading model from {}".format(serialisation_path))
-            self.model.load_weights(serialisation_path)
-        else:
-            # Loads tensorflow graph for optimal models.
-            utils.load(tf.keras.backend.get_session(), model_folder, cp_name=self.name, scope=self.name)
-
-    @classmethod
-    def get_hyperparm_choices(cls):
-        """Returns hyperparameter ranges for random search."""
-        return {
-            "dropout_rate": [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.9],
-            "hidden_layer_size": [10, 20, 40, 80, 160, 240, 320],
-            "minibatch_size": [64, 128, 256],
-            "learning_rate": [1e-4, 1e-3, 1e-2],
-            "max_gradient_norm": [0.01, 1.0, 100.0],
-            "num_heads": [1, 4],
-            "stack_size": [1],
-        }
diff --git a/examples/benchmarks/TFT/libs/utils.py b/examples/benchmarks/TFT/libs/utils.py
deleted file mode 100644
index 4682434d..00000000
--- a/examples/benchmarks/TFT/libs/utils.py
+++ /dev/null
@@ -1,224 +0,0 @@
-# coding=utf-8
-# Copyright 2020 The Google Research Authors.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Lint as: python3
-"""Generic helper functions used across codebase."""
-
-import os
-import pathlib
-
-import numpy as np
-import tensorflow as tf
-from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file
-
-
-# Generic.
-def get_single_col_by_input_type(input_type, column_definition):
-    """Returns name of single column.
-
-    Args:
-      input_type: Input type of column to extract
-      column_definition: Column definition list for experiment
-    """
-
-    l = [tup[0] for tup in column_definition if tup[2] == input_type]
-
-    if len(l) != 1:
-        raise ValueError("Invalid number of columns for {}".format(input_type))
-
-    return l[0]
-
-
-def extract_cols_from_data_type(data_type, column_definition, excluded_input_types):
-    """Extracts the names of columns that correspond to a define data_type.
-
-    Args:
-      data_type: DataType of columns to extract.
-      column_definition: Column definition to use.
-      excluded_input_types: Set of input types to exclude
-
-    Returns:
-      List of names for columns with data type specified.
-    """
-    return [tup[0] for tup in column_definition if tup[1] == data_type and tup[2] not in excluded_input_types]
-
-
-# Loss functions.
-def tensorflow_quantile_loss(y, y_pred, quantile):
-    """Computes quantile loss for tensorflow.
-
-    Standard quantile loss as defined in the "Training Procedure" section of
-    the main TFT paper
-
-    Args:
-      y: Targets
-      y_pred: Predictions
-      quantile: Quantile to use for loss calculations (between 0 & 1)
-
-    Returns:
-      Tensor for quantile loss.
-    """
-
-    # Checks quantile
-    if quantile < 0 or quantile > 1:
-        raise ValueError("Illegal quantile value={}! Values should be between 0 and 1.".format(quantile))
-
-    prediction_underflow = y - y_pred
-    q_loss = quantile * tf.maximum(prediction_underflow, 0.0) + (1.0 - quantile) * tf.maximum(
-        -prediction_underflow, 0.0
-    )
-
-    return tf.reduce_sum(q_loss, axis=-1)
-
-
-def numpy_normalised_quantile_loss(y, y_pred, quantile):
-    """Computes normalised quantile loss for numpy arrays.
-
-    Uses the q-Risk metric as defined in the "Training Procedure" section of the
-    main TFT paper.
-
-    Args:
-      y: Targets
-      y_pred: Predictions
-      quantile: Quantile to use for loss calculations (between 0 & 1)
-
-    Returns:
-      Float for normalised quantile loss.
-    """
-    prediction_underflow = y - y_pred
-    weighted_errors = quantile * np.maximum(prediction_underflow, 0.0) + (1.0 - quantile) * np.maximum(
-        -prediction_underflow, 0.0
-    )
-
-    quantile_loss = weighted_errors.mean()
-    normaliser = y.abs().mean()
-
-    return 2 * quantile_loss / normaliser
-
-
-# OS related functions.
-def create_folder_if_not_exist(directory):
-    """Creates folder if it doesn't exist.
-
-    Args:
-      directory: Folder path to create.
-    """
-    # Also creates directories recursively
-    pathlib.Path(directory).mkdir(parents=True, exist_ok=True)
-
-
-# Tensorflow related functions.
-def get_default_tensorflow_config(tf_device="gpu", gpu_id=0):
-    """Creates tensorflow config for graphs to run on CPU or GPU.
-
-    Specifies whether to run graph on gpu or cpu and which GPU ID to use for multi
-    GPU machines.
-
-    Args:
-      tf_device: 'cpu' or 'gpu'
-      gpu_id: GPU ID to use if relevant
-
-    Returns:
-      Tensorflow config.
-    """
-
-    if tf_device == "cpu":
-        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # for training on cpu
-        tf_config = tf.ConfigProto(log_device_placement=False, device_count={"GPU": 0})
-
-    else:
-        os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-        os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
-
-        print("Selecting GPU ID={}".format(gpu_id))
-
-        tf_config = tf.ConfigProto(log_device_placement=False)
-        tf_config.gpu_options.allow_growth = True
-
-    return tf_config
-
-
-def save(tf_session, model_folder, cp_name, scope=None):
-    """Saves Tensorflow graph to checkpoint.
-
-    Saves all trainiable variables under a given variable scope to checkpoint.
-
-    Args:
-      tf_session: Session containing graph
-      model_folder: Folder to save models
-      cp_name: Name of Tensorflow checkpoint
-      scope: Variable scope containing variables to save
-    """
-    # Save model
-    if scope is None:
-        saver = tf.train.Saver()
-    else:
-        var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope)
-        saver = tf.train.Saver(var_list=var_list, max_to_keep=100000)
-
-    save_path = saver.save(tf_session, os.path.join(model_folder, "{0}.ckpt".format(cp_name)))
-    print("Model saved to: {0}".format(save_path))
-
-
-def load(tf_session, model_folder, cp_name, scope=None, verbose=False):
-    """Loads Tensorflow graph from checkpoint.
-
-    Args:
-      tf_session: Session to load graph into
-      model_folder: Folder containing serialised model
-      cp_name: Name of Tensorflow checkpoint
-      scope: Variable scope to use.
-      verbose: Whether to print additional debugging information.
-    """
-    # Load model proper
-    load_path = os.path.join(model_folder, "{0}.ckpt".format(cp_name))
-
-    print("Loading model from {0}".format(load_path))
-
-    print_weights_in_checkpoint(model_folder, cp_name)
-
-    initial_vars = set([v.name for v in tf.get_default_graph().as_graph_def().node])
-
-    # Saver
-    if scope is None:
-        saver = tf.train.Saver()
-    else:
-        var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=scope)
-        saver = tf.train.Saver(var_list=var_list, max_to_keep=100000)
-    # Load
-    saver.restore(tf_session, load_path)
-    all_vars = set([v.name for v in tf.get_default_graph().as_graph_def().node])
-
-    if verbose:
-        print("Restored {0}".format(",".join(initial_vars.difference(all_vars))))
-        print("Existing {0}".format(",".join(all_vars.difference(initial_vars))))
-        print("All {0}".format(",".join(all_vars)))
-
-    print("Done.")
-
-
-def print_weights_in_checkpoint(model_folder, cp_name):
-    """Prints all weights in Tensorflow checkpoint.
-
-    Args:
-      model_folder: Folder containing checkpoint
-      cp_name: Name of checkpoint
-
-    Returns:
-
-    """
-    load_path = os.path.join(model_folder, "{0}.ckpt".format(cp_name))
-
-    print_tensors_in_checkpoint_file(file_name=load_path, tensor_name="", all_tensors=True, all_tensor_names=True)
diff --git a/examples/benchmarks/TFT/requirements.txt b/examples/benchmarks/TFT/requirements.txt
deleted file mode 100644
index f8bd0000..00000000
--- a/examples/benchmarks/TFT/requirements.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-tensorflow-gpu==1.15.0
-pandas==1.1.0
diff --git a/examples/benchmarks/TFT/tft.py b/examples/benchmarks/TFT/tft.py
deleted file mode 100644
index e6dd27e8..00000000
--- a/examples/benchmarks/TFT/tft.py
+++ /dev/null
@@ -1,320 +0,0 @@
-# Copyright (c) Microsoft Corporation.
-# Licensed under the MIT License.
-
-from pathlib import Path
-from typing import Union
-import numpy as np
-import pandas as pd
-import tensorflow.compat.v1 as tf
-import data_formatters.base
-import expt_settings.configs
-import libs.hyperparam_opt
-import libs.tft_model
-import libs.utils as utils
-import os
-import datetime as dte
-
-
-from qlib.model.base import ModelFT
-from qlib.data.dataset import DatasetH
-from qlib.data.dataset.handler import DataHandlerLP
-
-
-# To register new datasets, please add them here.
-ALLOW_DATASET = ["Alpha158", "Alpha360"]
-# To register new datasets, please add their configurations here.
-DATASET_SETTING = {
-    "Alpha158": {
-        "feature_col": [
-            "RESI5",
-            "WVMA5",
-            "RSQR5",
-            "KLEN",
-            "RSQR10",
-            "CORR5",
-            "CORD5",
-            "CORR10",
-            "ROC60",
-            "RESI10",
-            "VSTD5",
-            "RSQR60",
-            "CORR60",
-            "WVMA60",
-            "STD5",
-            "RSQR20",
-            "CORD60",
-            "CORD10",
-            "CORR20",
-            "KLOW",
-        ],
-        "label_col": "LABEL0",
-    },
-    "Alpha360": {
-        "feature_col": [
-            "HIGH0",
-            "LOW0",
-            "OPEN0",
-            "CLOSE1",
-            "HIGH1",
-            "VOLUME1",
-            "LOW1",
-            "VOLUME3",
-            "OPEN1",
-            "VOLUME4",
-            "CLOSE2",
-            "CLOSE4",
-            "VOLUME5",
-            "LOW2",
-            "CLOSE3",
-            "VOLUME2",
-            "HIGH2",
-            "LOW4",
-            "VOLUME8",
-            "VOLUME11",
-        ],
-        "label_col": "LABEL0",
-    },
-}
-
-
-def get_shifted_label(data_df, shifts=5, col_shift="LABEL0"):
-    return data_df[[col_shift]].groupby("instrument").apply(lambda df: df.shift(shifts))
-
-
-def fill_test_na(test_df):
-    test_df_res = test_df.copy()
-    feature_cols = ~test_df_res.columns.str.contains("label", case=False)
-    test_feature_fna = test_df_res.loc[:, feature_cols].groupby("datetime").apply(lambda df: df.fillna(df.mean()))
-    test_df_res.loc[:, feature_cols] = test_feature_fna
-    return test_df_res
-
-
-def process_qlib_data(df, dataset, fillna=False):
-    """Prepare data to fit the TFT model.
-
-    Args:
-      df: Original DataFrame.
-      fillna: Whether to fill the data with the mean values.
-
-    Returns:
-      Transformed DataFrame.
-
-    """
-    # Several features selected manually
-    feature_col = DATASET_SETTING[dataset]["feature_col"]
-    label_col = [DATASET_SETTING[dataset]["label_col"]]
-    temp_df = df.loc[:, feature_col + label_col]
-    if fillna:
-        temp_df = fill_test_na(temp_df)
-    temp_df = temp_df.swaplevel()
-    temp_df = temp_df.sort_index()
-    temp_df = temp_df.reset_index(level=0)
-    dates = pd.to_datetime(temp_df.index)
-    temp_df["date"] = dates
-    temp_df["day_of_week"] = dates.dayofweek
-    temp_df["month"] = dates.month
-    temp_df["year"] = dates.year
-    temp_df["const"] = 1.0
-    return temp_df
-
-
-def process_predicted(df, col_name):
-    """Transform the TFT predicted data into Qlib format.
-
-    Args:
-      df: Original DataFrame.
-      fillna: New column name.
-
-    Returns:
-      Transformed DataFrame.
-
-    """
-    df_res = df.copy()
-    df_res = df_res.rename(columns={"forecast_time": "datetime", "identifier": "instrument", "t+4": col_name})
-    df_res = df_res.set_index(["datetime", "instrument"]).sort_index()
-    df_res = df_res[[col_name]]
-    return df_res
-
-
-def format_score(forecast_df, col_name="pred", label_shift=5):
-    pred = process_predicted(forecast_df, col_name=col_name)
-    pred = get_shifted_label(pred, shifts=-label_shift, col_shift=col_name)
-    pred = pred.dropna()[col_name]
-    return pred
-
-
-def transform_df(df, col_name="LABEL0"):
-    df_res = df["feature"]
-    df_res[col_name] = df["label"]
-    return df_res
-
-
-class TFTModel(ModelFT):
-    """TFT Model"""
-
-    def __init__(self, **kwargs):
-        self.model = None
-        self.params = {"DATASET": "Alpha158", "label_shift": 5}
-        self.params.update(kwargs)
-
-    def _prepare_data(self, dataset: DatasetH):
-        df_train, df_valid = dataset.prepare(
-            ["train", "valid"], col_set=["feature", "label"], data_key=DataHandlerLP.DK_L
-        )
-        return transform_df(df_train), transform_df(df_valid)
-
-    def fit(self, dataset: DatasetH, MODEL_FOLDER="qlib_tft_model", USE_GPU_ID=0, **kwargs):
-        DATASET = self.params["DATASET"]
-        LABEL_SHIFT = self.params["label_shift"]
-        LABEL_COL = DATASET_SETTING[DATASET]["label_col"]
-
-        if DATASET not in ALLOW_DATASET:
-            raise AssertionError("The dataset is not supported, please make a new formatter to fit this dataset")
-
-        dtrain, dvalid = self._prepare_data(dataset)
-        dtrain.loc[:, LABEL_COL] = get_shifted_label(dtrain, shifts=LABEL_SHIFT, col_shift=LABEL_COL)
-        dvalid.loc[:, LABEL_COL] = get_shifted_label(dvalid, shifts=LABEL_SHIFT, col_shift=LABEL_COL)
-
-        train = process_qlib_data(dtrain, DATASET, fillna=True).dropna()
-        valid = process_qlib_data(dvalid, DATASET, fillna=True).dropna()
-
-        ExperimentConfig = expt_settings.configs.ExperimentConfig
-        config = ExperimentConfig(DATASET)
-        self.data_formatter = config.make_data_formatter()
-        self.model_folder = MODEL_FOLDER
-        self.gpu_id = USE_GPU_ID
-        self.label_shift = LABEL_SHIFT
-        self.expt_name = DATASET
-        self.label_col = LABEL_COL
-
-        use_gpu = (True, self.gpu_id)
-        # ===========================Training Process===========================
-        ModelClass = libs.tft_model.TemporalFusionTransformer
-        if not isinstance(self.data_formatter, data_formatters.base.GenericDataFormatter):
-            raise ValueError(
-                "Data formatters should inherit from"
-                + "AbstractDataFormatter! Type={}".format(type(self.data_formatter))
-            )
-
-        default_keras_session = tf.keras.backend.get_session()
-
-        if use_gpu[0]:
-            self.tf_config = utils.get_default_tensorflow_config(tf_device="gpu", gpu_id=use_gpu[1])
-        else:
-            self.tf_config = utils.get_default_tensorflow_config(tf_device="cpu")
-
-        self.data_formatter.set_scalers(train)
-
-        # Sets up default params
-        fixed_params = self.data_formatter.get_experiment_params()
-        params = self.data_formatter.get_default_model_params()
-
-        params = {**params, **fixed_params}
-
-        if not os.path.exists(self.model_folder):
-            os.makedirs(self.model_folder)
-        params["model_folder"] = self.model_folder
-
-        print("*** Begin training ***")
-        best_loss = np.Inf
-
-        tf.reset_default_graph()
-
-        self.tf_graph = tf.Graph()
-        with self.tf_graph.as_default():
-            self.sess = tf.Session(config=self.tf_config)
-            tf.keras.backend.set_session(self.sess)
-            self.model = ModelClass(params, use_cudnn=use_gpu[0])
-            self.sess.run(tf.global_variables_initializer())
-            self.model.fit(train_df=train, valid_df=valid)
-            print("*** Finished training ***")
-            saved_model_dir = self.model_folder + "/" + "saved_model"
-            if not os.path.exists(saved_model_dir):
-                os.makedirs(saved_model_dir)
-            self.model.save(saved_model_dir)
-
-            def extract_numerical_data(data):
-                """Strips out forecast time and identifier columns."""
-                return data[[col for col in data.columns if col not in {"forecast_time", "identifier"}]]
-
-            # p50_loss = utils.numpy_normalised_quantile_loss(
-            #    extract_numerical_data(targets), extract_numerical_data(p50_forecast),
-            #    0.5)
-            # p90_loss = utils.numpy_normalised_quantile_loss(
-            #    extract_numerical_data(targets), extract_numerical_data(p90_forecast),
-            #    0.9)
-            tf.keras.backend.set_session(default_keras_session)
-        print("Training completed at {}.".format(dte.datetime.now()))
-        # ===========================Training Process===========================
-
-    def predict(self, dataset):
-        if self.model is None:
-            raise ValueError("model is not fitted yet!")
-        d_test = dataset.prepare("test", col_set=["feature", "label"])
-        d_test = transform_df(d_test)
-        d_test.loc[:, self.label_col] = get_shifted_label(d_test, shifts=self.label_shift, col_shift=self.label_col)
-        test = process_qlib_data(d_test, self.expt_name, fillna=True).dropna()
-
-        use_gpu = (True, self.gpu_id)
-        # ===========================Predicting Process===========================
-        default_keras_session = tf.keras.backend.get_session()
-
-        # Sets up default params
-        fixed_params = self.data_formatter.get_experiment_params()
-        params = self.data_formatter.get_default_model_params()
-        params = {**params, **fixed_params}
-
-        print("*** Begin predicting ***")
-        tf.reset_default_graph()
-
-        with self.tf_graph.as_default():
-            tf.keras.backend.set_session(self.sess)
-            output_map = self.model.predict(test, return_targets=True)
-            targets = self.data_formatter.format_predictions(output_map["targets"])
-            p50_forecast = self.data_formatter.format_predictions(output_map["p50"])
-            p90_forecast = self.data_formatter.format_predictions(output_map["p90"])
-            tf.keras.backend.set_session(default_keras_session)
-
-        predict50 = format_score(p50_forecast, "pred", 1)
-        predict90 = format_score(p90_forecast, "pred", 1)
-        predict = (predict50 + predict90) / 2  # self.label_shift
-        # ===========================Predicting Process===========================
-        return predict
-
-    def finetune(self, dataset: DatasetH):
-        """
-        finetune model
-        Parameters
-        ----------
-        dataset : DatasetH
-            dataset for finetuning
-        """
-        pass
-
-    def to_pickle(self, path: Union[Path, str]):
-        """
-        Tensorflow model can't be dumped directly.
-        So the data should be save separately
-
-        **TODO**: Please implement the function to load the files
-
-        Parameters
-        ----------
-        path : Union[Path, str]
-            the target path to be dumped
-        """
-        # FIXME: implementing saving tensorflow models
-        # save tensorflow model
-        # path = Path(path)
-        # path.mkdir(parents=True)
-        # self.model.save(path)
-
-        # save qlib model wrapper
-        drop_attrs = ["model", "tf_graph", "sess", "data_formatter"]
-        orig_attr = {}
-        for attr in drop_attrs:
-            orig_attr[attr] = getattr(self, attr)
-            setattr(self, attr, None)
-        super(TFTModel, self).to_pickle(path)
-        for attr in drop_attrs:
-            setattr(self, attr, orig_attr[attr])
diff --git a/examples/benchmarks/TFT/workflow_config_tft_Alpha158.yaml b/examples/benchmarks/TFT/workflow_config_tft_Alpha158.yaml
deleted file mode 100644
index e925fb77..00000000
--- a/examples/benchmarks/TFT/workflow_config_tft_Alpha158.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-sys:
-    rel_path: .
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TFTModel
-        module_path: tft
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/TRA/README.md b/examples/benchmarks/TRA/README.md
deleted file mode 100644
index ea1d5aac..00000000
--- a/examples/benchmarks/TRA/README.md
+++ /dev/null
@@ -1,93 +0,0 @@
-# Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport
-
-Temporal Routing Adaptor (TRA) is designed to capture multiple trading patterns in the stock market data. Please refer to [our paper](http://arxiv.org/abs/2106.12950) for more details.
-
-If you find our work useful in your research, please cite:
-```
-@inproceedings{HengxuKDD2021,
- author = {Hengxu Lin and Dong Zhou and Weiqing Liu and Jiang Bian},
- title = {Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport},
- booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
- series = {KDD '21},
- year = {2021},
- publisher = {ACM},
-}
-
-@article{yang2020qlib,
-  title={Qlib: An AI-oriented Quantitative Investment Platform},
-  author={Yang, Xiao and Liu, Weiqing and Zhou, Dong and Bian, Jiang and Liu, Tie-Yan},
-  journal={arXiv preprint arXiv:2009.11189},
-  year={2020}
-}
-```
-
-## Usage (Recommended)
-
-**Update**: `TRA` has been moved to `qlib.contrib.model.pytorch_tra` to support other `Qlib` components like  `qlib.workflow` and `Alpha158/Alpha360` dataset.
-
-Please follow the official [doc](https://qlib.readthedocs.io/en/latest/component/workflow.html) to use `TRA` with `workflow`. Here we also provide several example config files:
-
-- `workflow_config_tra_Alpha360.yaml`: running `TRA` with `Alpha360` dataset
-- `workflow_config_tra_Alpha158.yaml`: running `TRA` with `Alpha158` dataset (with feature subsampling)
-- `workflow_config_tra_Alpha158_full.yaml`: running `TRA` with `Alpha158` dataset (without feature subsampling)
-
-The performances of `TRA` are reported in [Benchmarks](https://github.com/microsoft/qlib/tree/main/examples/benchmarks).
-
-## Usage (Not Maintained)
-
-This section is used to reproduce the results in the paper.
-
-### Running
-
-We attach our running scripts for the paper in `run.sh`.
-
-And here are two ways to run the model:
-
-* Running from scripts with default parameters
-
-  You can directly run from Qlib command `qrun`:
-  ```
-  qrun configs/config_alstm.yaml
-  ```
-
-* Running from code with self-defined parameters
-
-  Setting different parameters is also allowed. See codes in `example.py`:
-  ```
-  python example.py --config_file configs/config_alstm.yaml
-  ```
-
-Here we trained TRA on a pretrained backbone model. Therefore we run `*_init.yaml` before TRA's scripts.
-
-### Results
-
-After running the scripts, you can find result files in path `./output`:
-
-* `info.json` - config settings and result metrics.
-* `log.csv` - running logs.
-* `model.bin` - the model parameter dictionary.
-* `pred.pkl` - the prediction scores and output for inference.
-
-Evaluation metrics reported in the paper:
-This result is generated by qlib==0.7.1.
-
-| Methods | MSE| MAE| IC | ICIR | AR | AV | SR | MDD |
-|-------|-------|------|-----|-----|-----|-----|-----|-----|
-|Linear|0.163|0.327|0.020|0.132|-3.2%|16.8%|-0.191|32.1%|
-|LightGBM|0.160(0.000)|0.323(0.000)|0.041|0.292|7.8%|15.5%|0.503|25.7%|
-|MLP|0.160(0.002)|0.323(0.003)|0.037|0.273|3.7%|15.3%|0.264|26.2%|
-|SFM|0.159(0.001)	|0.321(0.001)	|0.047	|0.381	|7.1%	|14.3%	|0.497	|22.9%|
-|ALSTM|0.158(0.001)	|0.320(0.001)	|0.053	|0.419	|12.3%	|13.7%	|0.897	|20.2%|
-|Trans.|0.158(0.001)	|0.322(0.001)	|0.051	|0.400	|14.5%	|14.2%	|1.028	|22.5%|
-|ALSTM+TS|0.160(0.002)	|0.321(0.002)	|0.039	|0.291	|6.7%	|14.6%	|0.480|22.3%|
-|Trans.+TS|0.160(0.004)	|0.324(0.005)	|0.037	|0.278	|10.4%	|14.7%	|0.722	|23.7%|
-|ALSTM+TRA(Ours)|0.157(0.000)	|0.318(0.000)	|0.059	|0.460	|12.4%	|14.0%	|0.885	|20.4%|
-|Trans.+TRA(Ours)|0.157(0.000)	|0.320(0.000)	|0.056	|0.442	|16.1%	|14.2%	|1.133	|23.1%|
-
-A more detailed demo for our experiment results in the paper can be found in `Report.ipynb`.
-
-## Common Issues
-
-For help or issues using TRA, please submit a GitHub issue.
-
-Sometimes we might encounter situation where the loss is `NaN`, please check the `epsilon` parameter in the sinkhorn algorithm, adjusting the `epsilon` according to input's scale is important.
diff --git a/examples/benchmarks/TRA/Reports.ipynb b/examples/benchmarks/TRA/Reports.ipynb
deleted file mode 100644
index bd153443..00000000
--- a/examples/benchmarks/TRA/Reports.ipynb
+++ /dev/null
@@ -1,826 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# Overview\n",
-    "\n",
-    "This notebook contains all experiment results exhibited in our paper."
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 1,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "%matplotlib inline\n",
-    "import glob\n",
-    "import numpy as np\n",
-    "import pandas as pd\n",
-    "import json\n",
-    "import numpy as np\n",
-    "import pandas as pd\n",
-    "import seaborn as sns\n",
-    "import matplotlib.pyplot as plt\n",
-    "import matplotlib\n",
-    "\n",
-    "sns.set(style=\"white\")\n",
-    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
-    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
-    "\n",
-    "from tqdm.auto import tqdm\n",
-    "from joblib import Parallel, delayed\n",
-    "\n",
-    "\n",
-    "def func(x, N=80):\n",
-    "    ret = x.ret.copy()\n",
-    "    x = x.rank(pct=True)\n",
-    "    x[\"ret\"] = ret\n",
-    "    diff = x.score.sub(x.label)\n",
-    "    r = x.nlargest(N, columns=\"score\").ret.mean()\n",
-    "    r -= x.nsmallest(N, columns=\"score\").ret.mean()\n",
-    "    return pd.Series(\n",
-    "        {\n",
-    "            \"MSE\": diff.pow(2).mean(),\n",
-    "            \"MAE\": diff.abs().mean(),\n",
-    "            \"IC\": x.score.corr(x.label),\n",
-    "            \"R\": r,\n",
-    "        }\n",
-    "    )\n",
-    "\n",
-    "\n",
-    "ret = pd.read_pickle(\"data/ret.pkl\").clip(-0.1, 0.1)\n",
-    "\n",
-    "\n",
-    "def backtest(fname, **kwargs):\n",
-    "    pred = pd.read_pickle(fname).loc[\"2018-09-21\":\"2020-06-30\"]  # test period\n",
-    "    pred[\"ret\"] = ret\n",
-    "    dates = pred.index.unique(level=0)\n",
-    "    res = Parallel(n_jobs=-1)(delayed(func)(pred.loc[d], **kwargs) for d in dates)\n",
-    "    res = {dates[i]: res[i] for i in range(len(dates))}\n",
-    "    res = pd.DataFrame(res).T\n",
-    "    r = res[\"R\"].copy()\n",
-    "    r.index = pd.to_datetime(r.index)\n",
-    "    r = r.reindex(pd.date_range(r.index[0], r.index[-1])).fillna(0)  # paper use 365 days\n",
-    "    return {\n",
-    "        \"MSE\": res[\"MSE\"].mean(),\n",
-    "        \"MAE\": res[\"MAE\"].mean(),\n",
-    "        \"IC\": res[\"IC\"].mean(),\n",
-    "        \"ICIR\": res[\"IC\"].mean() / res[\"IC\"].std(),\n",
-    "        \"AR\": r.mean() * 365,\n",
-    "        \"AV\": r.std() * 365**0.5,\n",
-    "        \"SR\": r.mean() / r.std() * 365**0.5,\n",
-    "        \"MDD\": (r.cumsum().cummax() - r.cumsum()).max(),\n",
-    "    }, r\n",
-    "\n",
-    "\n",
-    "def fmt(x, p=3, scale=1, std=False):\n",
-    "    _fmt = \"{:.%df}\" % p\n",
-    "    string = _fmt.format((x.mean() if not isinstance(x, (float, np.floating)) else x) * scale)\n",
-    "    if std and len(x) > 1:\n",
-    "        string += \" (\" + _fmt.format(x.std() * scale) + \")\"\n",
-    "    return string\n",
-    "\n",
-    "\n",
-    "def backtest_multi(files, **kwargs):\n",
-    "    res = []\n",
-    "    pnl = []\n",
-    "    for fname in files:\n",
-    "        metric, r = backtest(fname, **kwargs)\n",
-    "        res.append(metric)\n",
-    "        pnl.append(r)\n",
-    "    res = pd.DataFrame(res)\n",
-    "    pnl = pd.concat(pnl, axis=1)\n",
-    "    return {\n",
-    "        \"MSE\": fmt(res[\"MSE\"], std=True),\n",
-    "        \"MAE\": fmt(res[\"MAE\"], std=True),\n",
-    "        \"IC\": fmt(res[\"IC\"]),\n",
-    "        \"ICIR\": fmt(res[\"ICIR\"]),\n",
-    "        \"AR\": fmt(res[\"AR\"], scale=100, p=1) + \"%\",\n",
-    "        \"VR\": fmt(res[\"AV\"], scale=100, p=1) + \"%\",\n",
-    "        \"SR\": fmt(res[\"SR\"]),\n",
-    "        \"MDD\": fmt(res[\"MDD\"], scale=100, p=1) + \"%\",\n",
-    "    }, pnl"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# Preparation\n",
-    "\n",
-    "\n",
-    "You could prepare the source data as below for the backtest code:\n",
-    "1. Linear: see Qlib examples\n",
-    "2. LightGBM: see Qlib examples\n",
-    "3. MLP: see Qlib examples\n",
-    "4. SFM: see Qlib examples\n",
-    "5. ALSTM: `qrun` configs/config_alstm.yaml\n",
-    "6. Transformer: `qrun` configs/config_transformer.yaml\n",
-    "7. ALSTM+TRA: `qrun` configs/config_alstm_tra_init.yaml && `qrun` configs/config_alstm_tra.yaml\n",
-    "8. Tranformer+TRA: `qrun` configs/config_transformer_tra_init.yaml && `qrun` configs/config_transformer_tra.yaml"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "exps = {\n",
-    "    \"Linear\": [\"output/Linear/pred.pkl\"],\n",
-    "    \"LightGBM\": [\"output/GBDT/lr0.05_leaves128/pred.pkl\"],\n",
-    "    \"MLP\": glob.glob(\"output/search/MLP/hs128_bs512_do0.3_lr0.001_seed*/pred.pkl\"),\n",
-    "    \"SFM\": glob.glob(\"output/search/SFM/hs32_bs512_do0.5_lr0.001_seed*/pred.pkl\"),\n",
-    "    \"ALSTM\": glob.glob(\"output/search/LSTM_Attn/hs256_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n",
-    "    \"Trans.\": glob.glob(\"output/search/Transformer/head4_hs64_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n",
-    "    \"ALSTM+TS\": glob.glob(\"output/LSTM_Attn_TS/hs256_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n",
-    "    \"Trans.+TS\": glob.glob(\"output/Transformer_TS/head4_hs64_bs1024_do0.1_lr0.0002_seed*/pred.pkl\"),\n",
-    "    \"ALSTM+TRA(Ours)\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K10_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "    \"Trans.+TRA(Ours)\": glob.glob(\n",
-    "        \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb1.0_head4_hs64_bs512_do0.1_lr0.0005_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "}"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "metadata": {
-    "scrolled": true
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "0acd535e05944e539fd001009ed0748d",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/10 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "res = {name: backtest_multi(exps[name]) for name in tqdm(exps)}\n",
-    "report = pd.DataFrame({k: v[0] for k, v in res.items()}).T"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 4,
-   "metadata": {
-    "scrolled": true
-   },
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>MSE</th>\n",
-       "      <th>MAE</th>\n",
-       "      <th>IC</th>\n",
-       "      <th>ICIR</th>\n",
-       "      <th>AR</th>\n",
-       "      <th>VR</th>\n",
-       "      <th>SR</th>\n",
-       "      <th>MDD</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>Linear</th>\n",
-       "      <td>0.163</td>\n",
-       "      <td>0.327</td>\n",
-       "      <td>0.020</td>\n",
-       "      <td>0.132</td>\n",
-       "      <td>-3.2%</td>\n",
-       "      <td>16.8%</td>\n",
-       "      <td>-0.191</td>\n",
-       "      <td>32.1%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>LightGBM</th>\n",
-       "      <td>0.160</td>\n",
-       "      <td>0.323</td>\n",
-       "      <td>0.041</td>\n",
-       "      <td>0.292</td>\n",
-       "      <td>7.8%</td>\n",
-       "      <td>15.5%</td>\n",
-       "      <td>0.503</td>\n",
-       "      <td>25.7%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>MLP</th>\n",
-       "      <td>0.160 (0.002)</td>\n",
-       "      <td>0.323 (0.003)</td>\n",
-       "      <td>0.037</td>\n",
-       "      <td>0.273</td>\n",
-       "      <td>3.7%</td>\n",
-       "      <td>15.3%</td>\n",
-       "      <td>0.264</td>\n",
-       "      <td>26.2%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>SFM</th>\n",
-       "      <td>0.159 (0.001)</td>\n",
-       "      <td>0.321 (0.001)</td>\n",
-       "      <td>0.047</td>\n",
-       "      <td>0.381</td>\n",
-       "      <td>7.1%</td>\n",
-       "      <td>14.3%</td>\n",
-       "      <td>0.497</td>\n",
-       "      <td>22.9%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>ALSTM</th>\n",
-       "      <td>0.158 (0.001)</td>\n",
-       "      <td>0.320 (0.001)</td>\n",
-       "      <td>0.053</td>\n",
-       "      <td>0.419</td>\n",
-       "      <td>12.3%</td>\n",
-       "      <td>13.7%</td>\n",
-       "      <td>0.897</td>\n",
-       "      <td>20.2%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>Trans.</th>\n",
-       "      <td>0.158 (0.001)</td>\n",
-       "      <td>0.322 (0.001)</td>\n",
-       "      <td>0.051</td>\n",
-       "      <td>0.400</td>\n",
-       "      <td>14.5%</td>\n",
-       "      <td>14.2%</td>\n",
-       "      <td>1.028</td>\n",
-       "      <td>22.5%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>ALSTM+TS</th>\n",
-       "      <td>0.160 (0.002)</td>\n",
-       "      <td>0.321 (0.002)</td>\n",
-       "      <td>0.039</td>\n",
-       "      <td>0.291</td>\n",
-       "      <td>6.7%</td>\n",
-       "      <td>14.6%</td>\n",
-       "      <td>0.480</td>\n",
-       "      <td>22.3%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>Trans.+TS</th>\n",
-       "      <td>0.160 (0.004)</td>\n",
-       "      <td>0.324 (0.005)</td>\n",
-       "      <td>0.037</td>\n",
-       "      <td>0.278</td>\n",
-       "      <td>10.4%</td>\n",
-       "      <td>14.7%</td>\n",
-       "      <td>0.722</td>\n",
-       "      <td>23.7%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>ALSTM+TRA(Ours)</th>\n",
-       "      <td>0.157 (0.000)</td>\n",
-       "      <td>0.318 (0.000)</td>\n",
-       "      <td>0.059</td>\n",
-       "      <td>0.460</td>\n",
-       "      <td>12.4%</td>\n",
-       "      <td>14.0%</td>\n",
-       "      <td>0.885</td>\n",
-       "      <td>20.4%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>Trans.+TRA(Ours)</th>\n",
-       "      <td>0.157 (0.000)</td>\n",
-       "      <td>0.320 (0.000)</td>\n",
-       "      <td>0.056</td>\n",
-       "      <td>0.442</td>\n",
-       "      <td>16.1%</td>\n",
-       "      <td>14.2%</td>\n",
-       "      <td>1.133</td>\n",
-       "      <td>23.1%</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "                            MSE            MAE     IC   ICIR     AR     VR  \\\n",
-       "Linear                    0.163          0.327  0.020  0.132  -3.2%  16.8%   \n",
-       "LightGBM                  0.160          0.323  0.041  0.292   7.8%  15.5%   \n",
-       "MLP               0.160 (0.002)  0.323 (0.003)  0.037  0.273   3.7%  15.3%   \n",
-       "SFM               0.159 (0.001)  0.321 (0.001)  0.047  0.381   7.1%  14.3%   \n",
-       "ALSTM             0.158 (0.001)  0.320 (0.001)  0.053  0.419  12.3%  13.7%   \n",
-       "Trans.            0.158 (0.001)  0.322 (0.001)  0.051  0.400  14.5%  14.2%   \n",
-       "ALSTM+TS          0.160 (0.002)  0.321 (0.002)  0.039  0.291   6.7%  14.6%   \n",
-       "Trans.+TS         0.160 (0.004)  0.324 (0.005)  0.037  0.278  10.4%  14.7%   \n",
-       "ALSTM+TRA(Ours)   0.157 (0.000)  0.318 (0.000)  0.059  0.460  12.4%  14.0%   \n",
-       "Trans.+TRA(Ours)  0.157 (0.000)  0.320 (0.000)  0.056  0.442  16.1%  14.2%   \n",
-       "\n",
-       "                      SR    MDD  \n",
-       "Linear            -0.191  32.1%  \n",
-       "LightGBM           0.503  25.7%  \n",
-       "MLP                0.264  26.2%  \n",
-       "SFM                0.497  22.9%  \n",
-       "ALSTM              0.897  20.2%  \n",
-       "Trans.             1.028  22.5%  \n",
-       "ALSTM+TS           0.480  22.3%  \n",
-       "Trans.+TS          0.722  23.7%  \n",
-       "ALSTM+TRA(Ours)    0.885  20.4%  \n",
-       "Trans.+TRA(Ours)   1.133  23.1%  "
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "report\n",
-    "# print(report.to_latex())"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# RQ1\n",
-    "\n",
-    "Case study"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "image/png": "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",
-      "text/plain": [
-       "<Figure size 504x216 with 2 Axes>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "df = pd.read_pickle(\n",
-    "    \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb0.0_head4_hs64_bs512_do0.1_lr0.0005_seed1000/pred.pkl\"\n",
-    ")\n",
-    "code = \"SH600157\"\n",
-    "date = \"2018-09-28\"\n",
-    "lookbackperiod = 50\n",
-    "\n",
-    "prob = df.iloc[:, -3:].loc(axis=0)[:, code].reset_index(level=1, drop=True).loc[date:].iloc[:lookbackperiod]\n",
-    "pred = (\n",
-    "    df.loc[:, [\"score_0\", \"score_1\", \"score_2\", \"label\"]]\n",
-    "    .loc(axis=0)[:, code]\n",
-    "    .reset_index(level=1, drop=True)\n",
-    "    .loc[date:]\n",
-    "    .iloc[:lookbackperiod]\n",
-    ")\n",
-    "e_all = pred.iloc[:, :-1].sub(pred.iloc[:, -1], axis=0).pow(2)\n",
-    "e_all = e_all.sub(e_all.min(axis=1), axis=0)\n",
-    "e_all.columns = [r\"$\\theta_%d$\" % d for d in range(1, 4)]\n",
-    "prob = pd.Series(np.argmax(prob.values, axis=1), index=prob.index).rolling(7).mean().round()\n",
-    "\n",
-    "fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
-    "e_all.plot(ax=axes[0], xlabel=\"\", rot=30)\n",
-    "prob.plot(\n",
-    "    ax=axes[1],\n",
-    "    xlabel=\"\",\n",
-    "    rot=30,\n",
-    "    color=\"red\",\n",
-    "    linestyle=\"None\",\n",
-    "    marker=\"^\",\n",
-    "    markersize=5,\n",
-    ")\n",
-    "plt.yticks(np.array([0, 1, 2]), e_all.columns.values)\n",
-    "axes[0].set_ylabel(\"Predictor Loss\")\n",
-    "axes[1].set_ylabel(\"Router Selection\")\n",
-    "plt.tight_layout()\n",
-    "# plt.savefig('select.pdf', bbox_inches='tight')\n",
-    "plt.show()"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# RQ2\n",
-    "\n",
-    "You could prepared the source data for this test as below:\n",
-    "1. Random: Setting `src_info` = \"NONE\"\n",
-    "2. LR: Setting `src_info` = \"LR\"\n",
-    "3. TPE: Setting `src_info` = \"TPE\"\n",
-    "4. LR+TPE: Setting `src_info` = \"LR_TPE\""
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "exps = {\n",
-    "    \"Random\": glob.glob(\n",
-    "        \"output/search/LSTM_Attn_tra/K10_traHs16_traSrcNONE_traLamb1.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "    \"LR\": glob.glob(\n",
-    "        \"output/search/LSTM_Attn_tra/K10_traHs16_traSrcLR_traLamb1.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "    \"TPE\": glob.glob(\n",
-    "        \"output/search/LSTM_Attn_tra/K10_traHs16_traSrcTPE_traLamb1.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "    \"LR+TPE\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K10_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/pred.pkl\"\n",
-    "    ),\n",
-    "}"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 7,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "910721fc4a7b46eea5ba6d50647320d4",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "res = {name: backtest_multi(exps[name]) for name in tqdm(exps)}\n",
-    "report = pd.DataFrame({k: v[0] for k, v in res.items()}).T"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {
-    "scrolled": true
-   },
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>MSE</th>\n",
-       "      <th>MAE</th>\n",
-       "      <th>IC</th>\n",
-       "      <th>ICIR</th>\n",
-       "      <th>AR</th>\n",
-       "      <th>VR</th>\n",
-       "      <th>SR</th>\n",
-       "      <th>MDD</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>Random</th>\n",
-       "      <td>0.159 (0.001)</td>\n",
-       "      <td>0.321 (0.002)</td>\n",
-       "      <td>0.048</td>\n",
-       "      <td>0.362</td>\n",
-       "      <td>11.4%</td>\n",
-       "      <td>14.1%</td>\n",
-       "      <td>0.810</td>\n",
-       "      <td>21.1%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>LR</th>\n",
-       "      <td>0.158 (0.001)</td>\n",
-       "      <td>0.320 (0.001)</td>\n",
-       "      <td>0.053</td>\n",
-       "      <td>0.409</td>\n",
-       "      <td>10.3%</td>\n",
-       "      <td>13.4%</td>\n",
-       "      <td>0.772</td>\n",
-       "      <td>20.8%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>TPE</th>\n",
-       "      <td>0.158 (0.001)</td>\n",
-       "      <td>0.321 (0.001)</td>\n",
-       "      <td>0.049</td>\n",
-       "      <td>0.381</td>\n",
-       "      <td>10.3%</td>\n",
-       "      <td>14.0%</td>\n",
-       "      <td>0.741</td>\n",
-       "      <td>21.2%</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>LR+TPE</th>\n",
-       "      <td>0.157 (0.000)</td>\n",
-       "      <td>0.318 (0.000)</td>\n",
-       "      <td>0.059</td>\n",
-       "      <td>0.460</td>\n",
-       "      <td>12.4%</td>\n",
-       "      <td>14.0%</td>\n",
-       "      <td>0.885</td>\n",
-       "      <td>20.4%</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "                  MSE            MAE     IC   ICIR     AR     VR     SR    MDD\n",
-       "Random  0.159 (0.001)  0.321 (0.002)  0.048  0.362  11.4%  14.1%  0.810  21.1%\n",
-       "LR      0.158 (0.001)  0.320 (0.001)  0.053  0.409  10.3%  13.4%  0.772  20.8%\n",
-       "TPE     0.158 (0.001)  0.321 (0.001)  0.049  0.381  10.3%  14.0%  0.741  21.2%\n",
-       "LR+TPE  0.157 (0.000)  0.318 (0.000)  0.059  0.460  12.4%  14.0%  0.885  20.4%"
-      ]
-     },
-     "execution_count": 8,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "report\n",
-    "# print(report.to_latex())"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# RQ3\n",
-    "\n",
-    "Set `lamb` = 0 to obtain results without Optimal Transport(OT)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "image/png": "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",
-      "text/plain": [
-       "<Figure size 360x288 with 1 Axes>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "a = pd.read_pickle(\n",
-    "    \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb0.0_head4_hs64_bs512_do0.1_lr0.0005_seed3000/pred.pkl\"\n",
-    ")\n",
-    "b = pd.read_pickle(\n",
-    "    \"output/search/finetune/Transformer_tra/K3_traHs16_traSrcLR_TPE_traLamb2.0_head4_hs64_bs512_do0.1_lr0.0005_seed3000/pred.pkl\"\n",
-    ")\n",
-    "a = a.iloc[:, -3:]\n",
-    "b = b.iloc[:, -3:]\n",
-    "b = np.eye(3)[b.values.argmax(axis=1)]\n",
-    "a = np.eye(3)[a.values.argmax(axis=1)]\n",
-    "\n",
-    "res = pd.DataFrame(\n",
-    "    {\"with OT\": b.sum(axis=0) / b.sum(), \"without OT\": a.sum(axis=0) / a.sum()},\n",
-    "    index=[r\"$\\theta_1$\", r\"$\\theta_2$\", r\"$\\theta_3$\"],\n",
-    ")\n",
-    "res.plot.bar(rot=30, figsize=(5, 4), color=[\"b\", \"g\"])\n",
-    "del a, b"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# RQ4\n",
-    "\n",
-    "You could prepared the source data for this test as below:\n",
-    "1. K=1: which is exactly the alstm model\n",
-    "2. K=3: Setting `num_states` = 3\n",
-    "3. K=5: Setting `num_states` = 5\n",
-    "4. K=10: Setting `num_states` = 10\n",
-    "5. K=20: Setting `num_states` = 20\n"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 10,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "exps = {\n",
-    "    \"K=1\": glob.glob(\"output/search/LSTM_Attn/hs256_bs1024_do0.1_lr0.0002_seed*/info.json\"),\n",
-    "    \"K=3\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K3_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/info.json\"\n",
-    "    ),\n",
-    "    \"K=5\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K5_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/info.json\"\n",
-    "    ),\n",
-    "    \"K=10\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K10_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/info.json\"\n",
-    "    ),\n",
-    "    \"K=20\": glob.glob(\n",
-    "        \"output/search/finetune/LSTM_Attn_tra/K20_traHs16_traSrcLR_TPE_traLamb2.0_hs256_bs1024_do0.1_lr0.0001_seed*/info.json\"\n",
-    "    ),\n",
-    "}"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 11,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "report = dict()\n",
-    "for k, v in exps.items():\n",
-    "    tmp = dict()\n",
-    "    for fname in v:\n",
-    "        with open(fname) as f:\n",
-    "            info = json.load(f)\n",
-    "        tmp[fname] = {\"IC\": info[\"metric\"][\"IC\"], \"MSE\": info[\"metric\"][\"MSE\"]}\n",
-    "    tmp = pd.DataFrame(tmp).T\n",
-    "    report[k] = tmp.mean()\n",
-    "report = pd.DataFrame(report).T"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 12,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "image/png": "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",
-      "text/plain": [
-       "<Figure size 432x216 with 2 Axes>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
-   "source": [
-    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
-    "axes = axes.flatten()\n",
-    "report[\"IC\"].plot.bar(rot=30, ax=axes[0])\n",
-    "axes[0].set_ylim(0.045, 0.062)\n",
-    "axes[0].set_title(\"IC performance\")\n",
-    "report[\"MSE\"].astype(float).plot.bar(rot=30, ax=axes[1], color=\"green\")\n",
-    "axes[1].set_ylim(0.155, 0.1585)\n",
-    "axes[1].set_title(\"MSE performance\")\n",
-    "plt.tight_layout()\n",
-    "# plt.savefig('sensitivity.pdf')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 13,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>IC</th>\n",
-       "      <th>MSE</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>K=1</th>\n",
-       "      <td>0.053247</td>\n",
-       "      <td>0.157792</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>K=3</th>\n",
-       "      <td>0.055535</td>\n",
-       "      <td>0.157410</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>K=5</th>\n",
-       "      <td>0.059224</td>\n",
-       "      <td>0.156796</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>K=10</th>\n",
-       "      <td>0.059403</td>\n",
-       "      <td>0.156766</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>K=20</th>\n",
-       "      <td>0.059193</td>\n",
-       "      <td>0.156801</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "            IC       MSE\n",
-       "K=1   0.053247  0.157792\n",
-       "K=3   0.055535  0.157410\n",
-       "K=5   0.059224  0.156796\n",
-       "K=10  0.059403  0.156766\n",
-       "K=20  0.059193  0.156801"
-      ]
-     },
-     "execution_count": 13,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "report"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  }
- ],
- "metadata": {
-  "interpreter": {
-   "hash": "9de784e21d4a351f53a5792b09a6ae66a23802b850ad98f62e10c0156e418c04"
-  },
-  "kernelspec": {
-   "display_name": "Python 3.8.5 64-bit ('base': conda)",
-   "name": "python3"
-  },
-  "language_info": {
-   "name": "python",
-   "version": ""
-  }
- },
- "nbformat": 4,
- "nbformat_minor": 5
-}
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_alstm.yaml b/examples/benchmarks/TRA/configs/config_alstm.yaml
deleted file mode 100644
index 573745e7..00000000
--- a/examples/benchmarks/TRA/configs/config_alstm.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 256
-  num_layers: 2
-  num_heads: 2
-  use_attn: True
-  dropout: 0.1
-
-num_states: &num_states 1
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0002
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/alstm
-      model_type: LSTM
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 1.0
-      rho: 0.99
-      freeze_model: False
-      model_init_state: 
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 1024
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_alstm_tra.yaml b/examples/benchmarks/TRA/configs/config_alstm_tra.yaml
deleted file mode 100644
index aa18f4f3..00000000
--- a/examples/benchmarks/TRA/configs/config_alstm_tra.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 256
-  num_layers: 2
-  num_heads: 2
-  use_attn: True
-  dropout: 0.1
-
-num_states: &num_states 10
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0001
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/alstm_tra
-      model_type: LSTM
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 2.0
-      rho: 0.99
-      freeze_model: True
-      model_init_state: output/test/alstm_tra_init/model.bin
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 1024
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_alstm_tra_init.yaml b/examples/benchmarks/TRA/configs/config_alstm_tra_init.yaml
deleted file mode 100644
index 0f5b9269..00000000
--- a/examples/benchmarks/TRA/configs/config_alstm_tra_init.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 256
-  num_layers: 2
-  num_heads: 2
-  use_attn: True
-  dropout: 0.1
-
-num_states: &num_states 3
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0002
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/alstm_tra_init
-      model_type: LSTM
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 1.0
-      rho: 0.99
-      freeze_model: False
-      model_init_state: 
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 512
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_transformer.yaml b/examples/benchmarks/TRA/configs/config_transformer.yaml
deleted file mode 100644
index 2ffbe20b..00000000
--- a/examples/benchmarks/TRA/configs/config_transformer.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 64
-  num_layers: 2
-  num_heads: 4
-  use_attn: False
-  dropout: 0.1
-
-num_states: &num_states 1
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0002
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/transformer
-      model_type: Transformer
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 1.0
-      rho: 0.99
-      freeze_model: False
-      model_init_state: 
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 1024
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_transformer_tra.yaml b/examples/benchmarks/TRA/configs/config_transformer_tra.yaml
deleted file mode 100644
index e68bcc45..00000000
--- a/examples/benchmarks/TRA/configs/config_transformer_tra.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 64
-  num_layers: 2
-  num_heads: 4
-  use_attn: False
-  dropout: 0.1
-
-num_states: &num_states 3
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0005
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/transformer_tra
-      model_type: Transformer
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 1.0
-      rho: 0.99
-      freeze_model: True
-      model_init_state: output/test/transformer_tra_init/model.bin
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 512
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/configs/config_transformer_tra_init.yaml b/examples/benchmarks/TRA/configs/config_transformer_tra_init.yaml
deleted file mode 100644
index 927e74e5..00000000
--- a/examples/benchmarks/TRA/configs/config_transformer_tra_init.yaml
+++ /dev/null
@@ -1,63 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-data_loader_config: &data_loader_config
-  class: StaticDataLoader
-  module_path: qlib.data.dataset.loader
-  kwargs:
-    config:
-      feature: data/feature.pkl
-      label: data/label.pkl
-
-model_config: &model_config
-  input_size: 16
-  hidden_size: 64
-  num_layers: 2
-  num_heads: 4
-  use_attn: False
-  dropout: 0.1
-
-num_states: &num_states 3
-
-tra_config: &tra_config
-  num_states: *num_states
-  hidden_size: 16
-  tau: 1.0
-  src_info: LR_TPE
-
-task:
-  model:
-    class: TRAModel
-    module_path: src/model.py
-    kwargs:
-      lr: 0.0002
-      n_epochs: 500
-      max_steps_per_epoch: 100
-      early_stop: 20
-      seed: 1000
-      logdir: output/test/transformer_tra_init
-      model_type: Transformer
-      model_config: *model_config
-      tra_config: *tra_config
-      lamb: 1.0
-      rho: 0.99
-      freeze_model: False
-      model_init_state: 
-  dataset:
-    class: MTSDatasetH
-    module_path: src/dataset.py
-    kwargs:
-      handler:
-        class: DataHandler
-        module_path: qlib.data.dataset.handler
-        kwargs:
-          data_loader: *data_loader_config
-      segments:
-        train: [2007-10-30, 2016-05-27]
-        valid: [2016-09-26, 2018-05-29]
-        test: [2018-09-21, 2020-06-30]
-      seq_len: 60
-      horizon: 21
-      num_states: *num_states
-      batch_size: 512
\ No newline at end of file
diff --git a/examples/benchmarks/TRA/data/README.md b/examples/benchmarks/TRA/data/README.md
deleted file mode 100644
index 2362fbf1..00000000
--- a/examples/benchmarks/TRA/data/README.md
+++ /dev/null
@@ -1 +0,0 @@
-Data Link: https://drive.google.com/drive/folders/1fMqZYSeLyrHiWmVzygeI4sw3vp5Gt8cY?usp=sharing
diff --git a/examples/benchmarks/TRA/example.py b/examples/benchmarks/TRA/example.py
deleted file mode 100644
index 0d52c877..00000000
--- a/examples/benchmarks/TRA/example.py
+++ /dev/null
@@ -1,37 +0,0 @@
-import argparse
-
-import qlib
-import ruamel.yaml as yaml
-from qlib.utils import init_instance_by_config
-
-
-def main(seed, config_file="configs/config_alstm.yaml"):
-    # set random seed
-    with open(config_file) as f:
-        config = yaml.safe_load(f)
-
-    # seed_suffix = "/seed1000" if "init" in config_file else f"/seed{seed}"
-    seed_suffix = ""
-    config["task"]["model"]["kwargs"].update(
-        {"seed": seed, "logdir": config["task"]["model"]["kwargs"]["logdir"] + seed_suffix}
-    )
-
-    # initialize workflow
-    qlib.init(
-        provider_uri=config["qlib_init"]["provider_uri"],
-        region=config["qlib_init"]["region"],
-    )
-    dataset = init_instance_by_config(config["task"]["dataset"])
-    model = init_instance_by_config(config["task"]["model"])
-
-    # train model
-    model.fit(dataset)
-
-
-if __name__ == "__main__":
-    # set params from cmd
-    parser = argparse.ArgumentParser(allow_abbrev=False)
-    parser.add_argument("--seed", type=int, default=1000, help="random seed")
-    parser.add_argument("--config_file", type=str, default="configs/config_alstm.yaml", help="config file")
-    args = parser.parse_args()
-    main(**vars(args))
diff --git a/examples/benchmarks/TRA/requirements.txt b/examples/benchmarks/TRA/requirements.txt
deleted file mode 100644
index e46f8338..00000000
--- a/examples/benchmarks/TRA/requirements.txt
+++ /dev/null
@@ -1,5 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
-seaborn
diff --git a/examples/benchmarks/TRA/run.sh b/examples/benchmarks/TRA/run.sh
deleted file mode 100644
index d9428b29..00000000
--- a/examples/benchmarks/TRA/run.sh
+++ /dev/null
@@ -1,29 +0,0 @@
-#!/bin/bash
-
-# we used random seed(1 1000 2000 3000 4000 5000) in our experiments 
-
-# Directly run from Qlib command `qrun`
-qrun configs/config_alstm.yaml
-
-qrun configs/config_transformer.yaml
-
-qrun configs/config_transformer_tra_init.yaml
-qrun configs/config_transformer_tra.yaml
-
-qrun configs/config_alstm_tra_init.yaml
-qrun configs/config_alstm_tra.yaml
-
-
-# Or setting different parameters with example.py
-python example.py --config_file configs/config_alstm.yaml
-
-python example.py --config_file configs/config_transformer.yaml
-
-python example.py --config_file configs/config_transformer_tra_init.yaml
-python example.py --config_file configs/config_transformer_tra.yaml
-
-python example.py --config_file configs/config_alstm_tra_init.yaml
-python example.py --config_file configs/config_alstm_tra.yaml
-
-
-
diff --git a/examples/benchmarks/TRA/src/dataset.py b/examples/benchmarks/TRA/src/dataset.py
deleted file mode 100644
index de4b2ad4..00000000
--- a/examples/benchmarks/TRA/src/dataset.py
+++ /dev/null
@@ -1,257 +0,0 @@
-# Copyright (c) Microsoft Corporation.
-# Licensed under the MIT License.
-
-import copy
-import torch
-import numpy as np
-import pandas as pd
-
-from qlib.data.dataset import DatasetH
-
-
-device = "cuda" if torch.cuda.is_available() else "cpu"
-
-
-def _to_tensor(x):
-    if not isinstance(x, torch.Tensor):
-        return torch.tensor(x, dtype=torch.float, device=device)
-    return x
-
-
-def _create_ts_slices(index, seq_len):
-    """
-    create time series slices from pandas index
-
-    Args:
-        index (pd.MultiIndex): pandas multiindex with <instrument, datetime> order
-        seq_len (int): sequence length
-    """
-    assert index.is_lexsorted(), "index should be sorted"
-
-    # number of dates for each code
-    sample_count_by_codes = pd.Series(0, index=index).groupby(level=0).size().values
-
-    # start_index for each code
-    start_index_of_codes = np.roll(np.cumsum(sample_count_by_codes), 1)
-    start_index_of_codes[0] = 0
-
-    # all the [start, stop) indices of features
-    # features btw [start, stop) are used to predict the `stop - 1` label
-    slices = []
-    for cur_loc, cur_cnt in zip(start_index_of_codes, sample_count_by_codes):
-        for stop in range(1, cur_cnt + 1):
-            end = cur_loc + stop
-            start = max(end - seq_len, 0)
-            slices.append(slice(start, end))
-    slices = np.array(slices)
-
-    return slices
-
-
-def _get_date_parse_fn(target):
-    """get date parse function
-
-    This method is used to parse date arguments as target type.
-
-    Example:
-        get_date_parse_fn('20120101')('2017-01-01') => '20170101'
-        get_date_parse_fn(20120101)('2017-01-01') => 20170101
-    """
-    if isinstance(target, pd.Timestamp):
-        _fn = lambda x: pd.Timestamp(x)  # Timestamp('2020-01-01')
-    elif isinstance(target, str) and len(target) == 8:
-        _fn = lambda x: str(x).replace("-", "")[:8]  # '20200201'
-    elif isinstance(target, int):
-        _fn = lambda x: int(str(x).replace("-", "")[:8])  # 20200201
-    else:
-        _fn = lambda x: x
-    return _fn
-
-
-class MTSDatasetH(DatasetH):
-    """Memory Augmented Time Series Dataset
-
-    Args:
-        handler (DataHandler): data handler
-        segments (dict): data split segments
-        seq_len (int): time series sequence length
-        horizon (int): label horizon (to mask historical loss for TRA)
-        num_states (int): how many memory states to be added (for TRA)
-        batch_size (int): batch size (<0 means daily batch)
-        shuffle (bool): whether shuffle data
-        pin_memory (bool): whether pin data to gpu memory
-        drop_last (bool): whether drop last batch < batch_size
-    """
-
-    def __init__(
-        self,
-        handler,
-        segments,
-        seq_len=60,
-        horizon=0,
-        num_states=1,
-        batch_size=-1,
-        shuffle=True,
-        pin_memory=False,
-        drop_last=False,
-        **kwargs,
-    ):
-        assert horizon > 0, "please specify `horizon` to avoid data leakage"
-
-        self.seq_len = seq_len
-        self.horizon = horizon
-        self.num_states = num_states
-        self.batch_size = batch_size
-        self.shuffle = shuffle
-        self.drop_last = drop_last
-        self.pin_memory = pin_memory
-        self.params = (batch_size, drop_last, shuffle)  # for train/eval switch
-
-        super().__init__(handler, segments, **kwargs)
-
-    def setup_data(self, handler_kwargs: dict = None, **kwargs):
-        super().setup_data()
-
-        # change index to <code, date>
-        # NOTE: we will use inplace sort to reduce memory use
-        df = self.handler._data
-        df.index = df.index.swaplevel()
-        df.sort_index(inplace=True)
-
-        self._data = df["feature"].values.astype("float32")
-        self._label = df["label"].squeeze().astype("float32")
-        self._index = df.index
-
-        # add memory to feature
-        self._data = np.c_[self._data, np.zeros((len(self._data), self.num_states), dtype=np.float32)]
-
-        # padding tensor
-        self.zeros = np.zeros((self.seq_len, self._data.shape[1]), dtype=np.float32)
-
-        # pin memory
-        if self.pin_memory:
-            self._data = _to_tensor(self._data)
-            self._label = _to_tensor(self._label)
-            self.zeros = _to_tensor(self.zeros)
-
-        # create batch slices
-        self.batch_slices = _create_ts_slices(self._index, self.seq_len)
-
-        # create daily slices
-        index = [slc.stop - 1 for slc in self.batch_slices]
-        act_index = self.restore_index(index)
-        daily_slices = {date: [] for date in sorted(act_index.unique(level=1))}
-        for i, (code, date) in enumerate(act_index):
-            daily_slices[date].append(self.batch_slices[i])
-        self.daily_slices = list(daily_slices.values())
-
-    def _prepare_seg(self, slc, **kwargs):
-        fn = _get_date_parse_fn(self._index[0][1])
-
-        if isinstance(slc, slice):
-            start, stop = slc.start, slc.stop
-        elif isinstance(slc, (list, tuple)):
-            start, stop = slc
-        else:
-            raise NotImplementedError(f"This type of input is not supported")
-        start_date = fn(start)
-        end_date = fn(stop)
-        obj = copy.copy(self)  # shallow copy
-        # NOTE: Seriable will disable copy `self._data` so we manually assign them here
-        obj._data = self._data
-        obj._label = self._label
-        obj._index = self._index
-        new_batch_slices = []
-        for batch_slc in self.batch_slices:
-            date = self._index[batch_slc.stop - 1][1]
-            if start_date <= date <= end_date:
-                new_batch_slices.append(batch_slc)
-        obj.batch_slices = np.array(new_batch_slices)
-        new_daily_slices = []
-        for daily_slc in self.daily_slices:
-            date = self._index[daily_slc[0].stop - 1][1]
-            if start_date <= date <= end_date:
-                new_daily_slices.append(daily_slc)
-        obj.daily_slices = new_daily_slices
-        return obj
-
-    def restore_index(self, index):
-        if isinstance(index, torch.Tensor):
-            index = index.cpu().numpy()
-        return self._index[index]
-
-    def assign_data(self, index, vals):
-        if isinstance(self._data, torch.Tensor):
-            vals = _to_tensor(vals)
-        elif isinstance(vals, torch.Tensor):
-            vals = vals.detach().cpu().numpy()
-            index = index.detach().cpu().numpy()
-        self._data[index, -self.num_states :] = vals
-
-    def clear_memory(self):
-        self._data[:, -self.num_states :] = 0
-
-    # TODO: better train/eval mode design
-    def train(self):
-        """enable traning mode"""
-        self.batch_size, self.drop_last, self.shuffle = self.params
-
-    def eval(self):
-        """enable evaluation mode"""
-        self.batch_size = -1
-        self.drop_last = False
-        self.shuffle = False
-
-    def _get_slices(self):
-        if self.batch_size < 0:
-            slices = self.daily_slices.copy()
-            batch_size = -1 * self.batch_size
-        else:
-            slices = self.batch_slices.copy()
-            batch_size = self.batch_size
-        return slices, batch_size
-
-    def __len__(self):
-        slices, batch_size = self._get_slices()
-        if self.drop_last:
-            return len(slices) // batch_size
-        return (len(slices) + batch_size - 1) // batch_size
-
-    def __iter__(self):
-        slices, batch_size = self._get_slices()
-        if self.shuffle:
-            np.random.shuffle(slices)
-
-        for i in range(len(slices))[::batch_size]:
-            if self.drop_last and i + batch_size > len(slices):
-                break
-            # get slices for this batch
-            slices_subset = slices[i : i + batch_size]
-            if self.batch_size < 0:
-                slices_subset = np.concatenate(slices_subset)
-            # collect data
-            data = []
-            label = []
-            index = []
-            for slc in slices_subset:
-                _data = self._data[slc].clone() if self.pin_memory else self._data[slc].copy()
-                if len(_data) != self.seq_len:
-                    if self.pin_memory:
-                        _data = torch.cat([self.zeros[: self.seq_len - len(_data)], _data], axis=0)
-                    else:
-                        _data = np.concatenate([self.zeros[: self.seq_len - len(_data)], _data], axis=0)
-                if self.num_states > 0:
-                    _data[-self.horizon :, -self.num_states :] = 0
-                data.append(_data)
-                label.append(self._label[slc.stop - 1])
-                index.append(slc.stop - 1)
-            # concate
-            index = torch.tensor(index, device=device)
-            if isinstance(data[0], torch.Tensor):
-                data = torch.stack(data)
-                label = torch.stack(label)
-            else:
-                data = _to_tensor(np.stack(data))
-                label = _to_tensor(np.stack(label))
-            # yield -> generator
-            yield {"data": data, "label": label, "index": index}
diff --git a/examples/benchmarks/TRA/src/model.py b/examples/benchmarks/TRA/src/model.py
deleted file mode 100644
index ebafd6a5..00000000
--- a/examples/benchmarks/TRA/src/model.py
+++ /dev/null
@@ -1,593 +0,0 @@
-# Copyright (c) Microsoft Corporation.
-# Licensed under the MIT License.
-
-import os
-import copy
-import math
-import json
-import collections
-import numpy as np
-import pandas as pd
-
-import torch
-import torch.nn as nn
-import torch.optim as optim
-import torch.nn.functional as F
-
-from tqdm import tqdm
-
-from qlib.utils import get_or_create_path
-from qlib.log import get_module_logger
-from qlib.model.base import Model
-
-device = "cuda" if torch.cuda.is_available() else "cpu"
-
-
-class TRAModel(Model):
-    def __init__(
-        self,
-        model_config,
-        tra_config,
-        model_type="LSTM",
-        lr=1e-3,
-        n_epochs=500,
-        early_stop=50,
-        smooth_steps=5,
-        max_steps_per_epoch=None,
-        freeze_model=False,
-        model_init_state=None,
-        lamb=0.0,
-        rho=0.99,
-        seed=None,
-        logdir=None,
-        eval_train=True,
-        eval_test=False,
-        avg_params=True,
-        **kwargs,
-    ):
-        np.random.seed(seed)
-        torch.manual_seed(seed)
-
-        self.logger = get_module_logger("TRA")
-        self.logger.info("TRA Model...")
-
-        self.model = eval(model_type)(**model_config).to(device)
-        if model_init_state:
-            self.model.load_state_dict(torch.load(model_init_state, map_location="cpu")["model"])
-        if freeze_model:
-            for param in self.model.parameters():
-                param.requires_grad_(False)
-        else:
-            self.logger.info("# model params: %d" % sum([p.numel() for p in self.model.parameters()]))
-
-        self.tra = TRA(self.model.output_size, **tra_config).to(device)
-        self.logger.info("# tra params: %d" % sum([p.numel() for p in self.tra.parameters()]))
-
-        self.optimizer = optim.Adam(list(self.model.parameters()) + list(self.tra.parameters()), lr=lr)
-
-        self.model_config = model_config
-        self.tra_config = tra_config
-        self.lr = lr
-        self.n_epochs = n_epochs
-        self.early_stop = early_stop
-        self.smooth_steps = smooth_steps
-        self.max_steps_per_epoch = max_steps_per_epoch
-        self.lamb = lamb
-        self.rho = rho
-        self.seed = seed
-        self.logdir = logdir
-        self.eval_train = eval_train
-        self.eval_test = eval_test
-        self.avg_params = avg_params
-
-        if self.tra.num_states > 1 and not self.eval_train:
-            self.logger.warn("`eval_train` will be ignored when using TRA")
-
-        if self.logdir is not None:
-            if os.path.exists(self.logdir):
-                self.logger.warn(f"logdir {self.logdir} is not empty")
-            os.makedirs(self.logdir, exist_ok=True)
-
-        self.fitted = False
-        self.global_step = -1
-
-    def train_epoch(self, data_set):
-        self.model.train()
-        self.tra.train()
-
-        data_set.train()
-
-        max_steps = self.n_epochs
-        if self.max_steps_per_epoch is not None:
-            max_steps = min(self.max_steps_per_epoch, self.n_epochs)
-
-        count = 0
-        total_loss = 0
-        total_count = 0
-        for batch in tqdm(data_set, total=max_steps):
-            count += 1
-            if count > max_steps:
-                break
-
-            self.global_step += 1
-
-            data, label, index = batch["data"], batch["label"], batch["index"]
-
-            feature = data[:, :, : -self.tra.num_states]
-            hist_loss = data[:, : -data_set.horizon, -self.tra.num_states :]
-
-            hidden = self.model(feature)
-            pred, all_preds, prob = self.tra(hidden, hist_loss)
-
-            loss = (pred - label).pow(2).mean()
-
-            L = (all_preds.detach() - label[:, None]).pow(2)
-            L -= L.min(dim=-1, keepdim=True).values  # normalize & ensure positive input
-
-            data_set.assign_data(index, L)  # save loss to memory
-
-            if prob is not None:
-                P = sinkhorn(-L, epsilon=0.01)  # sample assignment matrix
-                lamb = self.lamb * (self.rho**self.global_step)
-                reg = prob.log().mul(P).sum(dim=-1).mean()
-                loss = loss - lamb * reg
-
-            loss.backward()
-            self.optimizer.step()
-            self.optimizer.zero_grad()
-
-            total_loss += loss.item()
-            total_count += len(pred)
-
-        total_loss /= total_count
-
-        return total_loss
-
-    def test_epoch(self, data_set, return_pred=False):
-        self.model.eval()
-        self.tra.eval()
-        data_set.eval()
-
-        preds = []
-        metrics = []
-        for batch in tqdm(data_set):
-            data, label, index = batch["data"], batch["label"], batch["index"]
-
-            feature = data[:, :, : -self.tra.num_states]
-            hist_loss = data[:, : -data_set.horizon, -self.tra.num_states :]
-
-            with torch.no_grad():
-                hidden = self.model(feature)
-                pred, all_preds, prob = self.tra(hidden, hist_loss)
-
-            L = (all_preds - label[:, None]).pow(2)
-
-            L -= L.min(dim=-1, keepdim=True).values  # normalize & ensure positive input
-
-            data_set.assign_data(index, L)  # save loss to memory
-
-            X = np.c_[
-                pred.cpu().numpy(),
-                label.cpu().numpy(),
-            ]
-            columns = ["score", "label"]
-            if prob is not None:
-                X = np.c_[X, all_preds.cpu().numpy(), prob.cpu().numpy()]
-                columns += ["score_%d" % d for d in range(all_preds.shape[1])] + [
-                    "prob_%d" % d for d in range(all_preds.shape[1])
-                ]
-
-            pred = pd.DataFrame(X, index=index.cpu().numpy(), columns=columns)
-
-            metrics.append(evaluate(pred))
-
-            if return_pred:
-                preds.append(pred)
-
-        metrics = pd.DataFrame(metrics)
-        metrics = {
-            "MSE": metrics.MSE.mean(),
-            "MAE": metrics.MAE.mean(),
-            "IC": metrics.IC.mean(),
-            "ICIR": metrics.IC.mean() / metrics.IC.std(),
-        }
-
-        if return_pred:
-            preds = pd.concat(preds, axis=0)
-            preds.index = data_set.restore_index(preds.index)
-            preds.index = preds.index.swaplevel()
-            preds.sort_index(inplace=True)
-
-        return metrics, preds
-
-    def fit(self, dataset, evals_result=dict()):
-        train_set, valid_set, test_set = dataset.prepare(["train", "valid", "test"])
-
-        best_score = -1
-        best_epoch = 0
-        stop_rounds = 0
-        best_params = {
-            "model": copy.deepcopy(self.model.state_dict()),
-            "tra": copy.deepcopy(self.tra.state_dict()),
-        }
-        params_list = {
-            "model": collections.deque(maxlen=self.smooth_steps),
-            "tra": collections.deque(maxlen=self.smooth_steps),
-        }
-        evals_result["train"] = []
-        evals_result["valid"] = []
-        evals_result["test"] = []
-
-        # train
-        self.fitted = True
-        self.global_step = -1
-
-        if self.tra.num_states > 1:
-            self.logger.info("init memory...")
-            self.test_epoch(train_set)
-
-        for epoch in range(self.n_epochs):
-            self.logger.info("Epoch %d:", epoch)
-
-            self.logger.info("training...")
-            self.train_epoch(train_set)
-
-            self.logger.info("evaluating...")
-            # average params for inference
-            params_list["model"].append(copy.deepcopy(self.model.state_dict()))
-            params_list["tra"].append(copy.deepcopy(self.tra.state_dict()))
-            self.model.load_state_dict(average_params(params_list["model"]))
-            self.tra.load_state_dict(average_params(params_list["tra"]))
-
-            # NOTE: during evaluating, the whole memory will be refreshed
-            if self.tra.num_states > 1 or self.eval_train:
-                train_set.clear_memory()  # NOTE: clear the shared memory
-                train_metrics = self.test_epoch(train_set)[0]
-                evals_result["train"].append(train_metrics)
-                self.logger.info("\ttrain metrics: %s" % train_metrics)
-
-            valid_metrics = self.test_epoch(valid_set)[0]
-            evals_result["valid"].append(valid_metrics)
-            self.logger.info("\tvalid metrics: %s" % valid_metrics)
-
-            if self.eval_test:
-                test_metrics = self.test_epoch(test_set)[0]
-                evals_result["test"].append(test_metrics)
-                self.logger.info("\ttest metrics: %s" % test_metrics)
-
-            if valid_metrics["IC"] > best_score:
-                best_score = valid_metrics["IC"]
-                stop_rounds = 0
-                best_epoch = epoch
-                best_params = {
-                    "model": copy.deepcopy(self.model.state_dict()),
-                    "tra": copy.deepcopy(self.tra.state_dict()),
-                }
-            else:
-                stop_rounds += 1
-                if stop_rounds >= self.early_stop:
-                    self.logger.info("early stop @ %s" % epoch)
-                    break
-
-            # restore parameters
-            self.model.load_state_dict(params_list["model"][-1])
-            self.tra.load_state_dict(params_list["tra"][-1])
-
-        self.logger.info("best score: %.6lf @ %d" % (best_score, best_epoch))
-        self.model.load_state_dict(best_params["model"])
-        self.tra.load_state_dict(best_params["tra"])
-
-        metrics, preds = self.test_epoch(test_set, return_pred=True)
-        self.logger.info("test metrics: %s" % metrics)
-
-        if self.logdir:
-            self.logger.info("save model & pred to local directory")
-
-            pd.concat({name: pd.DataFrame(evals_result[name]) for name in evals_result}, axis=1).to_csv(
-                self.logdir + "/logs.csv", index=False
-            )
-
-            torch.save(best_params, self.logdir + "/model.bin")
-
-            preds.to_pickle(self.logdir + "/pred.pkl")
-
-            info = {
-                "config": {
-                    "model_config": self.model_config,
-                    "tra_config": self.tra_config,
-                    "lr": self.lr,
-                    "n_epochs": self.n_epochs,
-                    "early_stop": self.early_stop,
-                    "smooth_steps": self.smooth_steps,
-                    "max_steps_per_epoch": self.max_steps_per_epoch,
-                    "lamb": self.lamb,
-                    "rho": self.rho,
-                    "seed": self.seed,
-                    "logdir": self.logdir,
-                },
-                "best_eval_metric": -best_score,  # NOTE: minux -1 for minimize
-                "metric": metrics,
-            }
-            with open(self.logdir + "/info.json", "w") as f:
-                json.dump(info, f)
-
-    def predict(self, dataset, segment="test"):
-        if not self.fitted:
-            raise ValueError("model is not fitted yet!")
-
-        test_set = dataset.prepare(segment)
-
-        metrics, preds = self.test_epoch(test_set, return_pred=True)
-        self.logger.info("test metrics: %s" % metrics)
-
-        return preds
-
-
-class LSTM(nn.Module):
-    """LSTM Model
-
-    Args:
-        input_size (int): input size (# features)
-        hidden_size (int): hidden size
-        num_layers (int): number of hidden layers
-        use_attn (bool): whether use attention layer.
-            we use concat attention as https://github.com/fulifeng/Adv-ALSTM/
-        dropout (float): dropout rate
-        input_drop (float): input dropout for data augmentation
-        noise_level (float): add gaussian noise to input for data augmentation
-    """
-
-    def __init__(
-        self,
-        input_size=16,
-        hidden_size=64,
-        num_layers=2,
-        use_attn=True,
-        dropout=0.0,
-        input_drop=0.0,
-        noise_level=0.0,
-        *args,
-        **kwargs,
-    ):
-        super().__init__()
-
-        self.input_size = input_size
-        self.hidden_size = hidden_size
-        self.num_layers = num_layers
-        self.use_attn = use_attn
-        self.noise_level = noise_level
-
-        self.input_drop = nn.Dropout(input_drop)
-
-        self.rnn = nn.LSTM(
-            input_size=input_size,
-            hidden_size=hidden_size,
-            num_layers=num_layers,
-            batch_first=True,
-            dropout=dropout,
-        )
-
-        if self.use_attn:
-            self.W = nn.Linear(hidden_size, hidden_size)
-            self.u = nn.Linear(hidden_size, 1, bias=False)
-            self.output_size = hidden_size * 2
-        else:
-            self.output_size = hidden_size
-
-    def forward(self, x):
-        x = self.input_drop(x)
-
-        if self.training and self.noise_level > 0:
-            noise = torch.randn_like(x).to(x)
-            x = x + noise * self.noise_level
-
-        rnn_out, _ = self.rnn(x)
-        last_out = rnn_out[:, -1]
-
-        if self.use_attn:
-            laten = self.W(rnn_out).tanh()
-            scores = self.u(laten).softmax(dim=1)
-            att_out = (rnn_out * scores).sum(dim=1).squeeze()
-            last_out = torch.cat([last_out, att_out], dim=1)
-
-        return last_out
-
-
-class PositionalEncoding(nn.Module):
-    # reference: https://pytorch.org/tutorials/beginner/transformer_tutorial.html
-    def __init__(self, d_model, dropout=0.1, max_len=5000):
-        super(PositionalEncoding, self).__init__()
-        self.dropout = nn.Dropout(p=dropout)
-
-        pe = torch.zeros(max_len, d_model)
-        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
-        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
-        pe[:, 0::2] = torch.sin(position * div_term)
-        pe[:, 1::2] = torch.cos(position * div_term)
-        pe = pe.unsqueeze(0).transpose(0, 1)
-        self.register_buffer("pe", pe)
-
-    def forward(self, x):
-        x = x + self.pe[: x.size(0), :]
-        return self.dropout(x)
-
-
-class Transformer(nn.Module):
-    """Transformer Model
-
-    Args:
-        input_size (int): input size (# features)
-        hidden_size (int): hidden size
-        num_layers (int): number of transformer layers
-        num_heads (int): number of heads in transformer
-        dropout (float): dropout rate
-        input_drop (float): input dropout for data augmentation
-        noise_level (float): add gaussian noise to input for data augmentation
-    """
-
-    def __init__(
-        self,
-        input_size=16,
-        hidden_size=64,
-        num_layers=2,
-        num_heads=2,
-        dropout=0.0,
-        input_drop=0.0,
-        noise_level=0.0,
-        **kwargs,
-    ):
-        super().__init__()
-
-        self.input_size = input_size
-        self.hidden_size = hidden_size
-        self.num_layers = num_layers
-        self.num_heads = num_heads
-        self.noise_level = noise_level
-
-        self.input_drop = nn.Dropout(input_drop)
-
-        self.input_proj = nn.Linear(input_size, hidden_size)
-
-        self.pe = PositionalEncoding(input_size, dropout)
-        layer = nn.TransformerEncoderLayer(
-            nhead=num_heads, dropout=dropout, d_model=hidden_size, dim_feedforward=hidden_size * 4
-        )
-        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers)
-
-        self.output_size = hidden_size
-
-    def forward(self, x):
-        x = self.input_drop(x)
-
-        if self.training and self.noise_level > 0:
-            noise = torch.randn_like(x).to(x)
-            x = x + noise * self.noise_level
-
-        x = x.permute(1, 0, 2).contiguous()  # the first dim need to be sequence
-        x = self.pe(x)
-
-        x = self.input_proj(x)
-        out = self.encoder(x)
-
-        return out[-1]
-
-
-class TRA(nn.Module):
-    """Temporal Routing Adaptor (TRA)
-
-    TRA takes historical prediction errors & latent representation as inputs,
-    then routes the input sample to a specific predictor for training & inference.
-
-    Args:
-        input_size (int): input size (RNN/Transformer's hidden size)
-        num_states (int): number of latent states (i.e., trading patterns)
-            If `num_states=1`, then TRA falls back to traditional methods
-        hidden_size (int): hidden size of the router
-        tau (float): gumbel softmax temperature
-    """
-
-    def __init__(self, input_size, num_states=1, hidden_size=8, tau=1.0, src_info="LR_TPE"):
-        super().__init__()
-
-        self.num_states = num_states
-        self.tau = tau
-        self.src_info = src_info
-
-        if num_states > 1:
-            self.router = nn.LSTM(
-                input_size=num_states,
-                hidden_size=hidden_size,
-                num_layers=1,
-                batch_first=True,
-            )
-            self.fc = nn.Linear(hidden_size + input_size, num_states)
-
-        self.predictors = nn.Linear(input_size, num_states)
-
-    def forward(self, hidden, hist_loss):
-        preds = self.predictors(hidden)
-
-        if self.num_states == 1:
-            return preds.squeeze(-1), preds, None
-
-        # information type
-        router_out, _ = self.router(hist_loss)
-        if "LR" in self.src_info:
-            latent_representation = hidden
-        else:
-            latent_representation = torch.randn(hidden.shape).to(hidden)
-        if "TPE" in self.src_info:
-            temporal_pred_error = router_out[:, -1]
-        else:
-            temporal_pred_error = torch.randn(router_out[:, -1].shape).to(hidden)
-
-        out = self.fc(torch.cat([temporal_pred_error, latent_representation], dim=-1))
-        prob = F.gumbel_softmax(out, dim=-1, tau=self.tau, hard=False)
-
-        if self.training:
-            final_pred = (preds * prob).sum(dim=-1)
-        else:
-            final_pred = preds[range(len(preds)), prob.argmax(dim=-1)]
-
-        return final_pred, preds, prob
-
-
-def evaluate(pred):
-    pred = pred.rank(pct=True)  # transform into percentiles
-    score = pred.score
-    label = pred.label
-    diff = score - label
-    MSE = (diff**2).mean()
-    MAE = (diff.abs()).mean()
-    IC = score.corr(label)
-    return {"MSE": MSE, "MAE": MAE, "IC": IC}
-
-
-def average_params(params_list):
-    assert isinstance(params_list, (tuple, list, collections.deque))
-    n = len(params_list)
-    if n == 1:
-        return params_list[0]
-    new_params = collections.OrderedDict()
-    keys = None
-    for i, params in enumerate(params_list):
-        if keys is None:
-            keys = params.keys()
-        for k, v in params.items():
-            if k not in keys:
-                raise ValueError("the %d-th model has different params" % i)
-            if k not in new_params:
-                new_params[k] = v / n
-            else:
-                new_params[k] += v / n
-    return new_params
-
-
-def shoot_infs(inp_tensor):
-    """Replaces inf by maximum of tensor"""
-    mask_inf = torch.isinf(inp_tensor)
-    ind_inf = torch.nonzero(mask_inf, as_tuple=False)
-    if len(ind_inf) > 0:
-        for ind in ind_inf:
-            if len(ind) == 2:
-                inp_tensor[ind[0], ind[1]] = 0
-            elif len(ind) == 1:
-                inp_tensor[ind[0]] = 0
-        m = torch.max(inp_tensor)
-        for ind in ind_inf:
-            if len(ind) == 2:
-                inp_tensor[ind[0], ind[1]] = m
-            elif len(ind) == 1:
-                inp_tensor[ind[0]] = m
-    return inp_tensor
-
-
-def sinkhorn(Q, n_iters=3, epsilon=0.01):
-    # epsilon should be adjusted according to logits value's scale
-    with torch.no_grad():
-        Q = shoot_infs(Q)
-        Q = torch.exp(Q / epsilon)
-        for i in range(n_iters):
-            Q /= Q.sum(dim=0, keepdim=True)
-            Q /= Q.sum(dim=1, keepdim=True)
-    return Q
diff --git a/examples/benchmarks/TRA/workflow_config_tra_Alpha158.yaml b/examples/benchmarks/TRA/workflow_config_tra_Alpha158.yaml
deleted file mode 100644
index 02c4ecac..00000000
--- a/examples/benchmarks/TRA/workflow_config_tra_Alpha158.yaml
+++ /dev/null
@@ -1,134 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-market: &market csi300
-benchmark: &benchmark SH000300
-
-data_handler_config: &data_handler_config
-  start_time: 2008-01-01
-  end_time: 2020-08-01
-  fit_start_time: 2008-01-01
-  fit_end_time: 2014-12-31
-  instruments: *market
-  infer_processors:
-    - class: FilterCol
-      kwargs:
-        fields_group: feature
-        col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10",
-                   "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5",
-                   "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"]
-    - class: RobustZScoreNorm
-      kwargs:
-        fields_group: feature
-        clip_outlier: true
-    - class: Fillna
-      kwargs:
-        fields_group: feature
-  learn_processors:
-    - class: CSRankNorm
-      kwargs:
-        fields_group: label
-  label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-
-num_states: &num_states 3
-
-memory_mode: &memory_mode sample
-
-tra_config: &tra_config
-  num_states: *num_states
-  rnn_arch: LSTM
-  hidden_size: 32
-  num_layers: 1
-  dropout: 0.0
-  tau: 1.0
-  src_info: LR_TPE
-
-model_config: &model_config
-  input_size: 20
-  hidden_size: 64
-  num_layers: 2
-  rnn_arch: LSTM
-  use_attn: True
-  dropout: 0.0
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-
-task:
-  model:
-    class: TRAModel
-    module_path: qlib.contrib.model.pytorch_tra
-    kwargs:
-      tra_config: *tra_config
-      model_config: *model_config
-      model_type: RNN
-      lr: 1e-3
-      n_epochs: 100
-      max_steps_per_epoch:
-      early_stop: 20
-      logdir: output/Alpha158
-      seed: 0
-      lamb: 1.0
-      rho: 0.99
-      alpha: 0.5
-      transport_method: router
-      memory_mode: *memory_mode
-      eval_train: False
-      eval_test: True
-      pretrain: True
-      init_state:
-      freeze_model: False
-      freeze_predictors: False
-  dataset:
-    class: MTSDatasetH
-    module_path: qlib.contrib.data.dataset
-    kwargs:
-      handler:
-        class: Alpha158
-        module_path: qlib.contrib.data.handler
-        kwargs: *data_handler_config
-      segments:
-        train: [2008-01-01, 2014-12-31]
-        valid: [2015-01-01, 2016-12-31]
-        test: [2017-01-01, 2020-08-01]
-      seq_len: 60
-      horizon: 2
-      input_size:
-      num_states: *num_states
-      batch_size: 1024
-      n_samples:
-      memory_mode: *memory_mode
-      drop_last: True
-  record:
-    - class: SignalRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        model: <MODEL>
-        dataset: <DATASET>
-    - class: SigAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        ana_long_short: False
-        ann_scaler: 252
-    - class: PortAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        config: *port_analysis_config
diff --git a/examples/benchmarks/TRA/workflow_config_tra_Alpha158_full.yaml b/examples/benchmarks/TRA/workflow_config_tra_Alpha158_full.yaml
deleted file mode 100644
index 9ccf56e8..00000000
--- a/examples/benchmarks/TRA/workflow_config_tra_Alpha158_full.yaml
+++ /dev/null
@@ -1,128 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-market: &market csi300
-benchmark: &benchmark SH000300
-
-data_handler_config: &data_handler_config
-  start_time: 2008-01-01
-  end_time: 2020-08-01
-  fit_start_time: 2008-01-01
-  fit_end_time: 2014-12-31
-  instruments: *market
-  infer_processors:
-    - class: RobustZScoreNorm
-      kwargs:
-        fields_group: feature
-        clip_outlier: true
-    - class: Fillna
-      kwargs:
-        fields_group: feature
-  learn_processors:
-    - class: CSRankNorm
-      kwargs:
-        fields_group: label
-  label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-
-num_states: &num_states 3
-
-memory_mode: &memory_mode sample
-
-tra_config: &tra_config
-  num_states: *num_states
-  rnn_arch: LSTM
-  hidden_size: 32
-  num_layers: 1
-  dropout: 0.0
-  tau: 1.0
-  src_info: LR_TPE
-
-model_config: &model_config
-  input_size: 158
-  hidden_size: 256
-  num_layers: 2
-  rnn_arch: LSTM
-  use_attn: True
-  dropout: 0.2
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-
-task:
-  model:
-    class: TRAModel
-    module_path: qlib.contrib.model.pytorch_tra
-    kwargs:
-      tra_config: *tra_config
-      model_config: *model_config
-      model_type: RNN
-      lr: 1e-3
-      n_epochs: 100
-      max_steps_per_epoch:
-      early_stop: 20
-      logdir: output/Alpha158_full
-      seed: 0
-      lamb: 1.0
-      rho: 0.99
-      alpha: 0.5
-      transport_method: router
-      memory_mode: *memory_mode
-      eval_train: False
-      eval_test: True
-      pretrain: True
-      init_state:
-      freeze_model: False
-      freeze_predictors: False
-  dataset:
-    class: MTSDatasetH
-    module_path: qlib.contrib.data.dataset
-    kwargs:
-      handler:
-        class: Alpha158
-        module_path: qlib.contrib.data.handler
-        kwargs: *data_handler_config
-      segments:
-        train: [2008-01-01, 2014-12-31]
-        valid: [2015-01-01, 2016-12-31]
-        test: [2017-01-01, 2020-08-01]
-      seq_len: 60
-      horizon: 2
-      input_size:
-      num_states: *num_states
-      batch_size: 1024
-      n_samples:
-      memory_mode: *memory_mode
-      drop_last: True
-  record:
-    - class: SignalRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        model: <MODEL>
-        dataset: <DATASET>
-    - class: SigAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        ana_long_short: False
-        ann_scaler: 252
-    - class: PortAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs:
-        config: *port_analysis_config
diff --git a/examples/benchmarks/TRA/workflow_config_tra_Alpha360.yaml b/examples/benchmarks/TRA/workflow_config_tra_Alpha360.yaml
deleted file mode 100644
index 29686d7d..00000000
--- a/examples/benchmarks/TRA/workflow_config_tra_Alpha360.yaml
+++ /dev/null
@@ -1,128 +0,0 @@
-qlib_init:
-  provider_uri: "~/.qlib/qlib_data/cn_data"
-  region: cn
-
-market: &market csi300
-benchmark: &benchmark SH000300
-
-data_handler_config: &data_handler_config
-  start_time: 2008-01-01
-  end_time: 2020-08-01
-  fit_start_time: 2008-01-01
-  fit_end_time: 2014-12-31
-  instruments: *market
-  infer_processors:
-    - class: RobustZScoreNorm
-      kwargs:
-        fields_group: feature
-        clip_outlier: true
-    - class: Fillna
-      kwargs:
-        fields_group: feature
-  learn_processors:
-    - class: CSRankNorm
-      kwargs:
-        fields_group: label
-  label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-
-num_states: &num_states 3
-
-memory_mode: &memory_mode sample
-
-tra_config: &tra_config
-  num_states: *num_states
-  rnn_arch: LSTM
-  hidden_size: 32
-  num_layers: 1
-  dropout: 0.0
-  tau: 1.0
-  src_info: LR_TPE
-
-model_config: &model_config
-  input_size: 6
-  hidden_size: 64
-  num_layers: 2
-  rnn_arch: LSTM
-  use_attn: True
-  dropout: 0.0
-
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-
-task:
-  model:
-    class: TRAModel
-    module_path: qlib.contrib.model.pytorch_tra
-    kwargs:
-      tra_config: *tra_config
-      model_config: *model_config
-      model_type: RNN
-      lr: 1e-3
-      n_epochs: 100
-      max_steps_per_epoch:
-      early_stop: 20
-      logdir: output/Alpha360
-      seed: 0
-      lamb: 1.0
-      rho: 0.99
-      alpha: 0.5
-      transport_method: router
-      memory_mode: *memory_mode
-      eval_train: False
-      eval_test: True
-      pretrain: True
-      init_state:
-      freeze_model: False
-      freeze_predictors: False
-  dataset:
-    class: MTSDatasetH
-    module_path: qlib.contrib.data.dataset
-    kwargs:
-      handler:
-        class: Alpha360
-        module_path: qlib.contrib.data.handler
-        kwargs: *data_handler_config
-      segments:
-        train: [2008-01-01, 2014-12-31]
-        valid: [2015-01-01, 2016-12-31]
-        test: [2017-01-01, 2020-08-01]
-      seq_len: 60
-      horizon: 2
-      input_size: 6
-      num_states: *num_states
-      batch_size: 1024
-      n_samples:
-      memory_mode: *memory_mode
-      drop_last: True
-  record:
-    - class: SignalRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        model: <MODEL>
-        dataset: <DATASET>
-    - class: SigAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs: 
-        ana_long_short: False
-        ann_scaler: 252
-    - class: PortAnaRecord
-      module_path: qlib.workflow.record_temp
-      kwargs:
-        config: *port_analysis_config
diff --git a/examples/benchmarks/TabNet/README.md b/examples/benchmarks/TabNet/README.md
deleted file mode 100644
index d7669396..00000000
--- a/examples/benchmarks/TabNet/README.md
+++ /dev/null
@@ -1,3 +0,0 @@
-# TabNet
-* Code: [https://github.com/dreamquark-ai/tabnet](https://github.com/dreamquark-ai/tabnet)
-* Paper: [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf).
diff --git a/examples/benchmarks/TabNet/requirements.txt b/examples/benchmarks/TabNet/requirements.txt
deleted file mode 100644
index d2f37de6..00000000
--- a/examples/benchmarks/TabNet/requirements.txt
+++ /dev/null
@@ -1,4 +0,0 @@
-pandas==1.1.2
-numpy==1.21.0
-scikit_learn==0.23.2
-torch==1.7.0
\ No newline at end of file
diff --git a/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha158.yaml b/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha158.yaml
deleted file mode 100644
index 7549688b..00000000
--- a/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha158.yaml
+++ /dev/null
@@ -1,81 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TabnetModel
-        module_path: qlib.contrib.model.pytorch_tabnet
-        kwargs:
-            d_feat: 158
-            pretrain: True
-            seed: 993
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha158
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                pretrain: [2008-01-01, 2014-12-31]
-                pretrain_validation: [2015-01-01, 2016-12-31]
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha360.yaml b/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha360.yaml
deleted file mode 100644
index 7155d25b..00000000
--- a/examples/benchmarks/TabNet/workflow_config_TabNet_Alpha360.yaml
+++ /dev/null
@@ -1,81 +0,0 @@
-qlib_init:
-    provider_uri: "~/.qlib/qlib_data/cn_data"
-    region: cn
-market: &market csi300
-benchmark: &benchmark SH000300
-data_handler_config: &data_handler_config
-    start_time: 2008-01-01
-    end_time: 2020-08-01
-    fit_start_time: 2008-01-01
-    fit_end_time: 2014-12-31
-    instruments: *market
-    infer_processors:
-        - class: RobustZScoreNorm
-          kwargs:
-              fields_group: feature
-              clip_outlier: true
-        - class: Fillna
-          kwargs:
-              fields_group: feature
-    learn_processors:
-        - class: DropnaLabel
-        - class: CSRankNorm
-          kwargs:
-              fields_group: label
-    label: ["Ref($close, -2) / Ref($close, -1) - 1"]
-port_analysis_config: &port_analysis_config
-    strategy:
-        class: TopkDropoutStrategy
-        module_path: qlib.contrib.strategy
-        kwargs:
-            signal: <PRED>
-            topk: 50
-            n_drop: 5
-    backtest:
-        start_time: 2017-01-01
-        end_time: 2020-08-01
-        account: 100000000
-        benchmark: *benchmark
-        exchange_kwargs:
-            limit_threshold: 0.095
-            deal_price: close
-            open_cost: 0.0005
-            close_cost: 0.0015
-            min_cost: 5
-task:
-    model:
-        class: TabnetModel
-        module_path: qlib.contrib.model.pytorch_tabnet
-        kwargs:
-            d_feat: 360
-            pretrain: True
-            seed: 993
-    dataset:
-        class: DatasetH
-        module_path: qlib.data.dataset
-        kwargs:
-            handler:
-                class: Alpha360
-                module_path: qlib.contrib.data.handler
-                kwargs: *data_handler_config
-            segments:
-                pretrain: [2008-01-01, 2014-12-31]
-                pretrain_validation: [2015-01-01, 2016-12-31]
-                train: [2008-01-01, 2014-12-31]
-                valid: [2015-01-01, 2016-12-31]
-                test: [2017-01-01, 2020-08-01]
-    record: 
-        - class: SignalRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            model: <MODEL>
-            dataset: <DATASET>
-        - class: SigAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            ana_long_short: False
-            ann_scaler: 252
-        - class: PortAnaRecord
-          module_path: qlib.workflow.record_temp
-          kwargs: 
-            config: *port_analysis_config
diff --git a/examples/benchmarks_dynamic/DDG-DA/workflow.py b/examples/benchmarks_dynamic/DDG-DA/workflow.py
index 7593fe37..7d32732f 100644
--- a/examples/benchmarks_dynamic/DDG-DA/workflow.py
+++ b/examples/benchmarks_dynamic/DDG-DA/workflow.py
@@ -4,10 +4,11 @@ from pathlib import Path
 from typing import Union
 
 import fire
-
+import qlib
 from qlib import auto_init
 from qlib.contrib.rolling.ddgda import DDGDA
 from qlib.tests.data import GetData
+from qlib.constant import REG_US
 
 DIRNAME = Path(__file__).absolute().resolve().parent
 BENCH_DIR = DIRNAME.parent / "baseline"
@@ -35,6 +36,8 @@ class DDGDABench(DDGDA):
 
 
 if __name__ == "__main__":
-    GetData().qlib_data(exists_skip=True)
-    auto_init()
+    # GetData().qlib_data(exists_skip=True)
+    # auto_init()
+    provider_uri = "~/.qlib/qlib_data/us_data"  # target_dir
+    qlib.init(provider_uri=provider_uri, region=REG_US)        
     fire.Fire(DDGDABench)
diff --git a/examples/benchmarks_dynamic/baseline/README.md b/examples/benchmarks_dynamic/baseline/README.md
index f1765141..889b9f4a 100644
--- a/examples/benchmarks_dynamic/baseline/README.md
+++ b/examples/benchmarks_dynamic/baseline/README.md
@@ -14,3 +14,7 @@ For example, users can try `LightGBM` forecasting models by running the followin
     python rolling_benchmark.py --conf_path=workflow_config_lightgbm_Alpha158.yaml run
 
 ```
+
+
+
+python rolling_benchmark_us.py --conf_path=/16t-2/cl/project/qlib/examples/benchmarks/Linear/workflow_config_linear_Alpha158_us.yaml run
\ No newline at end of file
diff --git a/qlib/contrib/meta/data_selection/dataset.py b/qlib/contrib/meta/data_selection/dataset.py
index 9349a12f..cfef237b 100644
--- a/qlib/contrib/meta/data_selection/dataset.py
+++ b/qlib/contrib/meta/data_selection/dataset.py
@@ -154,6 +154,8 @@ class MetaTaskDS(MetaTask):
 
             # these three lines occupied 70% of the time of initializing MetaTaskDS
             d_train, d_test = ds.prepare(["train", "test"], col_set=["feature", "label"])
+            d_train = d_train.replace([np.inf, -np.inf], np.nan)
+            d_test = d_test.replace([np.inf, -np.inf], np.nan)            
             prev_size = d_test.shape[0]
             d_train = d_train.dropna(axis=0)
             d_test = d_test.dropna(axis=0)
diff --git a/qlib/contrib/model/pytorch_lstm.py b/qlib/contrib/model/pytorch_lstm.py
index 168be6ca..6e500455 100755
--- a/qlib/contrib/model/pytorch_lstm.py
+++ b/qlib/contrib/model/pytorch_lstm.py
@@ -116,7 +116,7 @@ class LSTM(Model):
             dropout=self.dropout,
         )
         if optimizer.lower() == "adam":
-            self.train_optimizer = optim.Adam(self.lstm_model.parameters(), lr=self.lr)
+            self.train_optimizer = optim.Adam(self.lstm_model.parameters(), lr=0.001)
         elif optimizer.lower() == "gd":
             self.train_optimizer = optim.SGD(self.lstm_model.parameters(), lr=self.lr)
         else:
@@ -270,7 +270,7 @@ class LSTM(Model):
         sample_num = x_values.shape[0]
         preds = []
 
-        for begin in range(sample_num)[:: self.batch_size]:
+        for begin in range(0, sample_num, self.batch_size):
             if sample_num - begin < self.batch_size:
                 end = sample_num
             else:
@@ -278,9 +278,25 @@ class LSTM(Model):
             x_batch = torch.from_numpy(x_values[begin:end]).float().to(self.device)
             with torch.no_grad():
                 pred = self.lstm_model(x_batch).detach().cpu().numpy()
+            # Flatten pred if it has more than one dimension
+            pred = pred.reshape(-1)
             preds.append(pred)
-
-        return pd.Series(np.concatenate(preds), index=index)
+        
+        # Ensure preds is a 2D array before concatenation
+        preds = [np.expand_dims(p, axis=0) if p.ndim == 1 else p for p in preds]
+        return pd.Series(np.concatenate(preds, axis=0), index=index)
+
+        # for begin in range(sample_num)[:: self.batch_size]:
+        #     if sample_num - begin < self.batch_size:
+        #         end = sample_num
+        #     else:
+        #         end = begin + self.batch_size
+        #     x_batch = torch.from_numpy(x_values[begin:end]).float().to(self.device)
+        #     with torch.no_grad():
+        #         pred = self.lstm_model(x_batch).detach().cpu().numpy()
+        #     preds.append(pred)
+
+        # return pd.Series(np.concatenate(preds), index=index)
 
 
 class LSTMModel(nn.Module):
diff --git a/qlib/contrib/model/pytorch_lstm_ts.py b/qlib/contrib/model/pytorch_lstm_ts.py
index 8ecafc2d..f1bdd99b 100755
--- a/qlib/contrib/model/pytorch_lstm_ts.py
+++ b/qlib/contrib/model/pytorch_lstm_ts.py
@@ -121,7 +121,7 @@ class LSTM(Model):
             dropout=self.dropout,
         ).to(self.device)
         if optimizer.lower() == "adam":
-            self.train_optimizer = optim.Adam(self.LSTM_model.parameters(), lr=self.lr)
+            self.train_optimizer = optim.Adam(self.LSTM_model.parameters(), lr=float(self.lr))
         elif optimizer.lower() == "gd":
             self.train_optimizer = optim.SGD(self.LSTM_model.parameters(), lr=self.lr)
         else:
